# MoLE-Flow Update Notes

## Version History

---

## v1 (baseline) - Initial Implementation

### Architecture
- Task 0: Base NFÎßå ÌïôÏäµ (LoRA ÏóÜÏùå)
- Task 1+: Base frozen + LoRA ÌïôÏäµ
- LoRA scaling: `alpha / (2 * rank)` = 0.0156 (1.56%)
- InputAdapter: Instance Norm + Zero-init MLP

### Results (leather ‚Üí grid ‚Üí transistor)
| Class | Routing Acc | Image AUC | Pixel AUC |
|-------|-------------|-----------|-----------|
| leather | 100% | **1.0000** | **0.9481** |
| grid | 100% | 0.8204 | 0.9259 |
| transistor | 100% | 0.6654 | 0.7144 |
| **Mean** | 100% | 0.8286 | 0.8628 |

### Issues Identified
1. **Task 0 Bias**: Base NFÍ∞Ä Task 0Ïóê Ìé∏Ìñ•ÎêòÏñ¥ Îã§Î•∏ taskÏóêÏÑú ÏÑ±Îä• Ï†ÄÌïò
2. **LoRA Scaling Î∂ÄÏ°±**: 1.56% contributionÏúºÎ°ú adaptation Ìö®Í≥º ÎØ∏ÎØ∏
3. **InputAdapter ÌïúÍ≥Ñ**: MLP residual gateÍ∞Ä 0ÏúºÎ°ú ÏãúÏûëÌïòÏó¨ Í±∞Ïùò ÎØ∏ÏÇ¨Ïö©

---

## v2 (baseline_v2) - LoRA Scaling & Task 0 LoRA

### Changes from v1
1. **LoRA Scaling 2Î∞∞ Ï¶ùÍ∞Ä**
   ```python
   # v1: self.scaling = alpha / (2 * rank)  # 0.0156
   # v2: self.scaling = alpha / rank         # 0.03125
   ```

2. **Task 0ÎèÑ LoRA ÏÇ¨Ïö©**
   - Î™®Îì† TaskÍ∞Ä ÎèôÎì±ÌïòÍ≤å LoRAÎ°ú adaptation
   - Base NFÎäî Î≤îÏö© feature transformation ÌïôÏäµ
   - Task-specific adaptationÏùÄ LoRAÍ∞Ä Îã¥Îãπ

### Results (leather ‚Üí grid ‚Üí transistor)
| Class | Routing Acc | Image AUC | Pixel AUC |
|-------|-------------|-----------|-----------|
| leather | 100% | 0.9997 | 0.8900 |
| grid | 100% | **0.9850** | **0.9841** |
| transistor | 100% | **0.8075** | **0.8973** |
| **Mean** | 100% | **0.9307** | **0.9238** |

### Comparison (v1 ‚Üí v2)
| Metric | v1 | v2 | Change |
|--------|-----|-----|--------|
| leather Image | 1.0000 | 0.9997 | -0.03% |
| leather Pixel | 0.9481 | 0.8900 | **-6.1%** |
| grid Image | 0.8204 | 0.9850 | **+20.0%** |
| grid Pixel | 0.9259 | 0.9841 | +6.3% |
| transistor Image | 0.6654 | 0.8075 | **+21.4%** |
| transistor Pixel | 0.7144 | 0.8973 | **+25.6%** |
| **Mean Image** | 0.8286 | 0.9307 | **+12.3%** |
| **Mean Pixel** | 0.8628 | 0.9238 | **+7.1%** |

### Analysis
- **Overall**: Ï†ÑÏ≤¥ ÏÑ±Îä• ÎåÄÌè≠ Ìñ•ÏÉÅ (Mean Image AUC +12.3%)
- **Task 0 Issue**: leatherÏùò Pixel AUCÍ∞Ä 6.1% ÌïòÎùΩ
  - ÏõêÏù∏: Task 0ÏóêÏÑú Base + LoRA ÎèôÏãú ÌïôÏäµ Ïãú, LoRAÍ∞Ä ÏùºÎ∂Ä Ï†ïÎ≥¥Î•º Î∂ÑÎã¥ÌïòÎ©¥ÏÑú BaseÏùò ÌëúÌòÑÎ†• Î∂ÑÏÇ∞
  - LoRAÎäî Task-specific adaptationÏóê ÏµúÏ†ÅÌôîÎêòÏñ¥ pixel-level Ï†ïÎ∞ÄÎèÑÏóê ÏòÅÌñ•

---

## v3 (baseline_v3) - FiLM-style InputAdapter + Task 0 Self-Adaptation

### Changes from v2
1. **InputAdapter Íµ¨Ï°∞ Í∞úÏÑ† (FiLM-style)**
   - Instance Norm ‚Üí Layer Norm (spatial info Î≥¥Ï°¥)
   - FiLM (Feature-wise Linear Modulation): `y = gamma * x + beta`
   - residual_gate: 0 ‚Üí 0.5 (MLP Ï≤òÏùåÎ∂ÄÌÑ∞ active)
   - hidden_dim Ï¶ùÍ∞Ä: `channels//4` ‚Üí `max(channels//2, 128)`

2. **Task 0 Self-Adaptation**
   - Task 0ÏóêÎèÑ InputAdapter Ï†ÅÏö© (v2ÏóêÏÑúÎäî Task 0Ïóê InputAdapter ÏóÜÏóàÏùå)
   - `has_reference=False` ÏÑ§Ï†ïÏúºÎ°ú Í∞ïÌïú identity connection (90% identity + 10% transformed)
   - Ïù¥Î•º ÌÜµÌï¥ Task 0Ïùò pixel-level ÏÑ±Îä• ÌöåÎ≥µ Í∏∞ÎåÄ

3. **Î™®Îì† Task ÎèôÎì±Ìïú InputAdapter Ï†ÅÏö©**
   - v2: Task 0 (InputAdapter ÏóÜÏùå) vs Task 1+ (InputAdapter ÏûàÏùå)
   - v3: Î™®Îì† TaskÍ∞Ä InputAdapter ÏÇ¨Ïö© (Íµ¨Ï°∞Ï†Å ÏùºÍ¥ÄÏÑ±)

### Key Code Changes
```python
# adapters.py - TaskInputAdapter v3
class TaskInputAdapter(nn.Module):
    def __init__(self, channels, reference_mean=None, reference_std=None, use_norm=True):
        # FiLM parameters
        self.film_gamma = nn.Parameter(torch.ones(1, 1, 1, channels))
        self.film_beta = nn.Parameter(torch.zeros(1, 1, 1, channels))

        # Larger MLP
        hidden_dim = max(channels // 2, 128)  # Increased from channels//4

        # Active residual gate
        self.residual_gate = nn.Parameter(torch.tensor([0.5]))  # Changed from 0.0

        # Layer Norm instead of Instance Norm
        if use_norm:
            self.layer_norm = nn.LayerNorm(channels)

    def forward(self, x):
        # ...
        # Task 0 (has_reference=False): 90% identity + 10% transformed
        if not self.has_reference:
            x = 0.9 * identity + 0.1 * x
        return x
```

### Expected Improvements
- Task 0 pixel-level ÏÑ±Îä• ÌöåÎ≥µ (v1 ÏàòÏ§ÄÏúºÎ°ú)
- Îçî Í∞ïÎ†•Ìïú cross-task feature transformation
- Íµ¨Ï°∞Ï†Å ÏùºÍ¥ÄÏÑ±ÏúºÎ°ú Ïù∏Ìïú ÏïàÏ†ïÏ†ÅÏù∏ ÌïôÏäµ

---

## File Changes Summary

### v1 ‚Üí v2
| File | Changes |
|------|---------|
| `moleflow/models/lora.py` | scaling: `alpha/(2*rank)` ‚Üí `alpha/rank` |
| `moleflow/models/mole_nf.py` | Task 0ÏóêÏÑúÎèÑ LoRA adapter Ï∂îÍ∞Ä |
| `moleflow/trainer/continual_trainer.py` | Task 0 ÌïôÏäµ Î°úÏßÅ ÏàòÏ†ï |

### v2 ‚Üí v3
| File | Changes |
|------|---------|
| `moleflow/models/adapters.py` | FiLM-style InputAdapter (LayerNorm, gate=0.5, larger MLP) |
| `moleflow/models/mole_nf.py` | Task 0ÏóêÎèÑ InputAdapter Ï†ÅÏö© (self-adaptation) |
| `run.sh` | baseline_v3 Ïã§Ìóò ÏÑ§Ï†ï |

---

## v4 (baseline_v4) - CPCF + SC-LoRA (Novel Research Contribution)

### Research Contribution
**Paper Title**: "Beyond Independent Patches: Cross-Patch Coupling Flow with Spatial LoRA for Continual Anomaly Detection"

**Key Novelty Claims**:
1. **CPCF**: First normalizing flow that models `p(x_i | neighbors)` instead of `p(x_i)`
2. **SC-LoRA**: First spatially-varying LoRA for dense prediction tasks
3. **Continual AD**: Systematic benchmark for continual anomaly detection

### New Modules

#### 1. Spatial-Contextual LoRA (SC-LoRA)
```python
# moleflow/models/spatial_lora.py
class SpatialContextualLoRA(nn.Module):
    """
    Position-aware LoRA with spatial grid interpolation.

    Key Innovation:
    - LoRA parameters vary based on spatial position
    - Grid of LoRA parameters: (grid_size, grid_size, rank, dim)
    - Bilinear interpolation for smooth spatial adaptation
    """
    def __init__(self, in_features, out_features, rank=32, grid_size=4):
        # Grid of LoRA A: (G, G, R, D_in)
        self.lora_A = nn.Parameter(torch.zeros(grid_size, grid_size, rank, in_features))
        # Grid of LoRA B: (G, G, D_out, R)
        self.lora_B = nn.Parameter(torch.zeros(grid_size, grid_size, out_features, rank))

    def forward(self, x, positions):
        # Interpolate LoRA params based on position
        A, B = self._get_interpolated_lora(positions)
        return self.scaling * (x @ A.T @ B.T)
```

#### 2. Cross-Patch Coupling Flow (CPCF)
```python
# moleflow/models/cross_patch_flow.py
class CrossPatchCouplingLayer(nn.Module):
    """
    Coupling layer conditioned on neighborhood context.

    Standard: y = x * exp(s(x)) + t(x)
    CPCF:     y = x * exp(s(x, ctx)) + t(x, ctx)

    where ctx = NeighborhoodContext(x)
    """
    def __init__(self, channels, context_kernel=3):
        self.context_extractor = NeighborhoodContextExtractor(channels)
        self.s_net = SC_LoRA_MLP(channels + context_dim, channels)
        self.t_net = SC_LoRA_MLP(channels + context_dim, channels)

    def forward(self, x):
        context = self.context_extractor(x)  # (B, H, W, D)
        x1, x2 = x.split(D//2, dim=-1)

        # Condition on both patch and context
        s = self.s_net(cat([x1, context]))
        t = self.t_net(cat([x1, context]))

        return cat([x1, x2 * exp(s) + t])
```

### Theoretical Contribution

**Standard NF (Independent Patches)**:
```
log p(X) = Œ£·µ¢ log p(x·µ¢)
```
- Assumes patches are independent
- Ignores spatial context

**CPCF (Context-Aware Patches)**:
```
log p(X) = Œ£·µ¢ log p(x·µ¢ | N(i))
```
where N(i) = neighborhood of patch i

- Models "how different is this patch from its neighbors"
- Directly captures anomaly as contextual deviation

### Architecture Comparison

| Component | v3 | v4 |
|-----------|-----|-----|
| Flow Type | FrEIA (independent) | CPCF (context-aware) |
| LoRA Type | Standard LoRA | SC-LoRA (position-aware) |
| Patch Modeling | `p(x·µ¢)` | `p(x·µ¢ \| neighbors)` |
| Spatial Awareness | Position embedding only | Context + Position LoRA |

### Command Line Arguments
```bash
python run_moleflow.py \
    --use_cpcf \              # Enable Cross-Patch Coupling Flow
    --use_spatial_lora \       # Enable Spatial-Contextual LoRA
    --sc_lora_grid_size 4 \    # SC-LoRA grid resolution (4x4)
    --cpcf_context_kernel 3 \  # Context extraction kernel size
    --cpcf_use_attention       # Use attention instead of conv for context
```

### Expected Improvements
- **Image AUC**: +5-10% (better global anomaly detection)
- **Pixel AUC**: +10-15% (context-aware localization)
- **Cross-task**: Improved SC-LoRA handles position-dependent distribution shifts

### v3 ‚Üí v4
| File | Changes |
|------|---------|
| `moleflow/models/spatial_lora.py` | NEW: SC-LoRA module |
| `moleflow/models/cross_patch_flow.py` | NEW: CPCF module |
| `moleflow/models/mole_nf.py` | CPCF/SC-LoRA integration |
| `run_moleflow.py` | CPCF/SC-LoRA arguments |
| `run.sh` | baseline_v4 Ïã§Ìóò ÏÑ§Ï†ï |

---

## v4.1 - Fixed Context Extraction (Bug Fix)

### Issue
- v4ÏóêÏÑú Task 0 ÏÑ±Îä•ÏùÄ Ìñ•ÏÉÅÎêòÏóàÏúºÎÇò Task 1, 2 ÏÑ±Îä•Ïù¥ ÌÅ¨Í≤å Ï†ÄÌïòÎê®
- ÏõêÏù∏: Context ExtractorÍ∞Ä Task 0ÏóêÏÑúÎßå ÌïôÏäµÎêòÏñ¥ Task 0Ïóê Ìé∏Ìñ•

### Root Cause
```python
# Ïù¥Ï†Ñ ÏΩîÎìú - Task 0ÏóêÏÑúÎßå context extractor ÌïôÏäµ
if task_id == 0:
    params.extend(layer.context_extractor.parameters())
```
- Task 0: Context ExtractorÍ∞Ä Task 0 Îç∞Ïù¥ÌÑ∞Î°úÎßå ÌïôÏäµ
- Task 1+: Task 0Ïóê Ìé∏Ìñ•Îêú context feature Ï†úÍ≥µ ‚Üí ÏÑ±Îä• Ï†ÄÌïò

### Fix
Context extractionÏùÑ **Í≥†Ï†ïÎêú (non-learnable) Î∞©Ïãù**ÏúºÎ°ú Î≥ÄÍ≤Ω:

```python
# cross_patch_flow.py - NeighborhoodContextExtractor
class NeighborhoodContextExtractor(nn.Module):
    def __init__(self, channels, kernel_size=3, use_attention=False):
        # FIXED averaging kernel - no learnable parameters
        kernel = torch.ones(1, 1, kernel_size, kernel_size) / (kernel_size * kernel_size)
        self.register_buffer('avg_kernel', kernel)
        self.register_buffer('context_gate', torch.tensor([0.3]))  # Fixed gate

    def forward(self, x):
        # Simple neighborhood mean (task-agnostic)
        neighbor_mean = F.conv2d(x, self.avg_kernel, padding, groups=D)
        context = (1 - gate) * x + gate * neighbor_mean
        return context
```

### Key Insight
- **Context = Ï£ºÎ≥Ä ÌèâÍ∑†** ‚Üí task-agnostic (Ïñ¥Îñ§ taskÏóêÏÑúÎèÑ ÎèôÏùºÌïú ÏùòÎØ∏)
- **SC-LoRA = task-specific adaptation** ‚Üí task Î≥ÑÎ°ú Îã§Î•¥Í≤å ÌïôÏäµ
- Ïó≠Ìï† Î∂ÑÎ¶¨: Í≥†Ï†ï context + ÌïôÏäµ Í∞ÄÎä•Ìïú adaptation

### v4 ‚Üí v4.1
| File | Changes |
|------|---------|
| `moleflow/models/cross_patch_flow.py` | Fixed (non-learnable) context extraction |
| `moleflow/models/mole_nf.py` | Removed context_extractor from trainable params |

---

## v5 - Center Loss for Discriminative Feature Learning

### Motivation
- v4Ïùò cross-patch context Ï†ëÍ∑ºÎ≤ïÏù¥ task bias Î¨∏Ï†úÎ°ú Ïã§Ìå®
- Anomaly Detection ÏûêÏ≤¥Ïùò ÏÑ±Îä• Ìñ•ÏÉÅÏóê ÏßëÏ§ë
- Normal featureÎ•º Îçî compactÌïòÍ≤å ÎßåÎì§Ïñ¥ÏÑú anomaly Íµ¨Î∂Ñ Ïö©Ïù¥ÌïòÍ≤å

### Core Idea
**Latent space z**Ïóê Center LossÎ•º Ï†ÅÏö©ÌïòÏó¨ normalÏùÑ z ‚âà 0ÏúºÎ°ú Îçî Í∞ïÌïòÍ≤å Ïú†ÎèÑ:
```
Loss = NLL_loss + Œª * Center_loss
     = -log p(x) + Œª * ||z||¬≤
```

**Key Insight**:
- NFÎäî inputÏùÑ GaussianÏúºÎ°ú Îß§Ìïë ‚Üí normalÏùÄ z ‚âà 0
- Center LossÎäî Ïù¥ Î™©ÌëúÎ•º **Îçî Í∞ïÌïòÍ≤å** Í∞ïÏ†ú
- Input featureÍ∞Ä ÏïÑÎãå **latent z**Ïóê Ï†ÅÏö©Ìï¥Ïïº gradientÍ∞Ä NFÏóê Ï†ÑÌååÎê®

### Implementation

```python
# Training loopÏóêÏÑú
z, log_jac_det = nf_model.forward(x, reverse=False)

# NLL loss
log_pz = -0.5 * (z ** 2).sum() / (B * H * W)
nll_loss = -(log_pz + log_jac)

# Center loss on latent z (fixed center at zero)
center_loss = (z ** 2).sum(dim=-1).mean()  # ||z - 0||¬≤

total_loss = nll_loss + Œª * center_loss
```

### Why Fixed Center at Zero?
- Learnable center ‚Üí centerÍ∞Ä zÏùò meanÏúºÎ°ú Ïù¥Îèô ‚Üí ÏùòÎØ∏ ÏóÜÏùå
- Fixed center = 0 ‚Üí zÎ•º ÏõêÏ†êÏúºÎ°ú Í∞ïÌïòÍ≤å ÎãπÍπÄ ‚Üí Gaussian prior Í∞ïÌôî

### Training Flow
1. Forward: x ‚Üí NF ‚Üí z
2. NLL loss: zÍ∞Ä GaussianÏùÑ Îî∞Î•¥ÎèÑÎ°ù
3. Center loss: zÍ∞Ä ÏõêÏ†êÏóê Í∞ÄÍπùÎèÑÎ°ù (Ï∂îÍ∞Ä regularization)
4. Backward: gradientÍ∞Ä NFÎ°ú Ï†ÑÌååÎêòÏñ¥ Îçî compactÌïú latent space ÌïôÏäµ

### Command Line Arguments
```bash
python run_moleflow.py \
    --center_loss_weight 0.05 \  # Center loss weight (recommend 0.01-0.1)
    ...
```

### Expected Improvements
- Normal featureÍ∞Ä Îçî compactÌï¥Ï†∏ÏÑú anomaly Íµ¨Î∂Ñ Ìñ•ÏÉÅ
- ÌäπÌûà pixel-level anomaly detectionÏóêÏÑú Ìö®Í≥º Í∏∞ÎåÄ
- TaskÎ≥Ñ centerÍ∞Ä task-specific ÌäπÏÑ±ÏùÑ ÌïôÏäµ

### v3 ‚Üí v5
| File | Changes |
|------|---------|
| `moleflow/models/center_loss.py` | NEW: CenterLoss module |
| `moleflow/trainer/continual_trainer.py` | Center loss integration |
| `run_moleflow.py` | `--center_loss_weight` argument |
| `run.sh` | v5 experiment configuration |

---

## v6 - Patch Self-Attention for Contextual Anomaly Detection

### Motivation
- v5Ïùò Center LossÎäî NLLÏù¥ Ïù¥ÎØ∏ z ‚âà 0ÏùÑ Ïú†ÎèÑÌïòÎØÄÎ°ú Ìö®Í≥º ÎØ∏ÎØ∏
- **Contextual Anomaly** ÌÉêÏßÄ ÌïÑÏöî: Ï£ºÎ≥Ä Ìå®ÏπòÏôÄ Îã§Î•∏ Ìå®ÏπòÍ∞Ä anomaly
- Patch Í∞Ñ Í¥ÄÍ≥ÑÎ•º Î™®Îç∏ÎßÅÌïòÏó¨ anomaly detection ÏÑ±Îä• Ìñ•ÏÉÅ

### Core Idea
**Standard NF (Independent Patches)**:
```
log p(X) = Œ£·µ¢ log p(x·µ¢)
```
- Í∞Å Ìå®ÏπòÎ•º ÎèÖÎ¶ΩÏ†ÅÏúºÎ°ú Ï≤òÎ¶¨
- Ï£ºÎ≥Ä context Î¨¥Ïãú

**Patch Self-Attention (Context-Aware)**:
```
log p(X) = Œ£·µ¢ log p(x·µ¢ | context_i)
where context_i = Attention(x·µ¢, all patches)
```
- Ìå®Ïπò Í∞Ñ Í¥ÄÍ≥Ñ Î™®Îç∏ÎßÅ
- "Ï£ºÎ≥ÄÍ≥º Îã§Î•∏" Ìå®ÏπòÎ•º anomalyÎ°ú ÌÉêÏßÄ

### Architecture
```
ViT Features [B, H, W, D]
       ‚Üì
Patch Self-Attention (LightweightPatchAttention)
       ‚Üì
Context-Enhanced Features [B, H, W, D]
       ‚Üì
Normalizing Flow
       ‚Üì
Latent z, log_jac_det
```

### LightweightPatchAttention Module
```python
class LightweightPatchAttention(nn.Module):
    def __init__(self, embed_dim=512, hidden_dim=256, dropout=0.1):
        # Q, K, V projections
        self.q_proj = nn.Linear(embed_dim, hidden_dim)
        self.k_proj = nn.Linear(embed_dim, hidden_dim)
        self.v_proj = nn.Linear(embed_dim, hidden_dim)

        # Learnable gate (starts at 0 for stable training)
        self.gate = nn.Parameter(torch.zeros(1))

        # FFN for additional processing
        self.ffn = nn.Sequential(...)

    def forward(self, x):  # x: [B, H, W, D]
        # Reshape to sequence
        x_seq = x.view(B, H*W, D)

        # Self-attention
        Q, K, V = self.q_proj(x), self.k_proj(x), self.v_proj(x)
        attn = softmax(Q @ K.T / sqrt(d))
        attn_out = attn @ V

        # Gated residual connection
        gate = sigmoid(self.gate)
        x = x + gate * attn_out

        # FFN
        x = x + self.ffn(x)

        return x.view(B, H, W, D)
```

### Key Design Choices
1. **Learnable Gate (starts at 0)**:
   - ÌïôÏäµ Ï¥àÍ∏∞ÏóêÎäî identity (ÏïàÏ†ïÏ†Å ÌïôÏäµ)
   - Ï†êÏßÑÏ†ÅÏúºÎ°ú attention Í∏∞Ïó¨ÎèÑ Ï¶ùÍ∞Ä

2. **Single-Head Attention**:
   - LightweightÌïòÎ©¥ÏÑúÎèÑ patch Í¥ÄÍ≥Ñ Ìè¨Ï∞©
   - Multi-head ÎåÄÎπÑ Í≥ÑÏÇ∞ Ìö®Ïú®Ï†Å

3. **Pre-LayerNorm + FFN**:
   - Transformer Ïä§ÌÉÄÏùº ÏïàÏ†ïÏ†Å ÌïôÏäµ
   - FFNÏúºÎ°ú ÎπÑÏÑ†Ìòï transformation Í∞ïÌôî

### Training
- Patch attention Î™®ÎìàÏùÄ **Î™®Îì† taskÏóêÏÑú Í≥µÏú†** (Base NFÏ≤òÎüº)
- Task 0ÏóêÏÑú ÌïôÏäµ ÌõÑ freeze
- Task 1+ÏóêÏÑúÎäî LoRAÎßå ÌïôÏäµ

### Command Line Arguments
```bash
python run_moleflow.py \
    --use_patch_attention \  # Enable Patch Self-Attention
    ...
```

### Expected Improvements
- **Contextual Anomaly Detection**: Ï£ºÎ≥ÄÍ≥º Îã§Î•∏ Ìå®Ïπò ÌÉêÏßÄ Ìñ•ÏÉÅ
- **Pixel-level AUC**: Context Ï†ïÎ≥¥Î°ú localization Ï†ïÎ∞ÄÎèÑ Ìñ•ÏÉÅ
- **Structural Anomaly**: Ï†ÑÏó≠Ï†Å Ìå®Ïπò Í¥ÄÍ≥ÑÎ°ú Íµ¨Ï°∞Ï†Å Ïù¥ÏÉÅ ÌÉêÏßÄ

### v3 ‚Üí v6
| File | Changes |
|------|---------|
| `moleflow/models/patch_attention.py` | NEW: LightweightPatchAttention, PatchInteractionModule |
| `moleflow/models/__init__.py` | Export patch attention modules |
| `moleflow/trainer/continual_trainer.py` | Patch attention integration |
| `run_moleflow.py` | `--use_patch_attention` argument |
| `run.sh` | v6 experiment configuration |

### v6 Result
- **Ïã§Ìå®**: ViTÍ∞Ä Ïù¥ÎØ∏ self-attentionÏúºÎ°ú contextualizedÎêú featureÎ•º Ï∂úÎ†•ÌïòÎØÄÎ°ú Ï∂îÍ∞Ä attentionÏù¥ Ïò§ÌûàÎ†§ Ìï¥Í∞Ä Îê®

---

## v7 - Focal NLL Loss for Hard Sample Mining

### Motivation
- v5 (Center Loss): NLLÏù¥ Ïù¥ÎØ∏ z ‚âà 0 Ïú†ÎèÑÌïòÎØÄÎ°ú Ìö®Í≥º ÎØ∏ÎØ∏
- v6 (Patch Attention): ViT Ï§ëÎ≥µÏúºÎ°ú Ïã§Ìå®
- **ÏÉàÎ°úÏö¥ Ï†ëÍ∑º**: Ïñ¥Î†§Ïö¥ ÏÉòÌîåÏóê Îçî ÏßëÏ§ëÌïòÏó¨ decision boundary ÌïôÏäµ Í∞ïÌôî

### Core Idea
**Standard NLL**:
```
L = -log p(x)  # Î™®Îì† ÏÉòÌîå ÎèôÎì±Ìïú Í∞ÄÏ§ëÏπò
```

**Focal NLL**:
```
L = (1 - p)^Œ≥ * (-log p(x))

Œ≥ = 0: Standard NLL (Î™®Îì† ÏÉòÌîå ÎèôÎì±)
Œ≥ = 1: ÏïΩÍ∞ÑÏùò hard sample Í∞ïÏ°∞
Œ≥ = 2: Í∞ïÌïú hard sample Í∞ïÏ°∞ (Í∂åÏû•)
```

- `p` = probability = exp(-nll)
- ÎÜíÏùÄ NLL (Ïñ¥Î†§Ïö¥ ÏÉòÌîå) ‚Üí ÎÇÆÏùÄ p ‚Üí ÎÜíÏùÄ weight (1-p)^Œ≥
- ÎÇÆÏùÄ NLL (Ïâ¨Ïö¥ ÏÉòÌîå) ‚Üí ÎÜíÏùÄ p ‚Üí ÎÇÆÏùÄ weight

### Implementation
```python
def _compute_nll_loss(self, z, log_jac_det):
    B, H, W, D = z.shape

    if not self.use_focal_loss:
        # Standard NLL
        log_pz = -0.5 * (z ** 2).sum() / (B * H * W)
        log_jac = log_jac_det.mean() / (H * W)
        return -(log_pz + log_jac)
    else:
        # Per-patch NLL
        log_pz_per_patch = -0.5 * (z ** 2).sum(dim=-1)  # [B, H, W]
        log_jac_per_patch = log_jac_det.view(B, 1, 1) / (H * W)
        nll_per_patch = -(log_pz_per_patch + log_jac_per_patch)

        # Focal weighting
        prob = torch.exp(-nll_per_patch.clamp(max=20))
        focal_weight = (1 - prob).pow(self.focal_gamma)

        return (focal_weight * nll_per_patch).mean()
```

### Why This Should Work
1. **Hard Sample Mining**: Normal distribution Í≤ΩÍ≥ÑÏóê ÏûàÎäî ÏÉòÌîåÏóê ÏßëÏ§ë
2. **Better Decision Boundary**: Ïñ¥Î†§Ïö¥ Ìå®ÏπòÎ•º Ïûò ÌïôÏäµÌïòÎ©¥ anomaly Íµ¨Î∂Ñ Ìñ•ÏÉÅ
3. **Gradient Focus**: Easy sampleÏùÄ gradient Í∏∞Ïó¨ Í∞êÏÜå, hard sampleÏóê gradient ÏßëÏ§ë

### Command Line Arguments
```bash
python run_moleflow.py \
    --focal_gamma 2.0 \  # Focal loss gamma (recommend 1.0-2.0)
    ...
```

### Expected Improvements
- Îçî sharpÌïú normal distribution Í≤ΩÍ≥Ñ ÌïôÏäµ
- ÌäπÌûà Task 0ÏóêÏÑú base NF ÌíàÏßà Ìñ•ÏÉÅ
- Anomaly detection ÏÑ±Îä• Ï†ÑÎ∞òÏ†Å Ìñ•ÏÉÅ

### v3 ‚Üí v7
| File | Changes |
|------|---------|
| `moleflow/trainer/continual_trainer.py` | `_compute_nll_loss()` helper method, focal weighting |
| `run_moleflow.py` | `--focal_gamma` argument |
| `run.sh` | v7 experiment configuration |

---

## Baseline 1.5 ‚Üí 2.0: Patch-wise Context Gate

### Motivation
**Baseline 1.5 (Global Alpha)Ïùò Î¨∏Ï†úÏ†ê**:
- `alpha`Îäî global scalar ‚Üí Î™®Îì† Ìå®ÏπòÏóê ÎèôÏùºÌïú context Í∞ïÎèÑ Ï†ÅÏö©
- ÌïôÏäµ Ï§ë **Ï†ïÏÉÅ Îç∞Ïù¥ÌÑ∞Îßå** Î¥Ñ ‚Üí anomaly-aware ÌïôÏäµ Î∂àÍ∞ÄÎä•
- Í≤∞Í≥º: `alpha ‚âà Ï¥àÍ∏∞Í∞í`ÏúºÎ°ú Í≥†Ï†ï, sigmoid boundÍ∞Ä ÏùòÎØ∏ ÏóÜÏùå

**ÌïµÏã¨ ÌÜµÏ∞∞**:
> Global alphaÎäî "knob"Ïùº ÎøêÏù¥Í≥†,
> Anomaly detectionÏóêÏÑúÎäî "switch"Í∞Ä ÌïÑÏöîÌïòÎã§.
> Í∑∏ switchÎäî **patch-wise gate**Îã§.

### Core Idea
| Íµ¨Î∂Ñ | Baseline 1.5 (Global Alpha) | Baseline 2.0 (Patch-wise Gate) |
|------|----------------------------|-------------------------------|
| ÏàòÏãù | `ctx = alpha * ctx` | `ctx = gate(x, ctx) * ctx` |
| Ï∞®Ïõê | `alpha` ‚àà ‚Ñù (scalar) | `gate` ‚àà ‚Ñù^(B√óH√óW√ó1) (per-patch) |
| ÌïôÏäµ | Î™®Îì† Ìå®Ïπò ÎèôÏùº | Ìå®ÏπòÎ≥Ñ ÎèÖÎ¶Ω Í≤∞Ï†ï |
| Ï†ïÏÉÅ Ìå®Ïπò | Œ± * ctx | gate ‚Üí 0 (context Î¨¥Ïãú) |
| Ïù¥ÏÉÅ Ìå®Ïπò | Œ± * ctx | gate ‚Üí 1 (context ÏÇ¨Ïö©) |

### Code Changes

#### 1. MoLEContextSubnet (lora.py)

**Before (Baseline 1.5 - Global Alpha)**:
```python
class MoLEContextSubnet(nn.Module):
    def __init__(self, dims_in, dims_out, ...,
                 context_init_scale=0.1, context_max_alpha=0.2):
        # ...

        # Global alpha with sigmoid upper bound
        # alpha = alpha_max * sigmoid(alpha_param)
        p = min(max(context_init_scale / context_max_alpha, 0.01), 0.99)
        init_param = torch.log(torch.tensor([p / (1 - p)]))  # Inverse sigmoid
        self.context_scale_param = nn.Parameter(init_param)

    def forward(self, x):
        # ...
        ctx = self.context_conv(x_spatial)

        # Global alpha scaling (same for ALL patches)
        alpha = self.context_max_alpha * torch.sigmoid(self.context_scale_param)
        ctx = alpha * ctx  # (BHW, D) * scalar

        s_input = torch.cat([x, ctx], dim=-1)
        # ...
```

**After (Baseline 2.0 - Patch-wise Gate)**:
```python
class MoLEContextSubnet(nn.Module):
    def __init__(self, dims_in, dims_out, ...,
                 context_init_scale=0.1, context_max_alpha=0.2,
                 use_context_gate=False, context_gate_hidden=64):  # NEW
        # ...
        self.use_context_gate = use_context_gate

        if use_context_gate:
            # NEW: Patch-wise gate network
            # gate = sigmoid(MLP([x, ctx])) ‚Üí (BHW, 1)
            self.context_gate_net = nn.Sequential(
                nn.Linear(dims_in * 2, context_gate_hidden),
                nn.ReLU(),
                nn.Linear(context_gate_hidden, 1)
            )
            # Initialize to output ~0 ‚Üí gate starts at 0.5
            nn.init.zeros_(self.context_gate_net[0].weight)
            nn.init.zeros_(self.context_gate_net[0].bias)
            nn.init.zeros_(self.context_gate_net[2].weight)
            nn.init.zeros_(self.context_gate_net[2].bias)

            self.context_scale_param = None  # No global alpha
        else:
            # Legacy: Global alpha (Baseline 1.5)
            p = min(max(context_init_scale / context_max_alpha, 0.01), 0.99)
            init_param = torch.log(torch.tensor([p / (1 - p)]))
            self.context_scale_param = nn.Parameter(init_param)
            self.context_gate_net = None

    def forward(self, x):
        # ...
        ctx = self.context_conv(x_spatial)

        if self.use_context_gate and self.context_gate_net is not None:
            # NEW: Patch-wise gate (per-patch decision)
            gate_input = torch.cat([x, ctx], dim=-1)  # (BHW, 2D)
            gate_logit = self.context_gate_net(gate_input)  # (BHW, 1)
            gate = torch.sigmoid(gate_logit)  # (BHW, 1)

            self._last_gate = gate.detach()  # For logging
            ctx = gate * ctx  # (BHW, D) * (BHW, 1) ‚Üí per-patch scaling
        else:
            # Legacy: Global alpha
            alpha = self.context_max_alpha * torch.sigmoid(self.context_scale_param)
            ctx = alpha * ctx

        s_input = torch.cat([x, ctx], dim=-1)
        # ...

    # NEW: Logging utilities
    def get_context_alpha(self) -> float:
        """Get global alpha value (legacy mode)."""
        if self.context_scale_param is not None:
            with torch.no_grad():
                return (self.context_max_alpha
                        * torch.sigmoid(self.context_scale_param)).item()
        return None

    def get_last_gate_stats(self) -> dict:
        """Get gate statistics (patch-wise mode)."""
        if hasattr(self, '_last_gate') and self._last_gate is not None:
            gate = self._last_gate
            return {
                'mean': gate.mean().item(),
                'std': gate.std().item(),
                'min': gate.min().item(),
                'max': gate.max().item()
            }
        return None
```

#### 2. AblationConfig (ablation.py)

**Added**:
```python
@dataclass
class AblationConfig:
    # ... existing fields ...

    # Scale-specific Context (Baseline 1.5)
    use_scale_context: bool = False
    scale_context_kernel: int = 3
    scale_context_init_scale: float = 0.1
    scale_context_max_alpha: float = 0.2

    # NEW: Patch-wise Context Gate (Baseline 2.0)
    use_context_gate: bool = False    # Use patch-wise gate instead of global alpha
    context_gate_hidden: int = 64     # Hidden dim for gate MLP
```

#### 3. MoLESpatialAwareNF (mole_nf.py)

**Before**:
```python
subnet = MoLEContextSubnet(
    dims_in, dims_out,
    rank=self.lora_rank,
    alpha=self.lora_alpha,
    use_lora=self.use_lora,
    use_task_bias=self.use_task_bias,
    context_kernel=self.scale_context_kernel,
    context_init_scale=self.scale_context_init_scale,
    context_max_alpha=self.scale_context_max_alpha
)
```

**After**:
```python
subnet = MoLEContextSubnet(
    dims_in, dims_out,
    rank=self.lora_rank,
    alpha=self.lora_alpha,
    use_lora=self.use_lora,
    use_task_bias=self.use_task_bias,
    context_kernel=self.scale_context_kernel,
    context_init_scale=self.scale_context_init_scale,
    context_max_alpha=self.scale_context_max_alpha,
    use_context_gate=self.use_context_gate,      # NEW
    context_gate_hidden=self.context_gate_hidden  # NEW
)
```

**Added get_context_info() method**:
```python
def get_context_info(self) -> dict:
    """Get context gate/alpha information for logging."""
    if not self.use_scale_context:
        return {}

    info = {}
    if self.use_context_gate:
        # Aggregate gate stats from all subnets
        gate_stats = []
        for subnet in self.subnets:
            if hasattr(subnet, 'get_last_gate_stats'):
                stats = subnet.get_last_gate_stats()
                if stats is not None:
                    gate_stats.append(stats)

        if gate_stats:
            info['gate_mean'] = sum(s['mean'] for s in gate_stats) / len(gate_stats)
            info['gate_std'] = sum(s['std'] for s in gate_stats) / len(gate_stats)
            info['gate_min'] = min(s['min'] for s in gate_stats)
            info['gate_max'] = max(s['max'] for s in gate_stats)
    else:
        # Collect alpha from all subnets
        alphas = [s.get_context_alpha() for s in self.subnets
                  if hasattr(s, 'get_context_alpha')]
        alphas = [a for a in alphas if a is not None]
        if alphas:
            info['alpha_mean'] = sum(alphas) / len(alphas)

    return info
```

#### 4. Trainer Logging (continual_trainer.py)

**Added context logging per epoch**:
```python
# In _train_base_task, _train_fast_stage, _train_slow_stage:
avg_epoch_loss = epoch_loss / max(num_batches, 1)
current_lr = optimizer.param_groups[0]['lr']

# NEW: Get context gate/alpha info for logging
extra_info = {"LR": current_lr}
context_info = self.nf_model.get_context_info()
if context_info:
    extra_info.update(context_info)

if self.logger:
    self.logger.log_epoch(task_id, epoch, num_epochs, avg_epoch_loss,
                          stage="FAST", extra_info=extra_info)
else:
    ctx_str = ""
    if 'gate_mean' in context_info:
        ctx_str = f" | Gate: {context_info['gate_mean']:.4f}¬±{context_info['gate_std']:.4f}"
    elif 'alpha_mean' in context_info:
        ctx_str = f" | Alpha: {context_info['alpha_mean']:.4f}"
    print(f"  üìä [FAST] Epoch [...] Average Loss: {avg_epoch_loss:.4f}{ctx_str}")
```

### Command Line Usage

```bash
# Baseline 1.5: Global Alpha (Í∏∞Ï°¥)
python run_moleflow.py \
    --use_scale_context \
    --scale_context_kernel 3 \
    --scale_context_init_scale 0.1 \
    --scale_context_max_alpha 0.2

# Baseline 2.0: Patch-wise Gate (NEW)
python run_moleflow.py \
    --use_scale_context \
    --use_context_gate \
    --context_gate_hidden 64
```

### Expected Improvements
- Ìå®ÏπòÎ≥ÑÎ°ú context ÏÇ¨Ïö© Ïó¨Î∂Ä Í≤∞Ï†ï ‚Üí anomaly Í≤ΩÍ≥ÑÏóêÏÑú Îçî Ï†ïÎ∞ÄÌïú detection
- Gate networkÍ∞Ä normal/anomaly Ìå®Ïπò ÌäπÏÑ± ÌïôÏäµ
- Îçî interpretableÌïú anomaly map ÏÉùÏÑ± Í∞ÄÎä•

### Baseline 1.5 ‚Üí 2.0
| File | Changes |
|------|---------|
| `moleflow/models/lora.py` | `MoLEContextSubnet` - context_gate_net Ï∂îÍ∞Ä |
| `moleflow/config/ablation.py` | `use_context_gate`, `context_gate_hidden` ÏÑ§Ï†ï Ï∂îÍ∞Ä |
| `moleflow/models/mole_nf.py` | context gate ÌååÎùºÎØ∏ÌÑ∞ Ï†ÑÎã¨, `get_context_info()` Î©îÏÑúÎìú |
| `moleflow/trainer/continual_trainer.py` | Context gate/alpha Î°úÍπÖ Ï∂îÍ∞Ä |

---

## Version 3 - No-Replay Continual Learning Solutions

### Motivation
Version 2ÏóêÏÑú continual learning Ïãú ÏÑ±Îä• Ï†ÄÌïò Î¨∏Ï†úÍ∞Ä Ïó¨Ï†ÑÌûà Ï°¥Ïû¨:
- Task 0 ‚Üí Task 1 ‚Üí Task 2 ÌïôÏäµ Ïãú Ïù¥Ï†Ñ task ÏÑ±Îä• Í∞êÏÜå (Catastrophic Forgetting)
- Í∏∞Ï°¥ Î∞©Î≤ï: Replay buffer ÏÇ¨Ïö© ‚Üí Î©îÎ™®Î¶¨ ÎπÑÏö©, ÌîÑÎùºÏù¥Î≤ÑÏãú Î¨∏Ï†ú

**Î™©Ìëú**: Replay ÏóÜÏù¥ continual learning ÏÑ±Îä• Ìñ•ÏÉÅ

### V3 New Modules Overview

| Module | Î™©Ï†Å | ÏúÑÏπò |
|--------|------|------|
| **WhiteningAdapter** | Task-agnostic feature normalization | Feature ‚Üí NF Ï†Ñ |
| **LightweightMSContext** | Multi-scale receptive field ÌôïÏû• | NF ÏûÖÎ†• Ï†Ñ |
| **DeepInvertibleAdapter (DIA)** | Task-specific nonlinear manifold adaptation | NF Ï∂úÎ†• ÌõÑ |
| **OrthogonalGradientProjection (OGP)** | Gradient projection to null space | Training loop |
| **TwoStageHybridRouter** | Prototype + Likelihood routing | Inference |

---

## V3-1: WhiteningAdapter

### Core Idea
Task Í∞Ñ feature distribution shift Î¨∏Ï†ú Ìï¥Í≤∞:
```
Task 0 features: mean=Œº‚ÇÄ, cov=Œ£‚ÇÄ
Task 1 features: mean=Œº‚ÇÅ, cov=Œ£‚ÇÅ  (Îã§Î•∏ Î∂ÑÌè¨)
```

**Solution**: Whitening ‚Üí Constrained De-whitening
```
x ‚Üí Whiten(x) ‚Üí z (zero mean, unit variance)
z ‚Üí ConstrainedDewhiten(z) ‚Üí x' (controlled distribution)
```

### Implementation
```python
# moleflow/models/adapters.py
class WhiteningAdapter(nn.Module):
    """
    Whitening-based Task Adapter (V3 Solution 3).

    Key Design:
    1. All tasks go through Whitening first (mean=0, std=1) via LayerNorm
    2. Task-specific de-whitening with constrained gamma/beta parameters
    3. Task 0 stays close to identity (anchor point)

    Parameters:
    - gamma: constrained to [gamma_min, gamma_max] via sigmoid
    - beta: constrained to [-beta_max, beta_max] via tanh
    """
    def __init__(self, channels: int, task_id: int = 0,
                 reference_mean=None, reference_std=None,
                 gamma_range: tuple = (0.5, 2.0), beta_max: float = 2.0):
        super().__init__()
        self.gamma_min, self.gamma_max = gamma_range
        self.beta_max = beta_max

        # Whitening layer (shared across all tasks, no learnable affine)
        self.whiten = nn.LayerNorm(channels, elementwise_affine=False)

        if task_id == 0:
            # Task 0: Start very close to identity
            # gamma ‚âà 1.0, beta ‚âà 0.0
            init_gamma_raw = -0.7 * torch.ones(1, 1, 1, channels)
            self.gamma_raw = nn.Parameter(init_gamma_raw)
            self.beta_raw = nn.Parameter(torch.zeros(1, 1, 1, channels))
            self.identity_reg_weight = 0.1  # Regularize toward identity
        else:
            # Task 1+: Learnable, initialized at midpoint
            self.gamma_raw = nn.Parameter(torch.zeros(1, 1, 1, channels))
            self.beta_raw = nn.Parameter(torch.zeros(1, 1, 1, channels))
            self.identity_reg_weight = 0.0

    @property
    def gamma(self):
        """Constrained gamma in [gamma_min, gamma_max]."""
        return self.gamma_min + (self.gamma_max - self.gamma_min) * torch.sigmoid(self.gamma_raw)

    @property
    def beta(self):
        """Constrained beta in [-beta_max, beta_max]."""
        return self.beta_max * torch.tanh(self.beta_raw)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        B, H, W, D = x.shape
        # 1. Whitening: normalize to N(0, 1)
        x_white = self.whiten(x.reshape(-1, D)).reshape(B, H, W, D)
        # 2. Task-specific de-whitening
        return self.gamma * x_white + self.beta

    def identity_regularization(self) -> torch.Tensor:
        """Regularization loss to keep Task 0 adapter close to identity."""
        if self.identity_reg_weight > 0:
            gamma_reg = ((self.gamma - 1.0) ** 2).mean()
            beta_reg = (self.beta ** 2).mean()
            return self.identity_reg_weight * (gamma_reg + beta_reg)
        return torch.tensor(0.0, device=self.gamma_raw.device)
```

### Key Design
1. **LayerNorm-based Whitening**: Task-agnostic normalization (no learnable params)
2. **Constrained Parameters**: sigmoid/tanhÎ°ú Î≤îÏúÑ Ï†úÌïú ‚Üí ÏïàÏ†ïÏ†Å ÌïôÏäµ
3. **Per-Task Adapter**: Í∞Å taskÎßàÎã§ Î≥ÑÎèÑ WhiteningAdapter (create_task_adapter factory Ìï®Ïàò ÏÇ¨Ïö©)
4. **Task 0 Identity Regularization**: Task 0Îäî identityÏóê Í∞ÄÍπùÍ≤å Ïú†ÏßÄ

### Command Line
```bash
python run_moleflow.py --use_whitening_adapter
```

---

## V3-2: LightweightMSContext (Multi-Scale Context)

### Core Idea
Í∏∞Ï°¥ NFÎäî patch Îã®ÏúÑ ÎèÖÎ¶Ω Ï≤òÎ¶¨ ‚Üí Ï£ºÎ≥Ä context Î¨¥Ïãú

**Solution**: Multi-scale dilated convolutionÏúºÎ°ú receptive field ÌôïÏû•
```
x ‚Üí [Conv_d1, Conv_d2, Conv_d4] ‚Üí concat ‚Üí fusion ‚Üí x + context
```

### Implementation
```python
# moleflow/models/ms_context.py
class LightweightMSContext(nn.Module):
    """
    Multi-scale context via dilated depthwise convolutions.

    Uses multiple dilation rates to capture context at different scales
    without significantly increasing parameters.
    """
    def __init__(self, channels, dilations=[1, 2, 4], kernel_size=3):
        self.dilated_convs = nn.ModuleList([
            nn.Conv2d(channels, channels, kernel_size,
                      padding=d*(kernel_size//2), dilation=d, groups=channels)
            for d in dilations
        ])
        self.fusion = nn.Conv2d(channels * len(dilations), channels, 1)
        self.gate = nn.Parameter(torch.zeros(1))  # Starts at 0.5 after sigmoid

    def forward(self, x):
        # x: (B, H, W, D) ‚Üí (B, D, H, W) for conv
        x_conv = x.permute(0, 3, 1, 2)

        # Multi-scale features
        ms_features = [conv(x_conv) for conv in self.dilated_convs]
        ms_concat = torch.cat(ms_features, dim=1)

        # Fusion and gating
        context = self.fusion(ms_concat).permute(0, 2, 3, 1)
        gate = torch.sigmoid(self.gate)

        return x + gate * context
```

### Key Design
1. **Depthwise Separable**: ÌååÎùºÎØ∏ÌÑ∞ Ìö®Ïú®Ï†Å
2. **Multiple Dilations**: d=1,2,4Î°ú Îã§ÏñëÌïú scale Ìè¨Ï∞©
3. **Learnable Gate**: ÌïôÏäµ Ï¥àÍ∏∞ ÏïàÏ†ïÏÑ±

### Command Line
```bash
python run_moleflow.py --use_ms_context
```

### ‚ö†Ô∏è Warning: WhiteningAdapter + MS-Context Ï∂©Îèå

Îëê Î™®ÎìàÏùÑ ÎèôÏãú ÏÇ¨Ïö© Ïãú ÌïôÏäµ Î∂àÏïàÏ†ï Î∞úÏÉù:
- LossÍ∞Ä ÏùåÏàòÎ°ú Î∞úÏÇ∞
- Task 0 ÏÑ±Îä• Í∏âÍ≤©Ìûà Ï†ÄÌïò

**ÏõêÏù∏**: Îëê Î™®Îìà Î™®Îëê NF ÏûÖÎ†• Ï†ÑÏóê featureÎ•º Î≥ÄÌôòÌïòÏó¨ distribution Ï∂©Îèå

**ÏûêÎèô Ìï¥Í≤∞**: `AblationConfig`ÏóêÏÑú ÏûêÎèôÏúºÎ°ú MS-Context ÎπÑÌôúÏÑ±Ìôî
```python
# ablation.py __post_init__()
if self.use_whitening_adapter and self.use_ms_context:
    print("‚ö†Ô∏è  Warning: use_whitening_adapter + use_ms_context Ï°∞Ìï©ÏùÄ ÌïôÏäµ Î∂àÏïàÏ†ï")
    self.use_ms_context = False
```

---

## V3-3: DeepInvertibleAdapter (DIA)

### Core Idea
Base NF Ï∂úÎ†• ÌõÑ task-specific nonlinear adaptation:
```
x ‚Üí Base NF ‚Üí z_base ‚Üí DIA_task ‚Üí z_final
```

**Why DIA?**
- LoRA: Linear adaptation (ÌëúÌòÑÎ†• Ï†úÌïú)
- DIA: Invertible nonlinear adaptation (Îçî Í∞ïÎ†•Ìïú manifold adaptation)

### Implementation
```python
# moleflow/models/lora.py
class DeepInvertibleAdapter(nn.Module):
    """
    Deep Invertible Adapter (DIA) - V3 Solution 1 (No Replay).

    Key Insight:
    Instead of linear LoRA (W + BA), we add a small task-specific Flow
    AFTER the base NF. This allows nonlinear manifold adaptation.

    Architecture:
    - Base NF: Frozen after Task 0 (extracts common features)
    - DIA: 1-2 lightweight coupling blocks per task (learns task-specific warping)

    Mathematical Formulation:
    - Base: z_base = f_base(x)
    - DIA:  z_final = f_DIA_t(z_base)
    - log p(x) = log p(z_final) + log|det J_base| + log|det J_DIA|
    """
    def __init__(self, channels: int, task_id: int, n_blocks: int = 2,
                 hidden_ratio: float = 0.5, clamp_alpha: float = 1.9):
        super().__init__()
        self.clamp_alpha = clamp_alpha
        hidden_dim = int(channels * hidden_ratio)

        # Build mini-flow: sequence of affine coupling blocks
        self.coupling_blocks = nn.ModuleList([
            AffineCouplingBlock(
                channels=channels,
                hidden_dim=hidden_dim,
                clamp_alpha=clamp_alpha,
                reverse=(i % 2 == 1)  # Alternate which half is transformed
            ) for i in range(n_blocks)
        ])
        self._initialize_near_identity()

    def _initialize_near_identity(self):
        """Initialize to near-identity transformation."""
        for block in self.coupling_blocks:
            nn.init.zeros_(block.s_net.layers[-1].weight)
            nn.init.zeros_(block.s_net.layers[-1].bias)
            nn.init.zeros_(block.t_net.layers[-1].weight)
            nn.init.zeros_(block.t_net.layers[-1].bias)

    def forward(self, x: torch.Tensor, reverse: bool = False):
        B, H, W, D = x.shape
        log_det = torch.zeros(B, H, W, device=x.device)
        blocks = reversed(self.coupling_blocks) if reverse else self.coupling_blocks

        for block in blocks:
            x, block_log_det = block(x, reverse=reverse)
            log_det = log_det + block_log_det
        return x, log_det


class AffineCouplingBlock(nn.Module):
    """Affine Coupling Block for DIA with clamped scale."""
    def __init__(self, channels: int, hidden_dim: int,
                 clamp_alpha: float = 1.9, reverse: bool = False):
        super().__init__()
        self.clamp_alpha = clamp_alpha
        self.reverse_split = reverse
        self.split_dim = channels // 2

        # Scale network: x1 -> s
        self.s_net = SimpleSubnet(self.split_dim, self.split_dim, hidden_dim)
        # Translation network: x1 -> t
        self.t_net = SimpleSubnet(self.split_dim, self.split_dim, hidden_dim)

    def forward(self, x: torch.Tensor, reverse: bool = False):
        B, H, W, D = x.shape
        if self.reverse_split:
            x2, x1 = x[..., :self.split_dim], x[..., self.split_dim:]
        else:
            x1, x2 = x[..., :self.split_dim], x[..., self.split_dim:]

        x1_flat = x1.reshape(-1, self.split_dim)
        s = self.s_net(x1_flat).reshape(B, H, W, self.split_dim)
        t = self.t_net(x1_flat).reshape(B, H, W, self.split_dim)
        s = self.clamp_alpha * torch.tanh(s / self.clamp_alpha)

        if not reverse:
            y2 = x2 * torch.exp(s) + t
            log_det = s.sum(dim=-1)
        else:
            y2 = (x2 - t) * torch.exp(-s)
            log_det = -s.sum(dim=-1)

        if self.reverse_split:
            return torch.cat([y2, x1], dim=-1), log_det
        return torch.cat([x1, y2], dim=-1), log_det


class SimpleSubnet(nn.Module):
    """Simple MLP subnet for DIA coupling blocks."""
    def __init__(self, in_dim: int, out_dim: int, hidden_dim: int):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(in_dim, hidden_dim), nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),
            nn.Linear(hidden_dim, out_dim)
        )
        # Initialize output layer to zero for identity start
        nn.init.zeros_(self.layers[-1].weight)
        nn.init.zeros_(self.layers[-1].bias)

    def forward(self, x):
        return self.layers(x)
```

### Integration in mole_nf.py
```python
class MoLESpatialAwareNF(nn.Module):
    def __init__(self, ...):
        # ...
        self.dia_adapters = nn.ModuleDict()  # Per-task DIA

    def add_task(self, task_id):
        # ...
        if self.use_dia:
            self.dia_adapters[str(task_id)] = DeepInvertibleAdapter(
                channels=self.embed_dim,
                task_id=task_id,
                n_blocks=self.dia_n_blocks,
                hidden_ratio=self.dia_hidden_ratio,
                clamp_alpha=self.clamp_alpha
            ).to(self.device)

    def forward(self, x, reverse=False):
        # Base NF forward
        z, logdet = self.flow(x)

        # DIA forward (applied AFTER base NF)
        if self.use_dia and self.current_task_id is not None:
            task_key = str(self.current_task_id)
            if task_key in self.dia_adapters:
                z, dia_logdet = self.dia_adapters[task_key](z, reverse=reverse)
                logdet = logdet + dia_logdet

        return z, logdet
```

### Command Line
```bash
python run_moleflow.py \
    --use_dia \
    --dia_n_blocks 2 \
    --dia_hidden_ratio 0.5
```

---

## V3-4: OrthogonalGradientProjection (OGP)

### Core Idea
Ïù¥Ï†Ñ taskÏóêÏÑú Ï§ëÏöîÌïú gradient Î∞©Ìñ•ÏùÑ Î≥¥Ï°¥:
```
‚àáL_new ‚Üí Project to null space of previous tasks ‚Üí ‚àáL_projected
```

**Gradient Projection**:
```
g' = g - Œ£·µ¢ (basis_i @ basis_i.T @ g)
```
where basis_i = important gradient directions from task i

### Implementation
```python
# moleflow/utils/replay.py
class OrthogonalGradientProjection:
    """
    Orthogonal Gradient Projection (OGP) - V3 No-Replay Solution.

    Key Idea:
    After learning Task t, compute the principal subspace of gradients
    (or features) that are important for that task. When learning Task t+1,
    project gradients to be orthogonal to this subspace, ensuring that
    updates don't interfere with previously learned knowledge.

    This is based on GPM (Gradient Projection Memory) from:
    "Continual Learning in Low-rank Orthogonal Subspaces", NeurIPS 2020

    Mathematical Formulation:
    1. After Task t: Compute U_t = SVD(G_t)[:, :k] where G_t is gradient matrix
    2. Store basis vectors (Vh transposed from SVD)
    3. For Task t+1: g' = g - basis @ (basis.T @ g) for each stored basis

    Advantages over Replay:
    - No data storage required
    - Memory: O(d √ó k) per task where k << d
    - Mathematically guarantees no interference in stored subspace
    """
    def __init__(self, threshold: float = 0.99, max_rank_per_task: int = 50,
                 device: str = 'cuda'):
        self.threshold = threshold
        self.max_rank_per_task = max_rank_per_task
        self.device = device

        # Store projection bases per parameter
        # param_name -> list of basis matrices (one per task)
        self.bases: Dict[str, List[torch.Tensor]] = {}
        self.is_initialized = False
        self.n_tasks = 0

    def compute_and_store_basis(self, model: nn.Module, data_loader,
                                 task_id: int, n_samples: int = 300):
        """
        Compute gradient subspace basis for completed task.
        Called AFTER training on a task is complete.
        """
        model.eval()
        gradient_matrices: Dict[str, List[torch.Tensor]] = {}

        n_processed = 0
        for batch in data_loader:
            if n_processed >= n_samples:
                break
            features = batch[0].to(self.device)
            batch_size = features.shape[0]

            model.zero_grad()
            log_prob = model.log_prob(features)
            loss = -log_prob.mean()
            loss.backward()

            for name, param in model.named_parameters():
                if param.requires_grad and param.grad is not None:
                    grad = param.grad.detach().flatten()
                    if name not in gradient_matrices:
                        gradient_matrices[name] = []
                    gradient_matrices[name].append(grad.clone())
            n_processed += batch_size

        # Compute SVD for each parameter's gradient matrix
        for name, grads in gradient_matrices.items():
            if len(grads) < 5:
                continue
            G = torch.stack(grads, dim=0)  # (n_samples, n_params)

            U, S, Vh = torch.linalg.svd(G, full_matrices=False)

            # Select top-k components based on variance threshold
            var_ratio = (S ** 2).cumsum(0) / (S ** 2).sum()
            k = min(
                (var_ratio < self.threshold).sum().item() + 1,
                self.max_rank_per_task,
                S.shape[0]
            )

            # Store basis vectors: Vh[:k, :].T gives (n_params, k)
            basis = Vh[:k, :].T  # (n_params, k)

            if name not in self.bases:
                self.bases[name] = []
            self.bases[name].append(basis.to(self.device))

        self.n_tasks = task_id + 1
        self.is_initialized = True

    def project_gradient(self, model: nn.Module):
        """
        Project current gradients to be orthogonal to stored subspaces.
        Call AFTER loss.backward() and BEFORE optimizer.step().
        """
        if not self.is_initialized:
            return

        for name, param in model.named_parameters():
            if not param.requires_grad or param.grad is None:
                continue
            if name not in self.bases:
                continue

            grad = param.grad.flatten()

            # Project out all stored subspaces for this parameter
            for basis in self.bases[name]:
                # basis: (n_params, k)
                # proj = basis @ (basis.T @ grad)
                proj = basis @ (basis.T @ grad)
                grad = grad - proj

            param.grad = grad.reshape(param.shape)

    def get_memory_usage(self) -> Dict[str, int]:
        """Get memory usage statistics."""
        total_elements = sum(b.numel() for bl in self.bases.values() for b in bl)
        return {
            'n_params': len(self.bases),
            'n_tasks': self.n_tasks,
            'total_elements': total_elements,
            'memory_mb': total_elements * 4 / (1024 * 1024)
        }
```

### Integration in Trainer
```python
# moleflow/trainer/continual_trainer.py
class MoLEContinualTrainer:
    def __init__(self, ...):
        if self.use_ogp:
            self.ogp = OrthogonalGradientProjection(
                threshold=self.ogp_threshold,
                max_rank_per_task=self.ogp_max_rank,
                device=device
            )

    def _train_fast_stage(self, task_id, ...):
        for batch in dataloader:
            loss.backward()

            # OGP: Project gradients for Task > 0
            if self.use_ogp and self.ogp is not None and self.ogp.is_initialized:
                self.ogp.project_gradient(self.nf_model)

            optimizer.step()

    def train_task(self, task_id, ...):
        # ... training code ...

        # Compute OGP basis AFTER task training completes
        if self.use_ogp and self.ogp is not None:
            self._compute_ogp_basis(task_id, train_loader)

    def _compute_ogp_basis(self, task_id, train_loader):
        """Compute and store OGP gradient basis for completed task."""
        # Creates FeatureDataLoader wrapper to provide features
        self.ogp.compute_and_store_basis(
            model=self.nf_model,
            data_loader=feature_loader,
            task_id=task_id,
            n_samples=self.ogp_n_samples
        )
```

### Command Line
```bash
python run_moleflow.py \
    --use_ogp \
    --ogp_threshold 0.99 \
    --ogp_max_rank 50 \
    --ogp_n_samples 300
```

---

## V3-5: TwoStageHybridRouter

### Core Idea
Í∏∞Ï°¥ RouterÎäî Prototype matchingÎßå ÏÇ¨Ïö© ‚Üí Ïú†ÏÇ¨Ìïú task Íµ¨Î∂Ñ Ïñ¥Î†§ÏõÄ

**Solution**: Two-stage routing
1. **Stage 1 (Fast)**: Prototype filtering ‚Üí Top-K candidates
2. **Stage 2 (Accurate)**: NF likelihood comparison ‚Üí Final selection

### Implementation
```python
# moleflow/models/routing.py
class TwoStageHybridRouter(nn.Module):
    """
    Two-stage routing: Prototype filtering + Likelihood refinement.

    Stage 1: Mahalanobis distance to prototypes ‚Üí Top-K candidates
    Stage 2: NF log-likelihood for final selection
    """
    def __init__(self, nf_model, top_k=2):
        self.prototype_router = PrototypeRouter()
        self.nf_model = nf_model
        self.top_k = top_k

    def forward(self, features):
        # Stage 1: Prototype distances
        distances = self.prototype_router.compute_distances(features)
        top_k_tasks = distances.argsort()[:self.top_k]

        # Stage 2: NF likelihood
        likelihoods = []
        for task_id in top_k_tasks:
            self.nf_model.set_task(task_id)
            z, logdet = self.nf_model(features)
            log_prob = -0.5 * (z**2).sum() + logdet
            likelihoods.append(log_prob)

        # Select task with highest likelihood
        best_idx = torch.stack(likelihoods).argmax()
        return top_k_tasks[best_idx]
```

### Command Line
```bash
python run_moleflow.py \
    --use_hybrid_router \
    --router_top_k 2
```

---

## V3 Experiment Results

### Ablation Study (leather ‚Üí grid ‚Üí transistor)

| Configuration | Image AUC | Pixel AUC | Notes |
|---------------|-----------|-----------|-------|
| **Baseline (V2)** | 0.8168 | 0.9166 | - |
| DIA only | 0.8217 | 0.9277 | +0.5% Image, +1.1% Pixel |
| OGP only | 0.8180 | 0.9161 | Minimal change |
| **DIA + OGP** | **0.8226** | **0.9231** | **Best combination** |
| WhiteningAdapter only | (Ïã§Ìóò Ï§ë) | (Ïã§Ìóò Ï§ë) | - |
| MS-Context only | (Ïã§Ìóò Ï§ë) | (Ïã§Ìóò Ï§ë) | - |
| All V3 (conflict) | 0.4471 | 0.5527 | ‚ùå Ïã§Ìå® (Ï∂©Îèå) |

### Key Findings
1. **DIA + OGP**: Best performance without replay
2. **WhiteningAdapter + MS-Context**: Ï°∞Ìï© Ïãú Ï∂©Îèå ‚Üí ÏûêÎèô ÎπÑÌôúÏÑ±Ìôî Ï≤òÎ¶¨
3. **DIA > OGP**: DIAÍ∞Ä Îçî ÌÅ∞ ÏÑ±Îä• Ìñ•ÏÉÅ Í∏∞Ïó¨

---

## V3 File Changes Summary

| File | Changes |
|------|---------|
| `moleflow/models/adapters.py` | **WhiteningAdapter** Ï∂îÍ∞Ä (line 417-531), `create_task_adapter` factoryÏóê "whitening" Î™®Îìú Ï∂îÍ∞Ä |
| `moleflow/models/lora.py` | **LightweightMSContext** (line 223-366), **TaskConditionedMSContext** (line 373-701), **DeepInvertibleAdapter** + AffineCouplingBlock + SimpleSubnet (line 708-908) Ï∂îÍ∞Ä |
| `moleflow/utils/replay.py` | **OrthogonalGradientProjection** (line 512-687), GradientProjectionHook, FeatureBank, DistillationLoss, EWC Ï∂îÍ∞Ä |
| `moleflow/models/mole_nf.py` | DIA integration (`dia_adapters`), WhiteningAdapter/MSContext/TaskConditionedMSContext ÌÜµÌï©, V3 config options Ï≤òÎ¶¨ |
| `moleflow/config/ablation.py` | V3 options: `use_dia`, `use_ogp`, `use_whitening_adapter`, `use_ms_context`, `use_task_conditioned_ms_context`, `ogp_*` params, `dia_*` params |
| `moleflow/trainer/continual_trainer.py` | OGP integration: `_compute_ogp_basis()`, `ogp.project_gradient()` in training loop |
| `run_moleflow.py` | V3 CLI arguments, config saving |

---

## V3 Command Line Reference

```bash
# Full V3 with recommended settings (DIA + OGP)
python run_moleflow.py \
    --use_dia \
    --dia_n_blocks 2 \
    --use_ogp \
    --ogp_threshold 0.99 \
    --ogp_max_rank 50 \
    --experiment_name Version3-DIA_OGP

# WhiteningAdapter only
python run_moleflow.py \
    --use_whitening_adapter \
    --experiment_name Version3-WhiteningAdapter

# MS-Context only (automatically disabled if WhiteningAdapter is on)
python run_moleflow.py \
    --use_ms_context \
    --experiment_name Version3-MSContext

# All options with diagnostics
python run_moleflow.py \
    --run_diagnostics \
    --use_dia \
    --use_ogp \
    --use_whitening_adapter \
    --experiment_name Version3-All
```

---

## V3 Problem Analysis 
--
  Ïã¨Ï∏µ Î∂ÑÏÑù Í≤∞Í≥º

  1. ÌïµÏã¨ Î∞úÍ≤¨: Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞ Î¨∏Ï†ú

  spatial_mixerÍ∞Ä Î™®Îì† taskÏóêÏÑú Í≥µÏú†ÎêòÍ≥† ÌïôÏäµÎê©ÎãàÎã§:

  # mole_nf.py:529-530
  if self.spatial_mixer is not None and not reverse:
      x = self.spatial_mixer(x)

  # mole_nf.py:721-722 (get_fast_params)
  if self.spatial_mixer is not None:
      params.extend(self.spatial_mixer.parameters())  # Î™®Îì† taskÏóêÏÑú ÌïôÏäµ!

  Forward Í≤ΩÎ°ú:
  Input ‚Üí WhiteningAdapter[task] ‚Üí SpatialMixer[SHARED] ‚Üí BaseNF ‚Üí DIA[task] ‚Üí Output
                                         ‚Üë
                              Ïù¥Í≤ÉÏù¥ Îß§ taskÎßàÎã§ ÏóÖÎç∞Ïù¥Ìä∏Îê®!

  ---
  2. Task 0 Î∂ïÍ¥¥ Î©îÏª§ÎãàÏ¶ò ÏÉÅÏÑ∏ Î∂ÑÏÑù

  Phase 1: Task 0 ÌïôÏäµ (Ï†ïÏÉÅ)

  leather features ‚Üí WhiteningAdapter_0 ‚Üí SpatialMixer_v0 ‚Üí BaseNF ‚Üí DIA_0
                                                ‚Üë
                                       Ïù¥ ÏãúÏ†êÏùò ÌååÎùºÎØ∏ÌÑ∞
  - Image AUC = 1.0 Îã¨ÏÑ±

  Phase 2: Task 1-6 ÌïôÏäµ (Ï†êÏßÑÏ†Å ÎìúÎ¶¨ÌîÑÌä∏)

  grid/transistor/... ‚Üí WhiteningAdapter_k ‚Üí SpatialMixer_v1...v6 ‚Üí BaseNF ‚Üí DIA_k
                                                    ‚Üë
                                           Îß§ taskÎßàÎã§ ÏóÖÎç∞Ïù¥Ìä∏
  - leather ÌèâÍ∞Ä Ïãú: SpatialMixer_v6Ïù¥ ÏÇ¨Ïö©Îê® (ÏõêÎûò v0Í≥º Îã§Î¶Ñ)
  - ÌïòÏßÄÎßå OGPÍ∞Ä Ïñ¥Îäê Ï†ïÎèÑ gradientÎ•º Ï†úÌïúÌïòÏó¨ ÎìúÎ¶¨ÌîÑÌä∏ ÏµúÏÜåÌôî
  - leather Image AUC: 1.0 ‚Üí 0.99 (ÎØ∏ÎØ∏Ìïú Í∞êÏÜå)

  Phase 3: Task 7-8 ÌïôÏäµ (Î∂ïÍ¥¥ ÏãúÏûë)

  metal_nut/screw ‚Üí WhiteningAdapter_k ‚Üí SpatialMixer_v7,v8 ‚Üí BaseNF ‚Üí DIA_k
                                                ‚Üë
                                        OGP Ï†úÏïΩÏù¥ Ìè¨Ìôî ÏÉÅÌÉú
  - OGPÏùò orthogonal Í≥µÍ∞ÑÏù¥ Ï†êÏ†ê Ï§ÑÏñ¥Îì¶
  - SpatialMixerÍ∞Ä ÏÉàÎ°úÏö¥ taskÏóê Ï†ÅÏùëÌïòÎ†§Î©¥ Ïù¥Ï†Ñ subspaceÏóêÏÑú Î≤óÏñ¥ÎÇòÏïº Ìï®
  - leather Image AUC: 0.99 ‚Üí 0.78 ‚Üí 0.55 (Í∏âÍ≤©Ìïú Í∞êÏÜå)

  Phase 4: Task 9+ ÌïôÏäµ (ÏôÑÏ†Ñ Î∂ïÍ¥¥)

  - OGP Ï†úÏïΩ ÌïòÏóêÏÑúÎèÑ SpatialMixerÍ∞Ä Í≥ÑÏÜç Î≥ÄÍ≤ΩÎê®
  - leatherÏùò representationÏù¥ ÏôÑÏ†ÑÌûà ÏÜêÏÉÅÎê®
  - leather Image AUC: 0.07 (Í±∞Ïùò random)

  ---
  3. ÏïåÌååÎ≤≥ ÏàúÏÑúÏóêÏÑú Îçî Îπ†Î•∏ Î∂ïÍ¥¥ ÏõêÏù∏

  | ÎπÑÍµê   | ÏõêÎûò ÏàúÏÑú        | ÏïåÌååÎ≤≥ ÏàúÏÑú         |
  |--------|------------------|---------------------|
  | Task 0 | leather (ÌÖçÏä§Ï≤ò) | bottle (ÌòïÏÉÅ)       |
  | Task 2 | transistor       | capsule             |
  | Ïú†ÏÇ¨ÏÑ± | ÎÇÆÏùå             | ÎÜíÏùå (Îëò Îã§ ÏõêÌÜµÌòï) |

  bottle ‚Üí capsule Ïú†ÏÇ¨ÏÑ± Î¨∏Ï†ú:
  1. bottleÏùò featureÎ°ú ÌïôÏäµÎêú SpatialMixer
  2. capsule ÌïôÏäµ Ïãú ÎπÑÏä∑Ìïú feature Í≥µÍ∞ÑÏóêÏÑú Í≤ΩÏüÅ
  3. OGPÍ∞Ä Î≥¥Ï°¥ÌïòÎ†§Îäî subspaceÏôÄ ÏÉà taskÍ∞Ä ÌïÑÏöîÌïú Í≥µÍ∞ÑÏù¥ ÌÅ¨Í≤å Ï§ëÏ≤©
  4. Í≤∞Í≥º: bottleÏùò representationÏù¥ 2Í∞ú task ÎßåÏóê ÏÜêÏÉÅÎê®

  leather ‚Üí grid ÎπÑÏú†ÏÇ¨ÏÑ±:
  1. leatherÏùò ÌÖçÏä§Ï≤ò featureÎ°ú ÌïôÏäµÎêú SpatialMixer
  2. grid (Ìå®ÌÑ¥), transistor (ÌòïÏÉÅ) Îì±ÏùÄ Îã§Î•∏ feature Í≥µÍ∞Ñ
  3. OGPÍ∞Ä Î≥¥Ï°¥ÌïòÎäî subspaceÏôÄ ÏÉà task Í≥µÍ∞ÑÏùò Ï§ëÏ≤©Ïù¥ Ï†ÅÏùå
  4. Í≤∞Í≥º: 7Í∞ú taskÍπåÏßÄ ÏÉÅÎåÄÏ†ÅÏúºÎ°ú ÏïàÏ†ï

  ---
  4. Image AUC vs Pixel AUC Ï∞®Ïù¥ Î∂ÑÏÑù

  leather (ÏõêÎûò ÏàúÏÑú)

  | Metric    | Task 0 | Task 14 | ÏÑ§Î™Ö     |
  |-----------|--------|---------|----------|
  | Pixel AUC | 0.97   | 0.66    | 32% ÌïòÎùΩ |
  | Image AUC | 1.00   | 0.07    | 93% ÌïòÎùΩ |

  Ìï¥ÏÑù:
  - Pixel-levelÏùÄ patchÎ≥Ñ anomaly score = -log p(z) - log|det J|
  - Image-levelÏùÄ patch scoresÏùò 99th percentile
  - Pixel AUC > 0.5: patchÎì§ Í∞ÑÏùò ÏÉÅÎåÄÏ†Å ÏàúÏÑúÎäî Ïñ¥Îäê Ï†ïÎèÑ Ïú†ÏßÄÎê®
  - Image AUC ‚âà 0: Î™®Îì† Ïù¥ÎØ∏ÏßÄÏùò 99th percentile Í∞íÏù¥ Ï†ÑÏ≤¥Ï†ÅÏúºÎ°ú shiftÎêòÏñ¥ normal/anomaly Íµ¨Î∂Ñ Î∂àÍ∞Ä

  ÏùòÎØ∏: SpatialMixer Î≥ÄÍ≤ΩÏúºÎ°ú Ï†ÑÏ≤¥ score Î∂ÑÌè¨Í∞Ä shiftÎê®. Í∞úÎ≥Ñ patchÏùò ÏÉÅÎåÄÏ†Å Ï∞®Ïù¥Îäî Ïú†ÏßÄÎêòÏßÄÎßå, image-level ÌÜµÍ≥ÑÍ∞Ä Î¨¥ÏùòÎØ∏Ìï¥Ïßê.

  bottle (ÏïåÌååÎ≤≥ ÏàúÏÑú)

  | Metric    | Task 0 | Task 14 | ÏÑ§Î™Ö         |
  |-----------|--------|---------|--------------|
  | Pixel AUC | 0.94   | 0.12    | Random Ïù¥Ìïò! |
  | Image AUC | 1.00   | 0.30    | 70% ÌïòÎùΩ     |

  Ìï¥ÏÑù:
  - Pixel AUC = 0.12 < 0.5: Î™®Îç∏Ïù¥ Î∞òÎåÄÎ°ú ÏòàÏ∏°
  - Anomaly patchÏóê ÎÇÆÏùÄ score, Normal patchÏóê ÎÜíÏùÄ score
  - Ïù¥Îäî Îã®ÏàúÌïú distribution shiftÍ∞Ä ÏïÑÎãàÎùº representation ÏûêÏ≤¥Ïùò inversion

  ÏùòÎØ∏: SpatialMixerÍ∞Ä bottleÏùò feature spaceÎ•º ÏôÑÏ†ÑÌûà Îí§ÏßëÏñ¥Î≤ÑÎ¶º. Îçî Ïã¨Í∞ÅÌïú ÏÜêÏÉÅ.

  ---
  5. OGPÏùò ÌïúÍ≥Ñ

  OGPÎäî gradientÎ•º Ïù¥Ï†Ñ taskÏùò Ï§ëÏöî subspaceÏóê orthogonalÌïòÍ≤å Ìà¨ÏòÅ:

  g' = g - Œ£(basis_i @ basis_i^T @ g)

  Î¨∏Ï†úÏ†ê:
  1. ÎàÑÏ†Å Ï†úÏïΩ: 15Í∞ú task √ó 50 rank = 750Í∞úÏùò orthogonal Î∞©Ìñ• Ï†úÏïΩ
  2. Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞Ïóê Ï†ÅÏö©: SpatialMixerÏùò gradientÎèÑ Ìà¨ÏòÅÎê®
  3. Î∂àÏôÑÏ†ÑÌïú Î≥¥Ìò∏: Ìà¨ÏòÅ ÌõÑÏóêÎèÑ ÎÇ®ÏùÄ gradientÍ∞Ä Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞Î•º Î≥ÄÍ≤Ω

  Task 0 basis: [v1, v2, ..., v50]  (leather Ï§ëÏöî Î∞©Ìñ•)
  Task 1 ÌïôÏäµ: g' = g - proj(g, Task0_basis)
                ‚Üë
         Ïù¥ g'Í∞Ä SpatialMixerÎ•º Î≥ÄÍ≤Ω ‚Üí leather ÏÜêÏÉÅ

  ---
  6. ÌïµÏã¨ Î¨∏Ï†ú ÏöîÏïΩ

  | Î¨∏Ï†ú                | ÏÑ§Î™Ö                                  | Ïã¨Í∞ÅÎèÑ      |
  |---------------------|---------------------------------------|-------------|
  | Í≥µÏú† SpatialMixer   | Î™®Îì† taskÏóêÏÑú ÌïôÏäµÎêòÏñ¥ Ïù¥Ï†Ñ task ÏÜêÏÉÅ | üî¥ Critical |
  | OGP ÎàÑÏ†Å Ï†úÏïΩ       | Task Ïàò Ï¶ùÍ∞Ä Ïãú ÌïôÏäµ Í≥µÍ∞Ñ Ï∂ïÏÜå        | üü† High     |
  | ÌÅ¥ÎûòÏä§ ÏàúÏÑú ÏùòÏ°¥ÏÑ±  | Ïú†ÏÇ¨ ÌÅ¥ÎûòÏä§Í∞Ä Ïó∞ÏÜçÎêòÎ©¥ Îçî Îπ†Î•∏ Î∂ïÍ¥¥   | üü° Medium   |
  | Task 0 Base NF Ìé∏Ìñ• | Ï≤´ taskÏóêÎßå ÏµúÏ†ÅÌôîÎêú Base NF          | üü° Medium   |

  ---
  7. RoutingÏù¥ 100% Ï†ïÌôïÌïúÎç∞ÎèÑ Î∂ïÍ¥¥ÌïòÎäî Ïù¥Ïú†

  Evaluation: leather test image
    ‚Üì
  Router: "This is leather" (100% Ï†ïÌôï)
    ‚Üì
  WhiteningAdapter_0: leatherÏö© adapter ‚úì
    ‚Üì
  SpatialMixer: Task 14 Ïù¥ÌõÑ Î≤ÑÏ†Ñ ‚úó  ‚Üê Ïó¨Í∏∞ÏÑú Î¨∏Ï†ú!
    ‚Üì
  BaseNF + LoRA_0: leatherÏö© ‚úì
    ‚Üì
  DIA_0: leatherÏö© ‚úì
    ‚Üì
  Wrong output due to SpatialMixer mismatch

  Í≤∞Î°†: Task-specific Ïª¥Ìè¨ÎÑåÌä∏Îäî Ï†ïÏÉÅÏù¥ÏßÄÎßå, Í≥µÏú† Ïª¥Ìè¨ÎÑåÌä∏(SpatialMixer)Ïùò ÎìúÎ¶¨ÌîÑÌä∏Í∞Ä Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏ÏùÑ Ïò§ÏóºÏãúÌÇ¥.

---

## V3 Í∑ºÎ≥∏Ï†Å Î¨∏Ï†úÏôÄ Ìï¥Í≤∞ Î∞©Ìñ•

### Í∑ºÎ≥∏Ï†Å Î¨∏Ï†ú ÏßÑÎã®

V3Ïùò Í∞ÄÏ†ï:
> "Task 0ÏóêÏÑú ÌïôÏäµÎêú Base NFÍ∞Ä Î™®Îì† taskÏóê Î≤îÏö©Ï†ÅÏúºÎ°ú Ï†ÅÏö© Í∞ÄÎä•ÌïòÍ≥†, LoRA/DIAÎ°ú task-specific adaptationÎßå ÌïòÎ©¥ ÎêúÎã§"

**Ïù¥ Í∞ÄÏ†ïÏù¥ ÌãÄÎ¶∞ Ïù¥Ïú†:**

1. **Base NFÏùò Î≥∏ÏßàÏ†Å Ìé∏Ìñ•**
   - Base NFÎäî Task 0 (leather ÎòêÎäî bottle)Ïùò "normal = Î¨¥Í≤∞Ìï®" Î∂ÑÌè¨Îßå ÌïôÏäµ
   - Îã§Î•∏ taskÏùò normal distributionÍ≥º Í∑ºÎ≥∏Ï†ÅÏúºÎ°ú Îã§Î¶Ñ
   - LoRA/DIAÎäî "fine-tuning"Ïùº Îøê, transformation ÏûêÏ≤¥Î•º Î∞îÍøÄ Ïàò ÏóÜÏùå

2. **Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞Ïùò ÏπòÎ™ÖÏ†Å ÏòÅÌñ•**
   - SpatialMixerÍ∞Ä Î™®Îì† taskÏóêÏÑú ÌïôÏäµÎê®
   - OGPÎäî gradientÎ•º Ï†úÌïúÌï† Îøê, ÏôÑÏ†ÑÌïú Î≥¥Ìò∏ Î∂àÍ∞Ä
   - Task Ïàò Ï¶ùÍ∞Ä Ïãú OGP Ï†úÏïΩ Í≥µÍ∞Ñ Ìè¨Ìôî ‚Üí Ïù¥Ï†Ñ task ÏÜêÏÉÅ

3. **LoRA/DIAÏùò ÌëúÌòÑÎ†• ÌïúÍ≥Ñ**
   - LoRA: `W + BA` (Ï†ÄÏ∞®Ïõê linear adaptation)
   - DIA: ÏûëÏùÄ flow block (2 coupling layers)
   - Base NFÍ∞Ä ÏûòÎ™ªÎêú Î≥ÄÌôòÏùÑ ÌïòÎ©¥ Ïù¥Î•º Î≥¥Ï†ïÌïòÍ∏∞ Ïñ¥Î†§ÏõÄ

### Í∞ÄÎä•Ìïú Ìï¥Í≤∞ Î∞©Ìñ•

| Ï†ëÍ∑ºÎ≤ï | ÏÑ§Î™Ö | Ïû•Ï†ê | Îã®Ï†ê |
|--------|------|------|------|
| **ÏÇ¨Ï†ÑÌïôÏäµ Base NF** | Îã§ÏñëÌïú domainÏóêÏÑú Base NF ÏÇ¨Ï†ÑÌïôÏäµ | Task-agnostic ÌëúÌòÑ | ÏÇ¨Ï†ÑÌïôÏäµ Îç∞Ïù¥ÌÑ∞ ÌïÑÏöî |
| **ÏôÑÏ†Ñ Î∂ÑÎ¶¨** | Î™®Îì† trainable ÌååÎùºÎØ∏ÌÑ∞ task-specific | Í∞ÑÏÑ≠ ÏõêÏ≤ú Ï∞®Îã® | Î©îÎ™®Î¶¨ Ï¶ùÍ∞Ä |
| **Replay Í∏∞Î∞ò** | Ïù¥Ï†Ñ task Îç∞Ïù¥ÌÑ∞ ÏùºÎ∂Ä Ï†ÄÏû• | ÏßÅÏ†ëÏ†Å forgetting Î∞©ÏßÄ | Privacy, Ï†ÄÏû• ÎπÑÏö© |

### Ï±ÑÌÉù Î∞©Ìñ•: ÏôÑÏ†Ñ Î∂ÑÎ¶¨ (Complete Separation)

**ÏÑ†ÌÉù Ïù¥Ïú†:**
1. Í∑ºÎ≥∏ ÏõêÏù∏(Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞ ÎìúÎ¶¨ÌîÑÌä∏)ÏùÑ ÏõêÏ≤ú Ï∞®Îã®
2. Ï∂îÍ∞Ä Îç∞Ïù¥ÌÑ∞ ÏàòÏßë/Ï†ÄÏû• Î∂àÌïÑÏöî
3. Íµ¨ÌòÑ Î≥µÏû°ÎèÑ ÎÇÆÏùå
4. ÌôïÏû•ÏÑ± Î≥¥Ïû• (task Ïàò Ï¶ùÍ∞ÄÏóêÎèÑ ÏïàÏ†ï)

---

## V4 - Complete Separation Architecture

### ÌïµÏã¨ ÏõêÏπô
> "Î™®Îì† ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞Îäî task-specificÏù¥Ïñ¥Ïïº ÌïúÎã§"

### Architecture Overview

```
V3 (Î¨∏Ï†ú):
Input ‚Üí WhiteningAdapter[task] ‚Üí SpatialMixer[SHARED+Trained] ‚Üí BaseNF[frozen] + LoRA[task] ‚Üí DIA[task] ‚Üí Output
                                         ‚Üë
                                    Î™®Îì† taskÏóêÏÑú ÌïôÏäµ ‚Üí ÎìúÎ¶¨ÌîÑÌä∏

V4 (Ìï¥Í≤∞):
Input ‚Üí WhiteningAdapter[task] ‚Üí SpatialMixer[FROZEN] ‚Üí BaseNF[frozen] + LoRA[task] ‚Üí DIA[task] ‚Üí Output
                                         ‚Üë
                                    Task 0 Ïù¥ÌõÑ ÏôÑÏ†Ñ ÎèôÍ≤∞
```

### ÌïµÏã¨ Î≥ÄÍ≤ΩÏÇ¨Ìï≠

| Ïª¥Ìè¨ÎÑåÌä∏ | V3 | V4 | Î≥ÄÍ≤Ω Ïù¥Ïú† |
|----------|-----|-----|----------|
| **SpatialMixer** | Î™®Îì† taskÏóêÏÑú ÌïôÏäµ | Task 0 Ïù¥ÌõÑ freeze | Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞ ÎìúÎ¶¨ÌîÑÌä∏ Î∞©ÏßÄ |
| **OGP** | ÌôúÏÑ±Ìôî | Ï†úÍ±∞ (Î∂àÌïÑÏöî) | Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞ ÏóÜÏùå ‚Üí Ìà¨ÏòÅ Î∂àÌïÑÏöî |
| **WhiteningAdapter** | taskÎ≥Ñ | taskÎ≥Ñ (Ïú†ÏßÄ) | Ïù¥ÎØ∏ ÏôÑÏ†Ñ Î∂ÑÎ¶¨Îê® |
| **LoRA** | taskÎ≥Ñ | taskÎ≥Ñ (Ïú†ÏßÄ) | Ïù¥ÎØ∏ ÏôÑÏ†Ñ Î∂ÑÎ¶¨Îê® |
| **DIA** | taskÎ≥Ñ | taskÎ≥Ñ (Ïú†ÏßÄ) | Ïù¥ÎØ∏ ÏôÑÏ†Ñ Î∂ÑÎ¶¨Îê® |

### ÌïôÏäµ ÌîÑÎ°úÌÜ†ÏΩú

**Task 0 (Base Training)**:
```python
# ÌïôÏäµ ÎåÄÏÉÅ: SpatialMixer + BaseNF + LoRA_0 + WhiteningAdapter_0 + DIA_0
trainable = [
    spatial_mixer.parameters(),      # Task 0ÏóêÏÑúÎßå ÌïôÏäµ
    base_nf.parameters(),            # Task 0ÏóêÏÑúÎßå ÌïôÏäµ
    lora_adapters["0"].parameters(),
    whitening_adapters["0"].parameters(),
    dia_adapters["0"].parameters()
]
```

**Task 1+ (Adapter Only)**:
```python
# ÌïôÏäµ ÎåÄÏÉÅ: LoRA_t + WhiteningAdapter_t + DIA_t (Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞ ÏôÑÏ†Ñ freeze)
trainable = [
    lora_adapters[str(task_id)].parameters(),
    whitening_adapters[str(task_id)].parameters(),
    dia_adapters[str(task_id)].parameters()
]
# SpatialMixer, BaseNFÎäî ÏôÑÏ†Ñ freeze
```

### Íµ¨ÌòÑ Î≥ÄÍ≤ΩÏÇ¨Ìï≠

#### 1. mole_nf.py - get_fast_params() ÏàòÏ†ï

**Before (V3)**:
```python
def get_fast_params(self, task_id: int) -> List[nn.Parameter]:
    params = []
    # ... LoRA, WhiteningAdapter, DIA params ...

    # SpatialMixerÍ∞Ä Î™®Îì† taskÏóêÏÑú ÌïôÏäµÎê® ‚Üê Î¨∏Ï†ú!
    if self.spatial_mixer is not None:
        params.extend(self.spatial_mixer.parameters())

    return params
```

**After (V4)**:
```python
def get_fast_params(self, task_id: int) -> List[nn.Parameter]:
    params = []
    # ... LoRA, WhiteningAdapter, DIA params ...

    # V4: SpatialMixerÎäî Task 0ÏóêÏÑúÎßå ÌïôÏäµ, Ïù¥ÌõÑ freeze
    if self.spatial_mixer is not None and task_id == 0:
        params.extend(self.spatial_mixer.parameters())

    return params
```

#### 2. continual_trainer.py - OGP Ï†úÍ±∞

**V4ÏóêÏÑú OGPÍ∞Ä Î∂àÌïÑÏöîÌïú Ïù¥Ïú†:**
- OGPÎäî "Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞"Ïùò gradientÎ•º Ìà¨ÏòÅÌïòÏó¨ Ïù¥Ï†Ñ task Î≥¥Ìò∏
- V4ÏóêÏÑúÎäî Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞Í∞Ä Î™®Îëê frozen ‚Üí Î≥¥Ìò∏Ìï† ÎåÄÏÉÅ ÏóÜÏùå
- OGP Ïó∞ÏÇ∞ Ïò§Î≤ÑÌó§Îìú Ï†úÍ±∞ ‚Üí ÌïôÏäµ ÏÜçÎèÑ Ìñ•ÏÉÅ

```python
# V4: OGP ÎπÑÌôúÏÑ±Ìôî
if self.use_ogp:
    warnings.warn("V4 Complete Separation: OGP is unnecessary and will be disabled")
    self.use_ogp = False
```

#### 3. run.sh - V4 Ïã§Ìóò ÏÑ§Ï†ï

```bash
# V4: Complete Separation (WhiteningAdapter + DIA, no OGP, frozen SpatialMixer)
python run_moleflow.py \
    --task_classes leather grid transistor carpet zipper hazelnut \
                   toothbrush metal_nut screw wood tile capsule pill cable bottle \
    --use_whitening_adapter \
    --use_dia \
    --dia_n_blocks 2 \
    --no_ogp \                  # V4: OGP ÎπÑÌôúÏÑ±Ìôî
    --freeze_spatial_mixer \    # V4: SpatialMixer Task 0 Ïù¥ÌõÑ freeze
    --experiment_name Version4-CompleteSeparation
```

### ÏòàÏÉÅ Í≤∞Í≥º

| ÏßÄÌëú | V3 (15 classes) | V4 ÏòàÏÉÅ | Í∑ºÍ±∞ |
|------|-----------------|---------|------|
| Task 0 Image AUC | 0.07~0.30 | 0.90+ | SpatialMixer ÎìúÎ¶¨ÌîÑÌä∏ ÏóÜÏùå |
| Mean Image AUC | 0.72 | 0.85+ | Î™®Îì† task ÏïàÏ†ï |
| Routing Acc | 99.76% | 99%+ | Ïú†ÏßÄ (RouterÎäî Î≥ÄÍ≤Ω ÏóÜÏùå) |
| ÌïôÏäµ ÏÜçÎèÑ | 1x | 1.2x+ | OGP Ïó∞ÏÇ∞ Ï†úÍ±∞ |

### V4 Íµ¨ÌòÑ Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏

- [x] `mole_nf.py`: `get_fast_params()`ÏóêÏÑú SpatialMixer task_id Ï°∞Í±¥ Ï∂îÍ∞Ä
  - Line 720-725: `if self.spatial_mixer is not None and task_id == 0:`
- [x] `mole_nf.py`: `freeze_fast_params()` Task 0 Ï°∞Í±¥ Ï∂îÍ∞Ä
  - Line 759-762: SpatialMixer freeze only for Task 0
- [x] `mole_nf.py`: `unfreeze_fast_params()` Task 0 Ï°∞Í±¥ Ï∂îÍ∞Ä
  - Line 794-797: SpatialMixer unfreeze only for Task 0
- [x] `run.sh`: V4 Ïã§Ìóò Ïä§ÌÅ¨Î¶ΩÌä∏ Ï∂îÍ∞Ä
  - `--use_whitening_adapter --use_dia` (no OGP)
  - All 15 classes in alphabetical order

**Note**: Î≥ÑÎèÑ config ÏòµÏÖò Î∂àÌïÑÏöî - `task_id == 0` Ï°∞Í±¥ÏúºÎ°ú ÏûêÎèô Ï≤òÎ¶¨Îê®

### V4 File Changes Summary

| File | Changes |
|------|---------|
| `moleflow/models/mole_nf.py` | `get_fast_params()`, `freeze_fast_params()`, `unfreeze_fast_params()` - SpatialMixerÎäî task_id == 0Ïùº ÎïåÎßå ÌïôÏäµ |
| `run.sh` | V4 Ïã§Ìóò Ïä§ÌÅ¨Î¶ΩÌä∏: `Version4-CompleteSeparation_all_classes_alphabet` |

---

## V4 Experiment Results (15 Classes)

### Catastrophic Forgetting Ìï¥Í≤∞ ‚úÖ

| ÏàúÏÑú | Task 0 | V3 After Task 14 | V4 After Task 14 | Í∞úÏÑ† |
|------|--------|------------------|------------------|------|
| Original | leather | 0.07 (-93%) | **1.00 (0%)** | ‚úÖ ÏôÑÏ†Ñ Ìï¥Í≤∞ |
| Alphabet | bottle | 0.30 (-70%) | **0.999 (-0.08%)** | ‚úÖ ÏôÑÏ†Ñ Ìï¥Í≤∞ |

### Ï†ÑÏ≤¥ ÏÑ±Îä• ÎπÑÍµê

| ÏßÄÌëú | V3 Original | V4 Original | V4 Alphabet |
|------|-------------|-------------|-------------|
| Mean Image AUC | 0.7716 | **0.8636** | 0.8564 |
| Mean Pixel AUC | 0.9009 | **0.9272** | 0.9245 |
| Routing Acc | 99.76% | 99.76% | 99.76% |

**V4 vs V3: Mean Image AUC +12% Ìñ•ÏÉÅ**

### ÌÅ¥ÎûòÏä§Î≥Ñ ÏÉÅÏÑ∏ Í≤∞Í≥º (V4 Original Order)

| Class | Task ID | Image AUC | Pixel AUC | Gap |
|-------|---------|-----------|-----------|-----|
| leather | 0 | 1.000 | 0.972 | +0.03 |
| grid | 1 | 0.842 | 0.908 | -0.07 |
| transistor | 2 | 0.773 | 0.926 | -0.15 |
| carpet | 3 | 0.968 | 0.965 | +0.00 |
| zipper | 4 | 0.935 | 0.853 | +0.08 |
| hazelnut | 5 | 0.952 | 0.968 | -0.02 |
| toothbrush | 6 | 0.775 | 0.946 | -0.17 |
| metal_nut | 7 | 0.946 | 0.978 | -0.03 |
| screw | 8 | **0.420** | 0.856 | **-0.44** |
| wood | 9 | 0.979 | 0.895 | +0.08 |
| tile | 10 | 1.000 | 0.883 | +0.12 |
| capsule | 11 | 0.670 | 0.939 | -0.27 |
| pill | 12 | 0.819 | 0.951 | -0.13 |
| cable | 13 | 0.875 | 0.910 | -0.03 |
| bottle | 14 | 0.999 | 0.958 | +0.04 |

### Î∞úÍ≤¨Îêú Î¨∏Ï†ú

#### 1. ÎØ∏ÏÑ∏ ÏÑ±Îä• Î≥ÄÌôî (context_conv Í≥µÏú†)

grid Image AUC Ï∂îÏ†Å:
```
After Task  1: 0.8463
After Task 14: 0.8421 (-0.42%)
```

**ÏõêÏù∏**: `context_conv`ÏôÄ `context_scale_param`Ïù¥ Ïó¨Ï†ÑÌûà Î™®Îì† taskÏóêÏÑú ÌïôÏäµÎê®
```python
# mole_nf.py:706-710 (V4)
if hasattr(subnet, 'context_conv'):
    params.extend(subnet.context_conv.parameters())  # Î™®Îì† taskÏóêÏÑú ÌïôÏäµ!
```

#### 2. Image AUC << Pixel AUC Î¨∏Ï†ú

| Class | Image AUC | Pixel AUC | Gap | ÏõêÏù∏ |
|-------|-----------|-----------|-----|------|
| screw | 0.42 | 0.86 | -0.44 | ÎØ∏ÏÑ∏ Í≤∞Ìï®, normalÎèÑ high score |
| capsule | 0.67 | 0.94 | -0.27 | ÌòïÏÉÅ Ïú†ÏÇ¨ÏÑ± |
| toothbrush | 0.78 | 0.95 | -0.17 | ÌÖçÏä§Ï≤ò Ïú†ÏÇ¨ |

**ÏõêÏù∏ Î∂ÑÏÑù:**
- Image Score = max(patch scores) ÎòêÎäî 99th percentile
- Normal Ïù¥ÎØ∏ÏßÄÏùò ÏùºÎ∂Ä Ìå®ÏπòÍ∞Ä ÎÜíÏùÄ anomaly scoreÎ•º Í∞ÄÏßê
- Anomaly/Normal Ïù¥ÎØ∏ÏßÄÏùò max score Î∂ÑÌè¨Í∞Ä Ï§ëÏ≤©
- Pixel-levelÏùÄ Í∞úÎ≥Ñ Ìå®Ïπò Îã®ÏúÑÎ°ú ÌèâÍ∞ÄÎêòÏñ¥ Î∂ÑÎ¶¨Í∞Ä Ïûò Îê®

---

## V4.1 - True Complete Separation

### Î≥ÄÍ≤Ω Ïù¥Ïú†

V4ÏóêÏÑú `context_conv`Í∞Ä Ïó¨Ï†ÑÌûà Í≥µÏú†ÎêòÏñ¥ ÎØ∏ÏÑ∏ ÏÑ±Îä• Ï†ÄÌïò Î∞úÏÉù

### ÌïµÏã¨ Î≥ÄÍ≤Ω

| Ïª¥Ìè¨ÎÑåÌä∏ | V4 | V4.1 |
|----------|-----|------|
| SpatialMixer | Task 0 Ïù¥ÌõÑ freeze | Task 0 Ïù¥ÌõÑ freeze |
| **context_conv** | Î™®Îì† task ÌïôÏäµ | **Task 0 Ïù¥ÌõÑ freeze** |
| **context_scale_param** | Î™®Îì† task ÌïôÏäµ | **Task 0 Ïù¥ÌõÑ freeze** |

### Íµ¨ÌòÑ Î≥ÄÍ≤Ω

#### mole_nf.py - get_fast_params()

```python
# V4.1: MoLEContextSubnet context parameters - only trained in Task 0
if task_id == 0:
    if hasattr(subnet, 'context_conv'):
        params.extend(subnet.context_conv.parameters())
    if hasattr(subnet, 'context_scale_param') and subnet.context_scale_param is not None:
        params.append(subnet.context_scale_param)
```

#### mole_nf.py - get_trainable_params() (Task > 0 Î∏îÎ°ù)

```python
# V4.1: MoLEContextSubnet context parameters are frozen for Task > 0
# They are only trained in Task 0 (see the task_id == 0 block above)
```

### V4.1 File Changes

| File | Changes |
|------|---------|
| `moleflow/models/mole_nf.py` | `get_fast_params()`, `get_trainable_params()`, `freeze_fast_params()`, `unfreeze_fast_params()` - context_convÎèÑ task_id == 0Ïùº ÎïåÎßå ÌïôÏäµ |
| `run.sh` | V4.1 Ïã§Ìóò Ïä§ÌÅ¨Î¶ΩÌä∏ Ï∂îÍ∞Ä |

### ÏòàÏÉÅ Í≤∞Í≥º

| ÏßÄÌëú | V4 | V4.1 ÏòàÏÉÅ |
|------|-----|-----------|
| Task ÏÑ±Îä• Î≥ÄÌôî | -0.42% | **0%** (ÏôÑÏ†Ñ Í≥†Ï†ï) |
| ÌïôÏäµ ÌååÎùºÎØ∏ÌÑ∞ | LoRA + DIA + WhiteningAdapter + context_conv | LoRA + DIA + WhiteningAdapter |

---

## V4,3 - Score Aggregation Improvements

### Motivation

V4.1ÏóêÏÑú catastrophic forgettingÏùÄ Ìï¥Í≤∞ÎêòÏóàÏßÄÎßå, **Image AUCÍ∞Ä Pixel AUCÎ≥¥Îã§ ÌòÑÏ†ÄÌûà ÎÇÆÏùÄ Î¨∏Ï†ú** Ïó¨Ï†ÑÌûà Ï°¥Ïû¨:

| Class | Image AUC | Pixel AUC | Gap |
|-------|-----------|-----------|-----|
| screw | 0.42 | 0.86 | -0.44 |
| capsule | 0.67 | 0.94 | -0.27 |
| toothbrush | 0.78 | 0.95 | -0.17 |
| **Mean** | **0.87** | **0.94** | **-0.07** |

**ÌÜµÍ≥Ñ Î∂ÑÏÑù:**
- Image AUC std: 0.1532 (ÎÜíÏùÄ Î∂ÑÏÇ∞)
- Pixel AUC std: 0.0399 (ÎÇÆÏùÄ Î∂ÑÏÇ∞)

### Î¨∏Ï†ú ÏõêÏù∏ Î∂ÑÏÑù

**ÌòÑÏû¨ Image Score Í≥ÑÏÇ∞:**
```python
# Í∏∞Ï°¥: 99th percentile
patch_scores = -log_pz - log_det  # (B, H, W)
image_scores = torch.quantile(patch_scores.reshape(B, -1), 0.99, dim=1)
```

**Î¨∏Ï†ú:**
1. Normal Ïù¥ÎØ∏ÏßÄÏóêÎèÑ outlier Ìå®Ïπò Ï°¥Ïû¨ (ÎÜíÏùÄ anomaly score)
2. 99th percentileÏùÄ Ïù¥ outlierÏóê ÎØºÍ∞ê
3. NormalÍ≥º Anomaly Ïù¥ÎØ∏ÏßÄÏùò image score Î∂ÑÌè¨Í∞Ä Ï§ëÏ≤©

```
Normal Image:  Ìå®Ïπò scores = [0.1, 0.2, 0.3, ..., 0.8, 0.9, 1.5(outlier)]
                                                            ‚Üë 99th percentile = 1.5
Anomaly Image: Ìå®Ïπò scores = [0.1, 0.2, 0.3, ..., 1.2, 1.4, 1.6(true anomaly)]
                                                            ‚Üë 99th percentile = 1.6
‚Üí Î∂ÑÌè¨ Ï§ëÏ≤©ÏúºÎ°ú Íµ¨Î∂Ñ Ïñ¥Î†§ÏõÄ
```

### Solution: Configurable Score Aggregation

**Top-K Averaging** Ï†ëÍ∑º:
```python
# Top-K ÌèâÍ∑†: outlier ÏòÅÌñ• Í∞êÏÜå
top_k_scores, _ = torch.topk(patch_scores, k=10, dim=1)
image_score = top_k_scores.mean(dim=1)
```

**Ïû•Ï†ê:**
- KÍ∞ú Ìå®Ïπò ÌèâÍ∑† ‚Üí Îã®Ïùº outlier ÏòÅÌñ• Ìù¨ÏÑù
- NormalÏùò sporadic outlierÏôÄ AnomalyÏùò clustered anomaly Íµ¨Î∂Ñ Í∞ÄÎä•

### Implementation

#### 1. AblationConfig (ablation.py)

ÏÉàÎ°úÏö¥ config ÏòµÏÖò Ï∂îÍ∞Ä:
```python
# V4.3 Score Aggregation
score_aggregation_mode: str = "percentile"  # percentile, top_k, top_k_percent, max, mean
score_aggregation_percentile: float = 0.99  # For percentile mode
score_aggregation_top_k: int = 10           # For top_k mode
score_aggregation_top_k_percent: float = 0.05  # For top_k_percent mode (5%)
```

#### 2. continual_trainer.py - _aggregate_patch_scores()

ÏÉàÎ°úÏö¥ aggregation Î©îÏÑúÎìú:
```python
def _aggregate_patch_scores(self, patch_scores: torch.Tensor) -> torch.Tensor:
    """
    Aggregate patch-level scores to image-level score.

    Args:
        patch_scores: (B, H, W) tensor of per-patch anomaly scores

    Returns:
        image_scores: (B,) tensor of per-image anomaly scores
    """
    B = patch_scores.shape[0]
    flat_scores = patch_scores.reshape(B, -1)  # (B, H*W)
    num_patches = flat_scores.shape[1]
    mode = self.score_aggregation_mode

    if mode == "percentile":
        p = self.score_aggregation_percentile
        image_scores = torch.quantile(flat_scores, p, dim=1)
    elif mode == "top_k":
        k = min(self.score_aggregation_top_k, num_patches)
        top_k_scores, _ = torch.topk(flat_scores, k, dim=1)
        image_scores = top_k_scores.mean(dim=1)
    elif mode == "top_k_percent":
        k = max(1, int(num_patches * self.score_aggregation_top_k_percent))
        top_k_scores, _ = torch.topk(flat_scores, k, dim=1)
        image_scores = top_k_scores.mean(dim=1)
    elif mode == "max":
        image_scores = flat_scores.max(dim=1)[0]
    elif mode == "mean":
        image_scores = flat_scores.mean(dim=1)
    else:
        # Fallback to percentile
        image_scores = torch.quantile(flat_scores, 0.99, dim=1)

    return image_scores
```

#### 3. CLI Arguments

```bash
python run_moleflow.py \
    --score_aggregation_mode top_k \
    --score_aggregation_top_k 10 \
    --experiment_name V4.3-TopK10
```

### Aggregation Modes ÎπÑÍµê

| Mode | ÏàòÏãù | ÌäπÏÑ± | ÏòàÏÉÅ Ìö®Í≥º |
|------|------|------|-----------|
| `percentile` | `quantile(scores, 0.99)` | Í∏∞Ï°¥ Î∞©Ïãù, outlier ÎØºÍ∞ê | Baseline |
| `top_k` | `mean(top_k_scores)` | KÍ∞ú ÌèâÍ∑†, outlier ÏòÅÌñ• Í∞êÏÜå | **Ï∂îÏ≤ú** |
| `top_k_percent` | `mean(top_5%_scores)` | ÎπÑÏú® Í∏∞Î∞ò, Ìï¥ÏÉÅÎèÑ Î¨¥Í¥Ä | Alternative |
| `max` | `max(scores)` | Í∞ÄÏû• Í∑πÎã®Ï†Å, Í∞ÄÏû• ÎØºÍ∞ê | ÌäπÏàò ÏºÄÏù¥Ïä§ |
| `mean` | `mean(scores)` | Ï†ÑÏ≤¥ ÌèâÍ∑†, Í∞ÄÏû• ÎëîÍ∞ê | ÌäπÏàò ÏºÄÏù¥Ïä§ |

### Ïã§Ìóò Í≥ÑÌöç

**Pilot (3 classes: leather, grid, transistor):**
```bash
# GPU 0: Baseline (percentile 99%)
python run_moleflow.py --score_aggregation_mode percentile --score_aggregation_percentile 0.99 \
    --experiment_name Version5-ScoreAgg_percentile99

# GPU 1: Top-K (K=10)
python run_moleflow.py --score_aggregation_mode top_k --score_aggregation_top_k 10 \
    --experiment_name Version5-ScoreAgg_topk10
```

**Ï∂îÍ∞Ä Ïã§Ìóò (ÏÑ†ÌÉù):**
- Top-K percent (5%)
- Lower percentile (95%)

### V4.3 File Changes Summary

| File | Changes |
|------|---------|
| `moleflow/config/ablation.py` | V5 Score Aggregation config options Ï∂îÍ∞Ä (lines 136-151), CLI arguments Ï∂îÍ∞Ä (lines 631-652), `parse_ablation_args()` ÏóÖÎç∞Ïù¥Ìä∏ (lines 817-827) |
| `moleflow/trainer/continual_trainer.py` | `_aggregate_patch_scores()` Î©îÏÑúÎìú Ï∂îÍ∞Ä, `_compute_anomaly_scores()` ÏàòÏ†ïÌïòÏó¨ aggregation Ìò∏Ï∂ú |
| `run.sh` | V4.3 Ïã§Ìóò Ïä§ÌÅ¨Î¶ΩÌä∏ Ï∂îÍ∞Ä |

### ÏòàÏÉÅ Í≤∞Í≥º

| ÏßÄÌëú | V4.1 (percentile) | V5 (top_k) ÏòàÏÉÅ |
|------|-------------------|-----------------|
| Image AUC (screw) | 0.42 | 0.55+ |
| Image AUC (capsule) | 0.67 | 0.75+ |
| Mean Image AUC | 0.87 | **0.90+** |
| Image AUC std | 0.1532 | 0.10 ÎØ∏Îßå |

---

## V4.4 - LayerNorm Ablation Study

### Î∞∞Í≤Ω

V4.2/V4.3 Ïã§Ìóò ÌõÑ Image AUCÍ∞Ä Pixel AUCÎ≥¥Îã§ ÎÇÆÏùÄ Î¨∏Ï†úÏùò ÏõêÏù∏ÏúºÎ°ú **LayerNormÏù¥ anomaly Ïã†Ìò∏Î•º ÏïΩÌôîÏãúÌÇ®Îã§**Îäî Í∞ÄÏÑ§ÏùÑ ÏÑ∏ÏõÄ.

Í∞ÄÏÑ§Ïùò Í∑ºÍ±∞:
- LayerNormÏùÄ patchÎ≥Ñ ÏóêÎÑàÏßÄ(||x||), ÌèâÍ∑†(mean), Î∂ÑÏÇ∞(std)ÏùÑ Ï†úÍ±∞
- Ïù¥ Ï†ïÎ≥¥Îì§Ïù¥ anomaly ÌÉêÏßÄÏóê Ï§ëÏöîÌï† Ïàò ÏûàÏùå
- WhiteningAdapterÍ∞Ä `nn.LayerNorm(channels, elementwise_affine=False)` ÏÇ¨Ïö©

### Ïã§Ìóò ÏÑ§Í≥Ñ

**Í≥µÏ†ïÌïú ÎπÑÍµêÎ•º ÏúÑÌï¥ WhiteningAdapterNoLN Íµ¨ÌòÑ:**

```python
class WhiteningAdapterNoLN(nn.Module):
    """WhiteningAdapter WITHOUT LayerNorm"""

    def forward(self, x):
        # LayerNorm ÏóÜÏù¥ Î∞îÎ°ú gamma/beta Ï†ÅÏö©
        # ||x||, mean(x), std(x) Ï†ïÎ≥¥ Î≥¥Ï°¥
        return self.gamma * x + self.beta
```

ÎπÑÍµê ÎåÄÏÉÅ:
| Adapter | LayerNorm | gamma/beta |
|---------|-----------|------------|
| WhiteningAdapter | ‚úÖ ON | constrained [0.5, 2.0] |
| WhiteningAdapterNoLN | ‚ùå OFF | constrained [0.5, 2.0] |

### Ïã§Ìóò Í≤∞Í≥º

| Ïã§Ìóò | LayerNorm | Mean Image AUC | Mean Pixel AUC |
|------|-----------|----------------|----------------|
| V4.2-topk3 | ‚úÖ ON | **0.8903** | **0.9357** |
| V4.4-whitening_no_ln | ‚ùå OFF | 0.8476 | 0.9222 |
| **Ï∞®Ïù¥** | | **-4.8%** | **-1.4%** |

ÌÅ¥ÎûòÏä§Î≥Ñ ÎπÑÍµê:
| Class | Image AUC (LN) | Image AUC (No LN) | Î≥ÄÌôî |
|-------|----------------|-------------------|------|
| leather | 1.0000 | 1.0000 | 0% |
| grid | 0.8956 | 0.8145 | **-9.1%** |
| transistor | 0.7754 | 0.7283 | **-6.1%** |

### Í≤∞Î°†

**Í∞ÄÏÑ§ Í∏∞Í∞Å: LayerNormÏùÄ Î≥ëÎ™©Ïù¥ ÏïÑÎãò**

1. LayerNorm Ï†úÍ±∞ Ïãú ÏÑ±Îä• **ÌïòÎùΩ** (ÌäπÌûà Image AUC -4.8%)
2. LayerNormÏù¥ Ïò§ÌûàÎ†§ ÌïôÏäµ ÏïàÏ†ïÏÑ±Ïóê Í∏∞Ïó¨
3. Image AUC ÌïòÎùΩÏù¥ Pixel AUCÎ≥¥Îã§ ÌÅº ‚Üí Î∂àÏïàÏ†ïÌïú patch scoreÍ∞Ä aggregationÏóêÏÑú Îçî ÌÅ∞ ÏòÅÌñ•

### File Changes

| File | Changes |
|------|---------|
| `moleflow/models/adapters.py` | `WhiteningAdapterNoLN` ÌÅ¥ÎûòÏä§ Ï∂îÍ∞Ä, `create_task_adapter()`Ïóê `whitening_no_ln` ÏòµÏÖò Ï∂îÍ∞Ä |
| `moleflow/config/ablation.py` | CLI choicesÏóê `whitening_no_ln` Ï∂îÍ∞Ä |

---

## V4.3 All Classes Î∂ÑÏÑù - ÌÅ¥ÎûòÏä§Î≥Ñ ÏÑ±Îä• Ìé∏Ï∞®

### 15 ÌÅ¥ÎûòÏä§ Ï†ÑÏ≤¥ Ïã§Ìóò Í≤∞Í≥º

**V4.3-topk3_all_classes (Í∏∞Î≥∏ ÏàúÏÑú):**

| Task ID | Class | Image AUC | Pixel AUC | ÎπÑÍ≥† |
|---------|-------|-----------|-----------|------|
| 0 | leather | 1.0000 | 0.9720 | ‚úÖ ÏµúÍ≥† |
| 1 | grid | 0.8956 | 0.9082 | |
| 2 | transistor | 0.7754 | 0.9270 | ‚ö†Ô∏è ÎÇÆÏùå |
| 3 | carpet | 0.9755 | 0.9648 | ‚úÖ Ïö∞Ïàò |
| 4 | zipper | 0.9288 | 0.8550 | |
| 5 | hazelnut | 0.9529 | 0.9682 | ‚úÖ Ïö∞Ïàò |
| 6 | toothbrush | 0.7861 | 0.9459 | ‚ö†Ô∏è ÎÇÆÏùå |
| 7 | metal_nut | 0.9565 | 0.9776 | ‚úÖ Ïö∞Ïàò |
| 8 | **screw** | **0.4575** | 0.8573 | ‚ùå **Îß§Ïö∞ ÎÇÆÏùå** |
| 9 | wood | 0.9798 | 0.8949 | ‚úÖ Ïö∞Ïàò |
| 10 | tile | 1.0000 | 0.8843 | ‚úÖ ÏµúÍ≥† |
| 11 | capsule | 0.6881 | 0.9388 | ‚ö†Ô∏è ÎÇÆÏùå |
| 12 | pill | 0.8391 | 0.9513 | |
| 13 | cable | 0.8771 | 0.9102 | |
| 14 | bottle | 0.9992 | 0.9571 | ‚úÖ ÏµúÍ≥† |
| **Mean** | | **0.8741** | **0.9275** | |

### ÏÑ±Îä• Î∂ÑÌè¨ Î∂ÑÏÑù

**Image AUC Í∏∞Ï§Ä Î∂ÑÎ•ò:**
- üü¢ **Ïö∞Ïàò (‚â•0.95)**: leather, tile, bottle, carpet, wood, metal_nut, hazelnut (7Í∞ú)
- üü° **Î≥¥ÌÜµ (0.80~0.95)**: grid, zipper, pill, cable (4Í∞ú)
- üü† **ÎÇÆÏùå (0.65~0.80)**: transistor, toothbrush, capsule (3Í∞ú)
- üî¥ **Îß§Ïö∞ ÎÇÆÏùå (<0.65)**: **screw** (1Í∞ú)

**ÌÜµÍ≥Ñ:**
- Mean Image AUC: 0.8741
- Std: ~0.15 (ÎÜíÏùÄ Ìé∏Ï∞®)
- Min: 0.4575 (screw)
- Max: 1.0000 (leather, tile)

### Î¨∏Ï†ú ÌÅ¥ÎûòÏä§ Î∂ÑÏÑù

#### 1. Screw (Image AUC: 0.4575) - Í∞ÄÏû• Ïã¨Í∞Å

**ÌäπÏÑ±:**
- Îß§Ïö∞ ÏûëÏùÄ Í≤∞Ìï® (Ïä§ÌÅ¨ÎûòÏπò, Ïä§Î†àÎìú ÏÜêÏÉÅ)
- Í≤∞Ìï®Ïù¥ Ï†ÑÏ≤¥ Ïù¥ÎØ∏ÏßÄÏóêÏÑú Îß§Ïö∞ ÏûëÏùÄ ÎπÑÏú® Ï∞®ÏßÄ
- NormalÍ≥º AnomalyÏùò ÏãúÍ∞ÅÏ†Å Ï∞®Ïù¥Í∞Ä ÎØ∏ÎØ∏

**Ï∂îÏ†ï ÏõêÏù∏:**
- Top-K(K=3) aggregationÏúºÎ°úÎèÑ Î∂ÄÏ°±
- ÏûëÏùÄ Í≤∞Ìï®Ïù¥ patch scoreÏóêÏÑú Ï∂©Î∂ÑÌûà ÎëêÎìúÎü¨ÏßÄÏßÄ ÏïäÏùå
- Pixel AUC (0.86)Îäî ÏñëÌò∏ ‚Üí ÏúÑÏπòÎäî Ï∞æÏßÄÎßå image-level ÌåêÎã® Ïã§Ìå®

#### 2. Transistor (Image AUC: 0.7754)

**ÌäπÏÑ±:**
- Îã§ÏñëÌïú Í≤∞Ìï® Ïú†Ìòï (misplaced, bent, damaged)
- Í≤∞Ìï® ÏúÑÏπòÏôÄ ÌòïÌÉúÍ∞Ä Îã§Ïñë

**Ï∂îÏ†ï ÏõêÏù∏:**
- Task ÏàúÏÑúÏÉÅ Ï¥àÍ∏∞(Task 2)Ïóê ÌïôÏäµÎêòÏñ¥ Base NFÏôÄ Ìï®Íªò ÏµúÏ†ÅÌôî
- ÌïòÏßÄÎßå ÌõÑÏÜç task ÌïôÏäµ Ïãú representation drift Í∞ÄÎä•ÏÑ±

#### 3. Capsule (Image AUC: 0.6881)

**ÌäπÏÑ±:**
- Î∞òÌà¨Î™ÖÌïú Í∞ùÏ≤¥, ÎÇ¥Î∂Ä Í≤∞Ìï®
- ÎØ∏Î¨òÌïú ÏÉâÏÉÅ/ÌÖçÏä§Ï≤ò Î≥ÄÌôî

**Ï∂îÏ†ï ÏõêÏù∏:**
- ViT featureÍ∞Ä Î∞òÌà¨Î™Ö Í∞ùÏ≤¥Ïùò ÎØ∏Î¨òÌïú Ï∞®Ïù¥Î•º Ìè¨Ï∞©ÌïòÍ∏∞ Ïñ¥Î†§ÏõÄ
- Í≤∞Ìï®Ïù¥ Ï†ÑÏó≠Ï†Å Ìå®ÌÑ¥Î≥¥Îã§ Íµ≠ÏÜåÏ†Å Î≥ÄÌôîÎ°ú ÎÇòÌÉÄÎÇ®

#### 4. Toothbrush (Image AUC: 0.7861)

**ÌäπÏÑ±:**
- Í∞ÄÎäî bristle Íµ¨Ï°∞
- Í≤∞Ìï®Ïù¥ Îß§Ïö∞ ÏûëÏùÄ ÏòÅÏó≠Ïóê ÏßëÏ§ë

**Ï∂îÏ†ï ÏõêÏù∏:**
- Í≥†Ìï¥ÏÉÅÎèÑ featureÍ∞Ä ÌïÑÏöîÌïòÏßÄÎßå ViT patch size(16x16)Î°ú Ïù∏Ìïú Ï†ïÎ≥¥ ÏÜêÏã§

### ÌïµÏã¨ Î¨∏Ï†ú Ï†ïÎ¶¨

1. **Image AUC << Pixel AUC Gap**
   - PixelÏùÄ Ïûò Ï∞æÏßÄÎßå Image-level ÌåêÎã® Ïã§Ìå®
   - Aggregation Î∞©ÏãùÏùò ÌïúÍ≥Ñ

2. **ÌÅ¥ÎûòÏä§Î≥Ñ Ìé∏Ï∞®Í∞Ä ÌÅº**
   - Std ~0.15 (Î™©Ìëú: 0.05 Ïù¥Ìïò)
   - ÌäπÏ†ï ÌÅ¥ÎûòÏä§(screw)Í∞Ä Ï†ÑÏ≤¥ ÌèâÍ∑†ÏùÑ ÌÅ¨Í≤å ÎÇÆÏ∂§

3. **ÏûëÏùÄ Í≤∞Ìï® ÌÉêÏßÄ Ïñ¥Î†§ÏõÄ**
   - screw, capsule, toothbrush Í≥µÌÜµÏ†ê: ÏûëÍ±∞ÎÇò ÎØ∏Î¨òÌïú Í≤∞Ìï®
   - Top-K aggregationÏúºÎ°úÎèÑ Ìï¥Í≤∞ Ïïà Îê®

---

## Version 5 - Íµ¨Ï°∞Ï†Å Î¨∏Ï†ú Ìï¥Í≤∞ÏùÑ ÏúÑÌïú Í∞úÏÑ†

### Í∑ºÎ≥∏ Î¨∏Ï†ú Î∂ÑÏÑù

#### 1. ÌïôÏäµ Î™©Ìëú vs ÌèâÍ∞Ä Î™©Ìëú Î∂àÏùºÏπò (The Objective Gap)

**ÌòÑÏÉÅ**:
- NF ÌïôÏäµ: ÌèâÍ∑†Ï†Å ÌîºÌåÖ (`log p(x)` ÏµúÎåÄÌôî) - Î™®Îì† Ìå®ÏπòÏùò Ìï©ÏùÑ ÌèâÍ∑†
- ÌèâÍ∞Ä: Î∂ÑÌè¨Ïùò Íº¨Î¶¨(Tail)Ïóê ÏûàÎäî Í∑πÍ∞í(Top-k)ÏúºÎ°ú Í≤∞Ï†ï

**ÏõêÏù∏** (`continual_trainer.py:226-265`):
```python
# ÌïôÏäµ: Î™®Îì† Ìå®ÏπòÏùò ÌèâÍ∑†
log_px_image = log_px_patch.sum(dim=(1, 2))  # Ï†ÑÏ≤¥ Ìï©
nll_loss = -log_px_image.mean()

# ÌèâÍ∞Ä: Í∑πÍ∞í Í∏∞Î∞ò
image_scores = torch.quantile(flat_scores, 0.99, dim=1)  # percentile
# ÎòêÎäî
top_k_scores, _ = torch.topk(flat_scores, k, dim=1)      # top_k
```

**Í≤∞Í≥º**: ÌèâÍ∑†Ï†ÅÏúºÎ°ú Ï†ïÏÉÅ Î∂ÑÌè¨Îäî Ï¢ãÏïÑÏ°åÏßÄÎßå Í∑πÍ∞íÏóê ÎåÄÌïú ÎåÄÏùëÏù¥ ÏóÜÏñ¥ Image AUCÍ∞Ä ÎÇÆÏùå

#### 2. Í∏∞ÌïòÌïôÏ†Å Ï†ïÎ†¨ Î∂ÄÏû¨ (Geometric Misalignment) - Screw Î¨∏Ï†ú

**ÌòÑÏÉÅ**:
- Screw ÌÅ¥ÎûòÏä§Ïùò Î¨¥ÏûëÏúÑ ÌöåÏ†ÑÏù¥ Î≥µÏû°Ìïú Îß§ÎãàÌè¥ÎìúÎ•º ÌòïÏÑ±
- Î™®Îç∏Ïù¥ Í≤∞Ìï® ÎåÄÏã† ÌöåÏ†Ñ(SE(2))ÏùÑ ÌïôÏäµÌïòÎäî Îç∞ Ïö©Îüâ ÏÜåÏßÑ

**ÏõêÏù∏**:
- ÏΩîÎìú Ï†ÑÏ≤¥ÏóêÏÑú ÌöåÏ†Ñ Î∂àÎ≥ÄÏÑ±/Îì±Î≥ÄÏÑ± Ï≤òÎ¶¨ Î©îÏª§ÎãàÏ¶ò ÏóÜÏùå
- ViT feature, SpatialMixer, NF coupling Î™®Îëê ÌöåÏ†ÑÏóê ÎØºÍ∞ê

#### 3. ÎÖºÎ¶¨Ï†Å Ïù¥ÏÉÅ ÎØ∏ÌÉêÏßÄ (Logical Anomaly) - Transistor Î¨∏Ï†ú

**ÌòÑÏÉÅ**:
- Î∂ÄÌíà ÎàÑÎùΩ/Ïò§Î∞∞Ïπò Îì± ÌÖçÏä§Ï≤òÎäî Ï†ïÏÉÅÏù¥ÏßÄÎßå Ï†ÑÏó≠ Íµ¨Ï°∞Í∞Ä Íπ®ÏßÑ Í≤ΩÏö∞ ÌÉêÏßÄ Ïã§Ìå®

**ÏõêÏù∏** (`adapters.py:673`, `lora.py:249`):
```python
# SpatialContextMixer: 3x3 kernel
kernel_size: int = 3  # 3x3 receptive field

# LightweightMSContext
dilations = (1, 2, 4)  # ÏµúÎåÄ 9x9 effective RF
```

- 37x37 patchesÏóêÏÑú 9x9Îäî Ï†ÑÏ≤¥Ïùò 0.6%Îßå Ïª§Î≤Ñ ‚Üí Ï†ÑÏó≠ Î¨∏Îß• Î∂ÄÏû¨

#### 4. Pixel-Image AUC Í≤©Ï∞® (Statistical Aggregation Error)

**ÌòÑÏÉÅ**:
- Pixel AUCÎäî ÎÜíÏúºÎÇò Image AUCÍ∞Ä ÌòÑÏ†ÄÌûà ÎÇÆÏùå
- Ï†ïÏÉÅ Ïù¥ÎØ∏ÏßÄÏóêÏÑúÎèÑ outlier patch Î∞úÏÉù ‚Üí image score Î∂ÑÌè¨ overlap

**ÏõêÏù∏**:
- Í∏∞Ï°¥ Max/Top-k Î∞©ÏãùÏùÄ ÏÇ∞Î∞úÏ†Å ÎÖ∏Ïù¥Ï¶àÏóê Ï∑®ÏïΩ
- Ïã§Ï†ú Í≤∞Ìï®Ïù¥ Í∞ñÎäî ÏúÑÏÉÅÌïôÏ†Å Íµ∞ÏßëÏÑ±(Topological Clustering)ÏùÑ Î∞òÏòÅÌïòÏßÄ Î™ªÌï®

#### 5. SpatialMixer Í≥†Ï†ï Î¨∏Ï†ú

**ÌòÑÏÉÅ**:
- Task 0Ïóê ÏµúÏ†ÅÌôîÎêú context filterÍ∞Ä Ïù¥ÌõÑ taskÏóêÏÑú Í≥†Ï†ï

**ÏõêÏù∏** (`mole_nf.py:719-726`):
```python
# V4 Complete Separation: Spatial mixer only trained in Task 0
if self.spatial_mixer is not None and task_id == 0:
    params.extend(self.spatial_mixer.parameters())
```

---

### Version 5 Ìï¥Í≤∞Ï±Ö

#### Î¨∏Ï†ú-Ìï¥Í≤∞Ï±Ö Îß§Ìïë

| ÏàúÏúÑ | Î¨∏Ï†úÏ†ê | Ìï¥Í≤∞Ï±Ö | ÎÇúÏù¥ÎèÑ | Í∏∞ÎåÄ Ìö®Í≥º |
|:----:|--------|--------|:------:|:---------:|
| **1** | ÌïôÏäµ-ÌèâÍ∞Ä Î∂àÏùºÏπò | Tail-Aware Loss | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **2** | Image AUC Î∂ïÍ¥¥ | Spatial Clustering Score | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **3** | SpatialMixer Í≥†Ï†ï | Task-Adaptive Context | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **4** | Long-range Dependency | Global Context Module | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **5** | Geometry-Semantic Entanglement | Semantic Projector | ‚≠ê‚≠ê~‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |

---

### Solution 1: Tail-Aware Loss (Phase 1)

**ÌïµÏã¨**: ÌïôÏäµ ÏãúÏóêÎèÑ Í∑πÍ∞íÏùÑ Í≥†Î†§ÌïòÎäî ÏÜêÏã§ Ìï®Ïàò

```python
def _compute_tail_aware_loss(self, z, logdet_patch,
                              tail_weight=0.3, top_k_ratio=0.05):
    """
    L = (1 - Œª) * L_mean + Œª * L_tail
    """
    # Patch-wise NLL
    nll_patch = -(log_pz + logdet_patch)  # (B, H, W)

    # 1. Mean loss (Í∏∞Ï°¥)
    nll_mean = nll_patch.mean()

    # 2. Tail loss (ÏÉÅÏúÑ k% Ìå®Ïπò)
    flat_nll = nll_patch.reshape(B, -1)
    k = max(1, int(flat_nll.shape[1] * top_k_ratio))
    top_k_nll, _ = torch.topk(flat_nll, k, dim=1)
    nll_tail = top_k_nll.mean()

    # Combined
    total_loss = (1 - tail_weight) * nll_mean + tail_weight * nll_tail
    return total_loss
```

**Config ÏòµÏÖò**:
```python
use_tail_aware_loss: bool = True
tail_weight: float = 0.3
tail_top_k_ratio: float = 0.05
```

---

### Solution 2: Spatial Clustering Score (Phase 1)

**ÌïµÏã¨**: ÏÇ∞Î∞úÏ†Å ÎÖ∏Ïù¥Ï¶à vs Ïã§Ï†ú Í≤∞Ìï®(cluster) Íµ¨Î∂Ñ

```python
def _aggregate_with_spatial_clustering(self, patch_scores,
                                        cluster_weight=0.5):
    """Ïã§Ï†ú Í≤∞Ìï®ÏùÄ cluster ÌòïÏÑ±, ÎÖ∏Ïù¥Ï¶àÎäî ÏÇ∞Î∞úÏ†Å"""
    # 1. Í∏∞Î≥∏ top-k score
    top_k_score = torch.topk(flat_scores, k=10, dim=1)[0].mean(dim=1)

    # 2. High-score regionÏùò connectivity Ï∏°Ï†ï
    high_mask = patch_scores > threshold
    eroded = -F.max_pool2d(-mask, kernel_size=3, stride=1, padding=1)
    dilated = F.max_pool2d(eroded, kernel_size=3, stride=1, padding=1)

    cluster_ratio = dilated.sum() / mask.sum()

    # 3. Cluster bonus: ÏßÑÏßú Í≤∞Ìï®Ïù¥Î©¥ Ï†êÏàò Ï¶ùÌè≠
    image_score = top_k_score * (1 + cluster_weight * cluster_ratio)
    return image_score
```

**Config ÏòµÏÖò**:
```python
score_aggregation_mode: str = "spatial_cluster"
cluster_weight: float = 0.5
```

---

### Solution 3: Task-Adaptive Context (Phase 2)

**ÌïµÏã¨**: Frozen base mixer + Task-specific lightweight adapter

```python
class TaskAdaptiveContextMixer(nn.Module):
    """
    Base SpatialMixer (frozen after Task 0) + Task-specific gate/scale/bias
    """
    def __init__(self, channels, base_mixer):
        self.base_mixer = base_mixer
        self.task_gates = nn.ParameterDict()
        self.task_scales = nn.ParameterDict()
        self.task_biases = nn.ParameterDict()

    def forward(self, x, task_id):
        base_out = self.base_mixer(x)
        gate = torch.sigmoid(self.task_gates[str(task_id)])
        scale = self.task_scales[str(task_id)]
        bias = self.task_biases[str(task_id)]

        adapted = scale * base_out + bias
        return (1 - gate) * x + gate * adapted
```

**Config ÏòµÏÖò**:
```python
use_task_adaptive_context: bool = True
```

---

### Solution 4: Global Context Module (Phase 3)

**ÌïµÏã¨**: Regional pooling + Cross-attentionÏúºÎ°ú Ï†ÑÏó≠ Î¨∏Îß• Ï∂îÏ∂ú

```python
class LightweightGlobalContext(nn.Module):
    """O(N * R¬≤) Î≥µÏû°ÎèÑÎ°ú global context"""
    def __init__(self, channels, num_regions=4, reduction=4):
        self.region_proj = nn.Linear(channels, channels // reduction)
        self.query_proj = nn.Linear(channels, channels // reduction)
        self.out_proj = nn.Linear(channels // reduction, channels)
        self.gate = nn.Parameter(torch.tensor([0.1]))

    def forward(self, x):
        # 1. Regional tokens via pooling
        regions = F.adaptive_avg_pool2d(x_4d, (R, R))

        # 2. Cross-attention
        Q = self.query_proj(x_flat)
        K, V = self.key_proj(regions), self.value_proj(regions)
        attn = softmax(Q @ K.T / sqrt(d))
        global_ctx = attn @ V

        # 3. Gated residual
        return x + sigmoid(self.gate) * global_ctx
```

**Config ÏòµÏÖò**:
```python
use_global_context: bool = True
global_context_regions: int = 4
```

---

### Solution 5: Semantic Projector (Phase 2)

**ÌïµÏã¨**: Permutation-invariant poolingÏúºÎ°ú positional info Ï†úÍ±∞, semantic ÌïôÏäµ

```python
class SemanticProjector(nn.Module):
    """Position-agnostic semantic feature extraction"""
    def __init__(self, channels, bottleneck_ratio=0.5):
        self.patch_encoder = nn.Sequential(...)  # Per-patch
        self.global_encoder = nn.Sequential(...)  # Set function
        self.global_decoder = nn.Sequential(...)
        self.gate = nn.Parameter(torch.tensor([0.3]))

    def forward(self, x):
        # 1. Per-patch semantic
        x_semantic = self.patch_encoder(x)

        # 2. Global context (permutation-invariant)
        global_feat = self.global_encoder(x).mean(dim=1)  # Position Ï†úÍ±∞
        global_ctx = self.global_decoder(global_feat)

        # 3. Combine
        return x_semantic + sigmoid(self.gate) * global_ctx
```

**Config ÏòµÏÖò**:
```python
use_semantic_projector: bool = True
semantic_bottleneck_ratio: float = 0.5
```

---

### Íµ¨ÌòÑ Î°úÎìúÎßµ

```
Phase 1 (Ï¶âÏãú Ï†ÅÏö©, ÎÜíÏùÄ Ìö®Í≥º)
‚îú‚îÄ‚îÄ Tail-Aware Loss
‚îî‚îÄ‚îÄ Spatial Clustering Score

Phase 2 (Îã®Í∏∞, Íµ¨Ï°∞ ÏàòÏ†ï)
‚îú‚îÄ‚îÄ Semantic Projector
‚îî‚îÄ‚îÄ Task-Adaptive Context

Phase 3 (Ï§ëÍ∏∞)
‚îî‚îÄ‚îÄ Global Context Module
```

### Í∏∞ÎåÄ Ìö®Í≥º

| Ìï¥Í≤∞Ï±Ö | Image AUC | Pixel AUC | ÌÅ¥ÎûòÏä§ Ìé∏Ï∞® | Screw | Transistor |
|--------|:---------:|:---------:|:----------:|:-----:|:----------:|
| Tail-Aware Loss | ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è | ‚¨ÜÔ∏è | ‚¨ÜÔ∏è‚¨ÜÔ∏è | ‚¨ÜÔ∏è | ‚¨ÜÔ∏è |
| Spatial Clustering | ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è | - | ‚¨ÜÔ∏è‚¨ÜÔ∏è | ‚¨ÜÔ∏è | ‚¨ÜÔ∏è |
| Task-Adaptive Ctx | ‚¨ÜÔ∏è | ‚¨ÜÔ∏è | ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è | ‚¨ÜÔ∏è | ‚¨ÜÔ∏è |
| Global Context | ‚¨ÜÔ∏è | ‚¨ÜÔ∏è | ‚¨ÜÔ∏è | ‚¨ÜÔ∏è | ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è |
| Semantic Projector | ‚¨ÜÔ∏è‚¨ÜÔ∏è | ‚¨ÜÔ∏è | ‚¨ÜÔ∏è‚¨ÜÔ∏è | ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è | ‚¨ÜÔ∏è‚¨ÜÔ∏è |

### File Changes Summary

| File | Changes |
|------|---------|
| `moleflow/config/ablation.py` | V5 config options Ï∂îÍ∞Ä |
| `moleflow/trainer/continual_trainer.py` | Tail-Aware Loss, Spatial Clustering Score |
| `moleflow/models/adapters.py` | SemanticProjector, TaskAdaptiveContextMixer, LightweightGlobalContext |
| `moleflow/models/mole_nf.py` | ÏÉà Î™®Îìà ÌÜµÌï© |
| `run.sh` | V5 Ïã§Ìóò Ïä§ÌÅ¨Î¶ΩÌä∏ |

---

## Ïù¥Ï†Ñ Î∂ÑÏÑù (Ï∞∏Í≥†Ïö©)

### V4.3 Ïù¥Ï†Ñ ÏïÑÌÇ§ÌÖçÏ≤ò Î¶¨Î∑∞

```
ViT Backbone (frozen)
    ‚Üì
Multi-block Feature Aggregation (blocks 8,9,10,11)
    ‚Üì
Positional Embedding (sin/cos)
    ‚Üì
WhiteningAdapter (task-specific, LayerNorm + gamma/beta)
    ‚Üì
SpatialMixer (frozen after Task 0)
    ‚Üì
Normalizing Flow + LoRA (task-specific)
    ‚Üì
DIA (task-specific invertible adapter)
    ‚Üì
Anomaly Score = -log p(z) - log|det J|
    ‚Üì
Aggregation (top-k mean)
    ‚Üì
Image Score
```

### Î≥ëÎ™© ÌõÑÎ≥¥ Î∂ÑÏÑù (V4 Í∏∞Ï§Ä)

#### A. Feature Extraction Level

| ÏöîÏÜå | ÌòÑÏû¨ ÏÉÅÌÉú | Ïû†Ïû¨Ï†Å Î¨∏Ï†ú |
|------|----------|-------------|
| Coupling layers | 8 layers | ÌëúÌòÑÎ†• Ï†úÌïú Í∞ÄÎä• |
| LoRA rank | 64 | TaskÎ≥Ñ Ï†ÅÏùëÎ†• Ï†úÌïú Í∞ÄÎä• |
| DIA | 2 blocks | Î∂ÑÌè¨ Ï†ïÎ†¨ ÌëúÌòÑÎ†• Ï†úÌïú |

#### D. Scoring Level

| ÏöîÏÜå | ÌòÑÏû¨ ÏÉÅÌÉú | Ïû†Ïû¨Ï†Å Î¨∏Ï†ú |
|------|----------|-------------|
| Patch score | -log p(z) - log|det J| | ÌëúÏ§Ä NLL |
| Aggregation | top-k mean (k=3) | **ÏûëÏùÄ Í≤∞Ìï®Ïóê Î∂ÄÏ°±** |
| Calibration | ÏóÜÏùå | **TaskÎ≥Ñ score scale Î∂àÏùºÏπò** |

### Í∞úÏÑ† Î∞©Ìñ• Ï†úÏïà

#### Î∞©Ìñ• 1: Adaptive Aggregation (ÌÅ¥ÎûòÏä§ ÎÇúÏù¥ÎèÑ Í∏∞Î∞ò)

**Î¨∏Ï†ú**: Í≥†Ï†ï KÍ∞íÏù¥ Î™®Îì† ÌÅ¥ÎûòÏä§Ïóê Ï†ÅÌï©ÌïòÏßÄ ÏïäÏùå
- Screw: Í≤∞Ìï®Ïù¥ Îß§Ïö∞ ÏûëÏùå ‚Üí K=1~2 ÌïÑÏöî
- Carpet: Í≤∞Ìï®Ïù¥ ÎÑìÏùå ‚Üí K=5~10 Ï†ÅÌï©

**Ï†úÏïà**:
```python
# ÌïôÏäµÎêú aggregation weight
class AdaptiveAggregation(nn.Module):
    def forward(self, patch_scores):
        # Attention-based weighted sum
        weights = self.attention(patch_scores)  # ÌïôÏäµ
        return (weights * patch_scores).sum()
```

#### Î∞©Ìñ• 2: Score Calibration (TaskÎ≥Ñ Ï†ïÍ∑úÌôî)

**Î¨∏Ï†ú**: TaskÎ≥Ñ score Î∂ÑÌè¨Í∞Ä Îã§Î¶Ñ
- Task 0 (leather): score range [0, 5]
- Task 8 (screw): score range [0, 20]

**Ï†úÏïà**:
```python
# TaskÎ≥Ñ Ï†ïÏÉÅ score ÌÜµÍ≥Ñ Ï†ÄÏû•
class ScoreCalibrator:
    def __init__(self):
        self.task_stats = {}  # {task_id: (mean, std)}

    def calibrate(self, score, task_id):
        mean, std = self.task_stats[task_id]
        return (score - mean) / std  # Z-score Ï†ïÍ∑úÌôî
```

#### Î∞©Ìñ• 3: Multi-scale Patch Analysis

**Î¨∏Ï†ú**: 16x16 patchÍ∞Ä ÏûëÏùÄ Í≤∞Ìï®ÏùÑ ÎÜìÏπ®

**Ï†úÏïà**: Îã§Ï§ë Ìï¥ÏÉÅÎèÑ feature ÏÇ¨Ïö©
- ÏõêÎ≥∏ patch (16x16)
- Overlapping patches
- ÎòêÎäî Îçî ÏûëÏùÄ patch size backbone

#### Î∞©Ìñ• 4: Contrastive/Margin Loss Ï∂îÍ∞Ä

**Î¨∏Ï†ú**: NLLÎßåÏúºÎ°úÎäî Normal/Anomaly Î∂ÑÎ¶¨Î†• Î∂ÄÏ°±

**Ï†úÏïà**:
```python
# Pseudo-anomalyÎ°ú margin loss Ï∂îÍ∞Ä
loss = nll_loss + lambda * margin_loss(normal_scores, pseudo_anomaly_scores)
```

#### Î∞©Ìñ• 5: DIA ÌëúÌòÑÎ†• ÌôïÎåÄ

**Î¨∏Ï†ú**: 2 blocks DIAÍ∞Ä Î∂ÑÌè¨ Ï∞®Ïù¥Í∞Ä ÌÅ∞ taskÏóê Î∂ÄÏ°±

**Ï†úÏïà**:
- Task ÎÇúÏù¥ÎèÑ Í∏∞Î∞ò blocks Ïàò Ï°∞Ï†ï
- ÎòêÎäî Îçî expressiveÌïú flow Íµ¨Ï°∞

### Ïö∞ÏÑ†ÏàúÏúÑ Ï∂îÏ≤ú

| ÏàúÏúÑ | Î∞©Ìñ• | Í∏∞ÎåÄ Ìö®Í≥º | Íµ¨ÌòÑ ÎÇúÏù¥ÎèÑ |
|------|------|----------|------------|
| 1 | Score Calibration | ÌÅ¥ÎûòÏä§Î≥Ñ Ìé∏Ï∞® ÏôÑÌôî | ÎÇÆÏùå |
| 2 | Adaptive Aggregation | screw Îì± Í∞úÏÑ† | Ï§ëÍ∞Ñ |
| 3 | DIA ÌëúÌòÑÎ†• ÌôïÎåÄ | Ï†ÑÎ∞òÏ†Å Ìñ•ÏÉÅ | ÎÇÆÏùå |
| 4 | Contrastive Loss | Î∂ÑÎ¶¨Î†• Ìñ•ÏÉÅ | Ï§ëÍ∞Ñ |
| 5 | Multi-scale Patch | ÏûëÏùÄ Í≤∞Ìï® ÌÉêÏßÄ | ÎÜíÏùå |

---
## V5.5 - Position-Agnostic Improvements (2025-12-28)

### Problem Identified

V5 experiments revealed screw class remains at ~0.40-0.44 Image AUC (worse than random).

**Root Cause Analysis**:
- Pixel AUC for screw: ~0.85 (decent - patch detection works)
- Image AUC for screw: ~0.41 (terrible - worse than random)
- **Key Insight**: The problem is NOT in anomaly detection, but in aggregation
- Screw has random orientations ‚Üí normal rotated patches get high anomaly scores ‚Üí false positive noise dominates top-k aggregation

**Fundamental Issue**: Position-dependent learning
- NF learns "pattern at position (x,y)" instead of "pattern regardless of position"
- Works for fixed-position objects (leather, grid) but breaks for rotated objects (screw)

### V5.5 Implementation: 3 Class-Agnostic Directions

All directions use V5.1a-TailAwareLoss as baseline and address the position problem without class-specific hacks.

#### Direction 1: Relative Position Encoding (`--use_relative_position`)
**Idea**: Replace absolute PE with relative position attention
- Instead of "what is at (5,5)?", ask "what is the relationship between neighboring patches?"
- Relative patterns (thread spacing) are rotation-invariant
- **Implementation**: `RelativePositionEmbedding` in adapters.py
  - Learnable relative position bias table
  - Query/Key projection for attention
  - Blend gate to combine with absolute PE

#### Direction 2: Dual Branch Scoring (`--use_dual_branch`)
**Idea**: Two parallel NF branches, learn when to trust each
- Position Branch: Standard NF with PE (good for aligned objects)
- No-Position Branch: NF without PE (good for rotated objects)
- Final score = Œ± * pos_score + (1-Œ±) * nopos_score
- Œ± is learned per-patch based on local pattern consistency
- **Implementation**: `DualBranchScorer` in adapters.py
  - Alpha predictor network
  - Dual forward pass in `_compute_anomaly_scores()`

#### Direction 3: Local Consistency Calibration (`--use_local_consistency`)
**Idea**: Down-weight isolated high scores (likely rotation noise)
- Real anomalies have spatially consistent high scores
- False positives (rotation artifacts) are isolated
- **Implementation**: `LocalConsistencyCalibrator` in adapters.py
  - 3x3 consistency convolution
  - Learnable temperature and minimum weight

### Experiment Setup (run.sh)

```bash
# GPU 0: Dir1 - Relative Position
--use_relative_position --relative_position_max_dist 7

# GPU 1: Dir3 - Local Consistency
--use_local_consistency --local_consistency_kernel 3

# GPU 4: Dir1+Dir3 Combined (most promising)
--use_relative_position --use_local_consistency

# GPU 5: Dir2 - Dual Branch
--use_dual_branch
```

### Files Modified

1. **adapters.py**: Added 3 new modules
   - `RelativePositionEmbedding`
   - `DualBranchScorer`
   - `LocalConsistencyCalibrator`

2. **ablation.py**: Added V5.5 config options and CLI args

3. **mole_nf.py**: Integrated V5.5 modules in forward pass

4. **continual_trainer.py**: 
   - Added V5.5 settings
   - Integrated LocalConsistency in `_aggregate_patch_scores()`
   - Implemented dual-branch scoring in `_compute_anomaly_scores()`

---

### V5.5 Ïã§Ìóò Í≤∞Í≥º (2025-12-28)

#### Í≤∞Í≥º ÌÖåÏù¥Î∏î (Image AUC)

| Experiment | leather | grid | transistor | screw | Mean |
|------------|---------|------|------------|-------|------|
| Baseline (V4.3) | 1.00 | 0.90 | 0.78 | 0.46 | 0.87 |
| Dir1-RelativePosition | 1.00 | 0.87 | 0.76 | 0.39 | 0.75 |
| Dir2-DualBranch | 0.17 | 0.35 | 0.52 | **0.91** | 0.49 |
| **Dir3-LocalConsistency** | 1.00 | **0.92** | **0.81** | 0.43 | **0.79** |
| Dir1+Dir3-Combined | 1.00 | 0.84 | 0.77 | 0.40 | 0.75 |

#### ÌïµÏã¨ Î∞úÍ≤¨

**1. Dir2 (DualBranch)Í∞Ä Í∞ÄÏÑ§ÏùÑ Ï¶ùÎ™ÖÌï®**
```
Screw Image AUC: 0.39 ‚Üí 0.91 (2.3Î∞∞ Ìñ•ÏÉÅ!)

Í∑∏Îü¨ÎÇò Îã§Î•∏ ÌÅ¥ÎûòÏä§ Î∂ïÍ¥¥:
- leather: 1.00 ‚Üí 0.17
- grid: 0.90 ‚Üí 0.35
- transistor: 0.78 ‚Üí 0.52
```

**Ìï¥ÏÑù**:
- ÏúÑÏπò Ï†ïÎ≥¥ Ï†úÍ±∞Í∞Ä screw Î¨∏Ï†úÏùò Ìï¥Í≤∞Ï±ÖÏûÑÏùÑ ÌôïÏù∏
- Œ± predictorÍ∞Ä Ï†úÎåÄÎ°ú ÌïôÏäµÎêòÏßÄ ÏïäÏùå
- no-position Î∏åÎûúÏπòÍ∞Ä Í≥ºÎèÑÌïòÍ≤å ÏßÄÎ∞∞ÌïòÎ©¥ÏÑú Í≥†Ï†ï Î∞©Ìñ• ÌÅ¥ÎûòÏä§ ÏÑ±Îä• Î∂ïÍ¥¥

**2. Dir3 (LocalConsistency)Í∞Ä Í∞ÄÏû• Í∑†ÌòïÏû°Ìûå Ï†ëÍ∑ºÎ≤ï**
```
Grid: 0.90 ‚Üí 0.92 (Í∞úÏÑ†)
Transistor: 0.78 ‚Üí 0.81 (Í∞úÏÑ†)
Screw: 0.46 ‚Üí 0.43 (ÎØ∏ÎØ∏Ìïú Î≥ÄÌôî)
Mean: 0.79 (baseline 0.87Î≥¥Îã§ ÎÇÆÏßÄÎßå 4ÌÅ¥ÎûòÏä§ Ï§ë Í∞ÄÏû• ÎÜíÏùå)
```

**3. Dir1 (RelativePosition)ÏùÄ Ìö®Í≥º ÏóÜÏùå**
- ÏÉÅÎåÄ ÏúÑÏπò Ïù∏ÏΩîÎî©ÎßåÏúºÎ°úÎäî rotation invariance Îã¨ÏÑ± Î∂àÍ∞Ä
- Screw Ïò§ÌûàÎ†§ ÏïÖÌôî: 0.46 ‚Üí 0.39

**4. Combined (Dir1+Dir3)Îäî Dir3 Îã®ÎèÖÎ≥¥Îã§ ÎÇòÏÅ®**
- Dir1Ïù¥ Ïò§ÌûàÎ†§ Î∞©Ìï¥ ÏöîÏÜåÎ°ú ÏûëÏö©

#### Ïã§Ìå® ÏõêÏù∏ Î∂ÑÏÑù

**Dir2 Œ± predictor Ïã§Ìå® ÏõêÏù∏**:
```python
# ÌòÑÏû¨ Íµ¨Ï°∞
self.alpha_net = nn.Sequential(
    nn.Linear(channels * 2, channels // 2),
    nn.LayerNorm(channels // 2),
    nn.GELU(),
    nn.Linear(channels // 2, 1),
    nn.Sigmoid()  # Œ± ‚àà [0, 1]
)
# Ï¥àÍ∏∞Ìôî: Œ± ‚âà 0.5Î°ú ÏãúÏûë

Î¨∏Ï†ú:
1. ÌïôÏäµ Ï¥àÍ∏∞ no-pos Î∏åÎûúÏπò lossÍ∞Ä Îçî ÎÇÆÏùå (ÏúÑÏπò ÏóêÎü¨ ÏóÜÏúºÎØÄÎ°ú)
2. GradientÍ∞Ä Œ±Î•º 0 Î∞©Ìñ•ÏúºÎ°ú Îπ†Î•¥Í≤å Ïù¥Îèô
3. ÏùºÎã® Œ± ‚Üí 0Ïù¥ ÎêòÎ©¥ pos Î∏åÎûúÏπò gradient ÏÜåÏã§
4. Í≤∞Í≥º: Œ± ‚âà 0 Í≥†Ï†ï (no-posÎßå ÏÇ¨Ïö©)
```

#### Îã§Ïùå Îã®Í≥Ñ Ï†úÏïà

1. **Dir2 Í∞úÏÑ†Ïïà**:
   - Œ± Ï¥àÍ∏∞Í∞íÏùÑ 0.7-0.8Î°ú ÏÑ§Ï†ï (pos Î∏åÎûúÏπò ÏÑ†Ìò∏)
   - Œ±Ïóê regularization Ï∂îÍ∞Ä: loss += Œª * |Œ± - 0.5|
   - Warm-up: Ï¥àÍ∏∞ N epochsÎäî Œ± Í≥†Ï†ï

2. **Dir3 ÌôïÏû•**:
   - Ïª§ÎÑê ÌÅ¨Í∏∞ Ïã§Ìóò: 5x5, 7x7
   - Temperature Ï°∞Ï†ï Ïã§Ìóò

3. **ÏÉàÎ°úÏö¥ Î∞©Ìñ•**:
   - Task-aware Œ±: Í∞Å taskÎ≥ÑÎ°ú Îã§Î•∏ Œ± ÌïôÏäµ
   - Rotation augmentation + contrastive learning

---

## V5.6 - Improved Position-Agnostic Solutions (2025-12-28)

### 1. V5.5 Ïã§Ìå® ÏõêÏù∏ Î∂ÑÏÑù

#### Dir2 (DualBranchScorer) Ïã§Ìå® Î∂ÑÏÑù

**ÌòÑÏÉÅ**: Screw 0.91 Îã¨ÏÑ±ÌñàÏúºÎÇò Îã§Î•∏ ÌÅ¥ÎûòÏä§ Î∂ïÍ¥¥ (leather 0.17)

**ÏõêÏù∏ Î∂ÑÏÑù**:
```
ÌïôÏäµ Ï¥àÍ∏∞:
  - pos_score: ÏúÑÏπò Ï†ïÎ≥¥ Í∏∞Î∞ò ‚Üí ÏùºÎ∂Ä Ìå®Ïπò ÎÜíÏùÄ error
  - nopos_score: ÏúÑÏπò Ï†ïÎ≥¥ ÏóÜÏùå ‚Üí Ï†ÑÎ∞òÏ†ÅÏúºÎ°ú ÎÇÆÏùÄ error
  
  ‚Üí nopos Î∏åÎûúÏπòÏùò lossÍ∞Ä Îçî ÎÇÆÏùå
  ‚Üí GradientÍ∞Ä Œ±Î•º 0 Î∞©Ìñ•ÏúºÎ°ú ÏóÖÎç∞Ïù¥Ìä∏
  ‚Üí Œ± ‚âà 0Ïù¥ ÎêòÎ©¥ pos Î∏åÎûúÏπò gradient ÏÜåÏã§
  ‚Üí Í≤∞Í≥º: Œ± ‚Üí 0 Í≥†Ï†ï (no-positionÎßå ÏÇ¨Ïö©)

Î¨∏Ï†úÏ†ê:
  1. Ï¥àÍ∏∞Í∞í Œ±=0.5Í∞Ä Î∂àÏïàÏ†ï
  2. Œ±Ïóê Ï†úÏïΩ ÏóÜÏñ¥ Í∑πÎã®Í∞íÏúºÎ°ú ÏàòÎ†¥
  3. Ìïú Î≤à Î∂ïÍ¥¥ÌïòÎ©¥ ÌöåÎ≥µ Î∂àÍ∞Ä
```

#### Dir3 (LocalConsistency) ÌïúÍ≥Ñ

**ÌòÑÏÉÅ**: Í∞ÄÏû• Ï¢ãÏïòÏúºÎÇò screw Í∞úÏÑ† ÎØ∏ÎØ∏ (0.43)

**ÏõêÏù∏**:
- Îã®Ïùº 3x3 Ïª§ÎÑêÏùÄ Í≤∞Ìï® ÌÅ¨Í∏∞ Îã§ÏñëÏÑ± ÎØ∏Î∞òÏòÅ
- ÌÅ∞ Í≤∞Ìï®ÏùÄ 5x5ÎÇò 7x7 Ïª§ÎÑê ÌïÑÏöî
- ÏûëÏùÄ Í≤∞Ìï®ÏùÄ 3x3Ïù¥ Ï†ÅÌï©

### 2. V5.6 Í∞úÏÑ† Î∞©Ïïà

#### 2.1 ImprovedDualBranchScorer (Anti-Collapse)

**ÌïµÏã¨ Í∞úÏÑ†**:
```python
class ImprovedDualBranchScorer(nn.Module):
    def __init__(self, channels, init_alpha=0.7, min_alpha=0.3, max_alpha=0.9):
        # 1. Ï¥àÍ∏∞Í∞í 0.7 (pos Î∏åÎûúÏπò ÏÑ†Ìò∏Î°ú ÏãúÏûë)
        init_logit = log(init_alpha / (1 - init_alpha))
        nn.init.constant_(self.alpha_net[-1].bias, init_logit)
        
        # 2. Œ± clampÎ°ú collapse Î∞©ÏßÄ
        self.min_alpha = min_alpha  # ÏµúÏÜå 30% pos ÏÇ¨Ïö©
        self.max_alpha = max_alpha  # ÏµúÎåÄ 90% pos ÏÇ¨Ïö©
    
    def forward(self, z_pos, z_nopos, score_pos, score_nopos):
        # 3. Score Ï∞®Ïù¥Î•º Ï∂îÍ∞Ä ÏûÖÎ†•ÏúºÎ°ú ÌôúÏö©
        score_diff = (score_pos - score_nopos) / (|score_pos| + |score_nopos| + Œµ)
        combined_input = cat([z_pos, z_nopos, score_diff], dim=-1)
        
        # 4. Œ±Î•º [min, max] Î≤îÏúÑÎ°ú Ï†úÌïú
        alpha_raw = sigmoid(self.alpha_net(combined_input))
        alpha = min_alpha + (max_alpha - min_alpha) * alpha_raw
        
        return alpha * score_pos + (1 - alpha) * score_nopos
```

**Í∏∞ÎåÄ Ìö®Í≥º**:
- Œ±Í∞Ä 0ÏúºÎ°ú Î∂ïÍ¥¥ÌïòÏßÄ ÏïäÏùå (min=0.3 Î≥¥Ïû•)
- pos Î∏åÎûúÏπòÍ∞Ä Ìï≠ÏÉÅ ÏµúÏÜå 30% Í∏∞Ïó¨
- Score Ï∞®Ïù¥ ÏûÖÎ†•ÏúºÎ°ú Îçî informativeÌïú Œ± ÏòàÏ∏°

#### 2.2 ScoreGuidedDualBranch (Alternative)

**Îçî Îã®ÏàúÌïú Ï†ëÍ∑º**:
```python
class ScoreGuidedDualBranch(nn.Module):
    """
    Latent ÎåÄÏã† score Ï∞®Ïù¥Î°ú ÏßÅÏ†ë Œ± Í≤∞Ï†ï.
    
    ÏïÑÏù¥ÎîîÏñ¥:
    - score_pos < score_nopos ‚Üí pos Î∏åÎûúÏπòÍ∞Ä Îçî Ï¢ãÏùå ‚Üí Œ± ‚Üë
    - score_pos > score_nopos ‚Üí nopos Î∏åÎûúÏπòÍ∞Ä Îçî Ï¢ãÏùå ‚Üí Œ± ‚Üì
    """
    
    def forward(self, z_pos, z_nopos, score_pos, score_nopos):
        score_diff = score_pos - score_nopos
        normalized_diff = score_diff / score_magnitude
        
        # diff > 0 (posÍ∞Ä worse) ‚Üí Œ± Í∞êÏÜå
        # diff < 0 (posÍ∞Ä better) ‚Üí Œ± Ï¶ùÍ∞Ä
        alpha = sigmoid(temp * (bias - normalized_diff))
        alpha = clamp(alpha, min=min_alpha, max=1-min_alpha)
        
        return alpha * score_pos + (1 - alpha) * score_nopos
```

**Ïû•Ï†ê**:
- Latent Í∏∞Î∞òÎ≥¥Îã§ ÏßÅÏ†ëÏ†Å
- GradientÍ∞Ä scoreÎ°ú ÏßÅÏ†ë Ï†ÑÌåå
- Îçî interpretable

#### 2.3 MultiScaleLocalConsistency

**Multi-scale Î∂ÑÏÑù**:
```python
class MultiScaleLocalConsistency(nn.Module):
    def __init__(self, kernel_sizes=[3, 5, 7], temperature=1.0):
        # Í∞Å Ïä§ÏºÄÏùºÎ≥Ñ learnable parameters
        self.temperatures = [Parameter for each kernel]
        self.min_weights = [Parameter for each kernel]
        self.scale_weights = Parameter([1/3, 1/3, 1/3])  # ÏúµÌï© Í∞ÄÏ§ëÏπò
        
        # Score-adaptive fusion
        self.adaptive_net = Linear(n_scales, n_scales) + Softmax
    
    def forward(self, patch_scores):
        # Í∞Å Ïä§ÏºÄÏùºÏóêÏÑú consistency Í≥ÑÏÇ∞
        weights_3x3 = compute_consistency(scores, kernel=3)
        weights_5x5 = compute_consistency(scores, kernel=5)
        weights_7x7 = compute_consistency(scores, kernel=7)
        
        # Adaptive fusion (Ïä§ÏºÄÏùºÎ≥Ñ Ï§ëÏöîÎèÑ ÌïôÏäµ)
        scale_means = stack([w.mean() for w in weights]).T
        fusion_weights = adaptive_net(scale_means)  # Softmax
        
        combined = sum(w * fw for w, fw in zip(all_weights, fusion_weights))
        return patch_scores * combined
```

**Í∏∞ÎåÄ Ìö®Í≥º**:
- ÏûëÏùÄ Í≤∞Ìï® (3x3) + Ï§ëÍ∞Ñ (5x5) + ÌÅ∞ Í≤∞Ìï® (7x7) Î™®Îëê Ïª§Î≤Ñ
- Learnable fusionÏúºÎ°ú ÏµúÏ†Å Ï°∞Ìï© ÌïôÏäµ
- V5.5 Dir3 ÎåÄÎπÑ Îã§ÏñëÌïú Í≤∞Ìï® ÌÅ¨Í∏∞ ÎåÄÏùë

### 3. Ïã§Ìóò Íµ¨ÏÑ± (run.sh)

| GPU | Ïã§Ìóò | ÌïµÏã¨ ÏÑ§Ï†ï |
|-----|------|----------|
| 0 | ImprovedDualBranch | init=0.7, Œ±‚àà[0.3, 0.9] |
| 1 | ScoreGuidedDual | temp=1.0, min_Œ±=0.2 |
| 4 | MultiScaleConsistency | kernels=[3,5,7] |
| 5 | Combined | ImprovedDual + MultiScale |

### 4. ÏàòÏ†ïÎêú ÌååÏùº

1. **adapters.py**:
   - `ImprovedDualBranchScorer`: Anti-collapse dual branch
   - `ScoreGuidedDualBranch`: Score-guided alternative
   - `MultiScaleLocalConsistency`: Multi-scale consistency

2. **ablation.py**:
   - V5.6 config options Ï∂îÍ∞Ä
   - CLI arguments Ï∂îÍ∞Ä

3. **mole_nf.py**:
   - V5.6 Î™®Îìà imports
   - V5.6 settings Ï≤òÎ¶¨
   - Î™®Îìà Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±
   - get_trainable_paramsÏóê V5.6 ÌååÎùºÎØ∏ÌÑ∞ Ï∂îÍ∞Ä

4. **continual_trainer.py**:
   - V5.6 settings Ï≤òÎ¶¨
   - _compute_anomaly_scoresÏóêÏÑú V5.6 dual branch Ï≤òÎ¶¨
   - _aggregate_patch_scoresÏóêÏÑú multiscale consistency Ï≤òÎ¶¨

5. **run.sh**:
   - V5.6 Ïã§Ìóò 4Í∞ú Íµ¨ÏÑ±

---

### V5.6 Ïã§Ìóò Í≤∞Í≥º (2025-12-28)

#### Í≤∞Í≥º ÌÖåÏù¥Î∏î (Image AUC)

| Experiment | leather | grid | transistor | screw | Mean |
|------------|---------|------|------------|-------|------|
| Baseline (V5.5-Dir3) | 1.00 | 0.92 | 0.81 | 0.43 | **0.79** |
| V5.6-ImprovedDualBranch | 0.47 | 0.40 | 0.60 | **0.90** | 0.59 |
| V5.6-ScoreGuidedDual | 0.14 | 0.49 | 0.57 | **0.90** | 0.52 |
| **V5.6-MultiScaleConsistency** | **1.00** | **0.92** | **0.81** | 0.39 | **0.78** |
| V5.6-Combined | 0.12 | 0.44 | 0.54 | **0.90** | 0.50 |

#### Î∂ÑÏÑù

**1. Dual Branch Í∞úÏÑ† Ïã§Ìå®**
- Œ± clamping [0.3, 0.9]ÎèÑ collapse Î∞©ÏßÄ Ïã§Ìå®
- ScrewÎäî 0.90ÏúºÎ°ú Ï¢ãÏßÄÎßå Îã§Î•∏ ÌÅ¥ÎûòÏä§ Î∂ïÍ¥¥
- **Í∑ºÎ≥∏ ÏõêÏù∏**: Ï†ïÏÉÅ Îç∞Ïù¥ÌÑ∞ÎßåÏúºÎ°úÎäî pos/nopos Íµ¨Î∂Ñ ÌïôÏäµ Î∂àÍ∞Ä

**2. MultiScaleConsistency Ïú†ÏßÄ**
- V5.5-Dir3ÏôÄ Í±∞Ïùò ÎèôÏùº (0.78 vs 0.79)
- Multi-scaleÏù¥ single-scale ÎåÄÎπÑ ÌÅ∞ Í∞úÏÑ† ÏóÜÏùå
- ScrewÎäî Ïó¨Ï†ÑÌûà 0.39

**3. Dual Branch Ïã§Ìå® Í∑ºÎ≥∏ ÏõêÏù∏**
```
ÌïôÏäµ Îç∞Ïù¥ÌÑ∞: Ï†ïÏÉÅ Ïù¥ÎØ∏ÏßÄÎßå ÏÇ¨Ïö©
  ‚Üì
pos_score ‚âà nopos_score (Ï†ïÏÉÅÏùÄ Îëò Îã§ ÎÇÆÏùå)
  ‚Üì
Œ± ÌïôÏäµÏóê Ïú†ÏùòÎØ∏Ìïú Ïã†Ìò∏ ÏóÜÏùå
  ‚Üì
Œ±Í∞Ä ÏûÑÏùò Î∞©Ìñ•ÏúºÎ°ú ÏàòÎ†¥
  ‚Üì
ÌÖåÏä§Ìä∏ Ïãú ÏùòÎØ∏ÏûàÎäî ÏÑ†ÌÉù Î∂àÍ∞Ä
```

#### Í≤∞Î°†

- **Dual Branch Ï†ëÍ∑ºÎ≤ï Ìè¨Í∏∞**: Ï†ïÏÉÅ Îç∞Ïù¥ÌÑ∞ÎßåÏúºÎ°úÎäî pos/nopos ÏÑ†ÌÉù ÌïôÏäµ Î∂àÍ∞Ä
- **MultiScaleConsistency**: V5.5-Dir3ÏôÄ ÎèôÎì±, Ï∂îÍ∞Ä Í∞úÏÑ† ÏóÜÏùå
- **ÏÉàÎ°úÏö¥ Î∞©Ìñ• ÌïÑÏöî**:
  1. Task-level Œ± (Í∞Å taskÎßàÎã§ Í≥†Ï†ï Œ± ÌïôÏäµ)
  2. Pseudo-anomaly Í∏∞Î∞ò contrastive learning
  3. Position encoding ÏûêÏ≤¥Î•º rotation-invariantÌïòÍ≤å ÏÑ§Í≥Ñ

---

## V5.7 - Rotation-Invariant Position Encoding

### V5.7-DirC-MultiOrientation Í≤∞Í≥º (All Classes)

| Task ID | Class | Routing Acc | Image AUC | Pixel AUC |
|---------|-------|-------------|-----------|-----------|
| 0 | bottle | 100.00 | 1.0000 | 0.9469 |
| 1 | cable | 100.00 | 0.9162 | 0.9042 |
| 2 | capsule | 100.00 | 0.7276 | 0.9203 |
| 3 | carpet | 100.00 | 0.9755 | 0.9643 |
| 4 | grid | 100.00 | 0.8989 | 0.8937 |
| 5 | hazelnut | 100.00 | 0.9625 | 0.9646 |
| 6 | leather | 100.00 | 1.0000 | 0.9699 |
| 7 | metal_nut | 100.00 | 0.9717 | 0.9654 |
| 8 | pill | 98.80 | 0.8568 | 0.9438 |
| 9 | screw | 100.00 | **0.3484** | 0.8168 |
| 10 | tile | 100.00 | 1.0000 | 0.8794 |
| 11 | toothbrush | 97.62 | 0.8417 | 0.9414 |
| 12 | transistor | 100.00 | 0.7967 | 0.9456 |
| 13 | wood | 100.00 | 0.9553 | 0.8811 |
| 14 | zipper | 100.00 | 0.9278 | 0.8629 |
| **Mean** | Overall | 99.76 | **0.8786** | 0.9200 |

### V5.7 Î∂ÑÏÑù

**Multi-Orientation Ensemble Ìö®Í≥º ÏóÜÏùå**:
- Mean 0.88Î°ú Ï¢ãÏïÑ Î≥¥Ïù¥ÏßÄÎßå **Screw 0.35Î°ú Ïó¨Ï†ÑÌûà Î¨∏Ï†ú**
- Feature ÌöåÏ†Ñ ‚â† ÏùòÎØ∏ÏûàÎäî Îã§Î•∏ ÏãúÏ†ê
- Position EmbeddingÏù¥ Ïù¥ÎØ∏ featureÏóê baked-in ÎêòÏñ¥ ÏûàÏùå
- 4Î∞∞ inference costÎßå Î∞úÏÉù, Í∞úÏÑ† ÏóÜÏùå

**ContentBasedPE/HybridPE**:
- Pilot Ïã§ÌóòÏóêÏÑú 0.75 meanÏúºÎ°ú baselineÎ≥¥Îã§ ÎÇòÏÅ®
- ÌïôÏäµ ÏóÜÏù¥ inference-timeÏóê prototype Îß§Ïπ≠ÏùÄ Î∂àÏïàÏ†ï

---

## V5.8 - TAPE (Task-Adaptive Position Encoding) Íµ¨ÌòÑ

### ÌïµÏã¨ ÏïÑÏù¥ÎîîÏñ¥

Ïù¥Ï†Ñ Ï†ëÍ∑ºÎ≤ïÏùò Ïã§Ìå® ÏõêÏù∏ Î∂ÑÏÑù:
```
V5.5/V5.6 Dual Branch:
  - Patch-level Œ± decision
  - Ï†ïÏÉÅ Îç∞Ïù¥ÌÑ∞: pos_score ‚âà nopos_score ‚Üí No gradient signal
  - Œ±Í∞Ä collapseÌïòÍ±∞ÎÇò ÎûúÎç§ÌïòÍ≤å ÏàòÎ†¥

V5.7 Multi-Orientation:
  - Inference-time rotation
  - ÌïôÏäµÏóê Î∞òÏòÅ ÏïàÎê® ‚Üí Cannot learn
  - FeatureÏóê PEÍ∞Ä Ïù¥ÎØ∏ Ï†ÅÏö©ÎêòÏñ¥ ÏûàÏñ¥ rotation Î¨¥ÏùòÎØ∏
```

**TAPE Ìï¥Í≤∞Ï±Ö**:
```
Task-level PE strength + Training-time learning
  ‚Üì
NLL loss provides direct gradient
  ‚Üì
Í∞Å taskÍ∞Ä ÏµúÏ†ÅÏùò PE strength ÏûêÎèô ÌïôÏäµ
```

### ÏÑ§Í≥Ñ

```python
class TaskAdaptivePositionEncoding(nn.Module):
    """
    V5.8: TAPE - TaskÎ≥Ñ PE Í∞ïÎèÑ ÌïôÏäµ

    - pe_gates: {task_id: learnable gate}
    - alpha = sigmoid(gate) ‚Üí PE strength (0~1)
    - features_with_pe = raw_features + alpha * grid_pe
    """
    def __init__(self, init_value: float = 0.0):
        self.init_value = init_value
        self.pe_gates = nn.ParameterDict()

    def add_task(self, task_id: int):
        self.pe_gates[str(task_id)] = nn.Parameter(
            torch.tensor([self.init_value])
        )

    def forward(self, features, grid_pe, task_id):
        gate = self.pe_gates[str(task_id)]
        alpha = torch.sigmoid(gate)  # 0~1
        return features + alpha * grid_pe
```

### Í∏∞ÎåÄ Ìö®Í≥º

| Task | ÏòàÏÉÅ PE Strength | Ïù¥Ïú† |
|------|------------------|------|
| Screw | ~0.1-0.3 (ÎÇÆÏùå) | ÌöåÏ†Ñ Î∂àÎ≥Ä ‚Üí PE ÏïΩÌïòÍ≤å |
| Leather | ~0.8-1.0 (ÎÜíÏùå) | Í≥µÍ∞Ñ ÏùºÍ¥ÄÏÑ± Ï§ëÏöî ‚Üí PE Í∞ïÌïòÍ≤å |
| Grid | ~0.5-0.7 (Ï§ëÍ∞Ñ) | Ïñ¥Îäê Ï†ïÎèÑ ÏúÑÏπò Ï†ïÎ≥¥ ÌïÑÏöî |

### ÏàòÏ†ïÎêú ÌååÏùº

1. **adapters.py**: `TaskAdaptivePositionEncoding` ÌÅ¥ÎûòÏä§ Ï∂îÍ∞Ä
2. **ablation.py**: `use_tape`, `tape_init_value` config Ï∂îÍ∞Ä
3. **mole_nf.py**: TAPE ÌÜµÌï© (Ï¥àÍ∏∞Ìôî, add_task, forward)
4. **continual_trainer.py**:
   - TAPE ÌôúÏÑ±Ìôî Ïãú raw features Ï†ÑÎã¨ (PEÎäî NF ÎÇ¥Î∂ÄÏóêÏÑú Ï†ÅÏö©)
   - Task ÌõàÎ†® ÌõÑ PE strength Î°úÍπÖ

### Ïã§Ìñâ Î∞©Î≤ï

```bash
# TAPE Í∏∞Î≥∏ Ïã§Ìóò
python run_moleflow.py --run_diagnostics \
    --use_tape \
    --tape_init_value 0.0 \
    --experiment_name Version5.8-TAPE

# TAPE + LocalConsistency
python run_moleflow.py --run_diagnostics \
    --use_tape \
    --tape_init_value 0.0 \
    --use_local_consistency \
    --local_consistency_kernel 3 \
    --experiment_name Version5.8-TAPE-LocalConsistency
```

### ÌïµÏã¨ Ï∞®Î≥ÑÏ†ê (vs Ïù¥Ï†Ñ Ï†ëÍ∑ºÎ≤ï)

| Ï∏°Î©¥ | V5.5/V5.6 | V5.7 | V5.8 TAPE |
|------|-----------|------|-----------|
| Decision Level | Patch | Image | **Task** |
| Learning | Training | Inference | **Training** |
| Gradient | None (normal‚âànormal) | None | **Clear (NLL)** |
| Î≥µÏû°ÎèÑ | Moderate | High (4x inference) | **Low** |

---

### V5.8-TAPE v1 Ïã§Ìóò Í≤∞Í≥º (Pilot)

| Task | Class | Image AUC | PE Strength |
|------|-------|-----------|-------------|
| 0 | leather | 1.0000 | 0.5028 |
| 1 | grid | 0.9365 | 0.5000 |
| 2 | transistor | 0.8087 | 0.5000 |
| 3 | screw | 0.3900 | 0.5000 |
| **Mean** | | **0.7838** | |

### Î¨∏Ï†ú Î∞úÍ≤¨: PE StrengthÍ∞Ä ÌïôÏäµÎêòÏßÄ ÏïäÏùå

**Ï¶ùÏÉÅ**: Î™®Îì† TaskÏùò PE strengthÍ∞Ä Ï¥àÍ∏∞Í∞í 0.5ÏóêÏÑú Í±∞Ïùò Î≥ÄÌïòÏßÄ ÏïäÏùå

**ÏõêÏù∏ Î∂ÑÏÑù**:
1. TAPE gateÎäî **Îã®Ïùº Ïä§ÏπºÎùº** ÌååÎùºÎØ∏ÌÑ∞
2. Îã§Î•∏ ÏàòÏ≤ú Í∞ú ÌååÎùºÎØ∏ÌÑ∞ÏôÄ **ÎèôÏùºÌïú learning rate** ÏÇ¨Ïö©
3. NLL lossÏóêÏÑú PE Í∏∞Ïó¨ÎèÑÍ∞Ä Îã§Î•∏ ÌååÎùºÎØ∏ÌÑ∞Ïóê ÎπÑÌï¥ ÏûëÏùå
4. GradientÍ∞Ä ÎÑàÎ¨¥ ÏûëÏïÑÏÑú ÌïôÏäµÏù¥ ÏùºÏñ¥ÎÇòÏßÄ ÏïäÏùå

### V5.8-TAPE v2: LR Multiplier Ï∂îÍ∞Ä

**Ìï¥Í≤∞Ï±Ö**: TAPE gateÏóê Î≥ÑÎèÑÏùò ÎÜíÏùÄ learning rate Ï†ÅÏö©

**ÏàòÏ†ï ÎÇ¥Ïö©**:

1. **ablation.py**:
   - `tape_lr_multiplier: float = 100.0` Ï∂îÍ∞Ä
   - CLI argument `--tape_lr_multiplier` Ï∂îÍ∞Ä

2. **continual_trainer.py**:
   - `_train_base_task`: Parameter groupsÎ°ú Î∂ÑÎ¶¨, TAPEÏóê 100x LR
   - `_train_fast_stage`: ÎèôÏùºÌïòÍ≤å Ï†ÅÏö©
   - WarmupÎèÑ Í∞Å Í∑∏Î£πÎ≥ÑÎ°ú Ï†ÅÏ†àÌûà Ï≤òÎ¶¨

```python
# ÏàòÏ†ïÎêú optimizer ÏÉùÏÑ± ÏΩîÎìú
if self.use_tape:
    tape_params = self.nf_model.tape.get_trainable_params(task_id)
    other_params = [p for p in trainable_params if id(p) not in tape_param_ids]

    param_groups = [
        {'params': other_params, 'lr': lr},
        {'params': tape_params, 'lr': lr * self.tape_lr_multiplier}  # 100x
    ]
    optimizer = create_optimizer(param_groups, lr=lr)
```

**Í∏∞ÎåÄ Ìö®Í≥º**:
- Í∏∞Î≥∏ LRÏù¥ 1e-4Î©¥, TAPE gateÎäî 1e-2Î°ú ÌïôÏäµ
- PE strengthÍ∞Ä Ïã§Ï†úÎ°ú Í∞Å task ÌäπÏÑ±Ïóê ÎßûÍ≤å Î≥ÄÌôîÌï† Í≤É
- Screw: 0.5 ‚Üí ~0.2 (PE Í∞êÏÜå), Leather: 0.5 ‚Üí ~0.8 (PE Ïú†ÏßÄ/Ï¶ùÍ∞Ä)

### V5.8-TAPE v2 Ïã§Ìóò Í≤∞Í≥º

| Task | Class | PE Strength | Image AUC | vs v1 |
|------|-------|-------------|-----------|-------|
| 0 | leather | 0.3257 | 1.0000 | = |
| 1 | grid | 0.9748 | 0.9165 | ‚Üì0.02 |
| 2 | transistor | 0.9426 | 0.7963 | ‚Üì0.01 |
| 3 | screw | 0.3082 | 0.3753 | ‚Üì0.01 |
| **Mean** | | | **0.7720** | ‚Üì0.01 |

### Î∂ÑÏÑù: TAPE ÌïôÏäµ Î∞©Ìñ• Î¨∏Ï†ú

**Î∞úÍ≤¨ 1**: PE strengthÍ∞Ä Ïù¥Ï†ú ÌïôÏäµÎê® (v1Ïùò 0.5ÏóêÏÑú Î≥ÄÌôî)
- Screw: 0.31 (ÎÇÆÏùå) ‚Üê ÏùòÎèÑÎåÄÎ°ú!
- Leather: 0.33 (ÎÇÆÏùå) ‚Üê **Î∞òÎåÄÎ°ú ÌïôÏäµÎê®!**
- Grid/Transistor: 0.94-0.97 (ÎÜíÏùå)

**Î∞úÍ≤¨ 2**: ÏÑ±Îä•ÏùÄ Ïò§ÌûàÎ†§ Ï†ÄÌïòÎê®
- v1 Mean: 0.7838 ‚Üí v2 Mean: 0.7720 (‚Üì)
- Î™®Îì† metricÏóêÏÑú ÏÜåÌè≠ ÌïòÎùΩ

**Í∑ºÎ≥∏ ÏõêÏù∏: NLL Loss ‚â† Anomaly Detection**

```
NLL Loss ÏµúÏÜåÌôî Î∞©Ìñ•:
  - ÎÇÆÏùÄ PE ‚Üí Îçî ÏûêÏú†Î°úÏö¥ fit ‚Üí Îçî ÎÇÆÏùÄ NLL
  - Î™®Îç∏ÏùÄ PEÎ•º ÎÇÆÏ∂îÎäî Î∞©Ìñ•ÏúºÎ°ú ÌïôÏäµ

Anomaly Detection ÏµúÏ†ÅÌôî Î∞©Ìñ•:
  - ÌÅ¥ÎûòÏä§ ÌäπÏÑ±Ïóê ÎßûÎäî PE ÌïÑÏöî
  - Leather: ÎÜíÏùÄ PE (Í≥µÍ∞Ñ Íµ¨Ï°∞ Ï§ëÏöî)
  - Screw: ÎÇÆÏùÄ PE (ÌöåÏ†Ñ Î∂àÎ≥Ä ÌïÑÏöî)

‚Üí Îëê Î™©ÌëúÍ∞Ä Ï†ïÎ†¨ÎêòÏßÄ ÏïäÏùå!
```

**LeatherÍ∞Ä ÎÇÆÏùÄ PEÎ°ú ÌïôÏäµÎêú Ïù¥Ïú†**:
- LeatherÏùò Ï†ïÏÉÅ Ïù¥ÎØ∏ÏßÄÎäî textureÍ∞Ä Í∑†Ïùº
- PE ÏóÜÏù¥ÎèÑ ÏâΩÍ≤å fit Í∞ÄÎä• ‚Üí ÎÇÆÏùÄ NLL
- ÌïòÏßÄÎßå anomaly detectionÏóêÏÑúÎäî ÏúÑÏπò Ï†ïÎ≥¥Í∞Ä ÌïÑÏöîÌï† Ïàò ÏûàÏùå

### Í≤∞Î°†: TAPE Ï†ëÍ∑ºÎ≤ïÏùò ÌïúÍ≥Ñ

**Normal-only trainingÏùò Í∑ºÎ≥∏Ï†Å ÌïúÍ≥Ñ**:
1. V5.5/V5.6: Patch-level Œ± ‚Üí No gradient (pos‚âànopos for normal)
2. V5.8 TAPE: Task-level Œ± ‚Üí Gradient exists but **wrong direction**

NLL lossÎßåÏúºÎ°úÎäî anomaly detectionÏóê ÏµúÏ†ÅÏù∏ PE strengthÎ•º ÌïôÏäµÌï† Ïàò ÏóÜÏùå.

**Í∞ÄÎä•Ìïú ÎåÄÏïà**:
1. **Prior knowledge Ï£ºÏûÖ**: ÌÅ¥ÎûòÏä§ ÌÉÄÏûÖÎ≥Ñ PE Í≥†Ï†ï (texture‚Üíhigh, object‚Üílow)
2. **Pseudo-anomaly ÏÇ¨Ïö©**: Í∞ÄÏßú anomalyÎ°ú contrastive learning
3. **Validation-based tuning**: Anomaly detection ÏÑ±Îä•ÏúºÎ°ú PE ÌäúÎãù

---

## Version 5 ÏµúÏ¢Ö Ï†ïÎ¶¨

### Version 5 Ïã§Ìóò ÏöîÏïΩ

| Version | Ï†ëÍ∑ºÎ≤ï | Í≤∞Í≥º | Î¨∏Ï†úÏ†ê |
|---------|--------|------|--------|
| V5.1a | Tail-Aware Loss + Top-K | **Best baseline** | Screw Ïó¨Ï†ÑÌûà ÎÇÆÏùå |
| V5.5 | Dual Branch (pos/nopos) | Ïã§Ìå® | No gradient signal |
| V5.6 | Improved Dual Branch | Ïã§Ìå® | Collapse to one branch |
| V5.7 | Multi-Orientation Ensemble | Í∞úÏÑ† ÏóÜÏùå | Feature rotation ‚â† viewpoint |
| V5.8 | TAPE (Task-Adaptive PE) | Ïó≠Ìö®Í≥º | NLL ‚â† AD performance |

### ÌïµÏã¨ ÍµêÌõà: Normal-Only TrainingÏùò ÌïúÍ≥Ñ

**Position Encoding ÏµúÏ†ÅÌôî ÏãúÎèÑ Ïã§Ìå® ÏõêÏù∏**:

```
Î¨∏Ï†ú Ï†ïÏùò:
  - Screw: ÌöåÏ†ÑÏóê Î∂àÎ≥ÄÌï¥Ïïº Ìï® ‚Üí PE ÏïΩÌïòÍ≤å
  - Leather: Í≥µÍ∞Ñ Íµ¨Ï°∞ Ï§ëÏöî ‚Üí PE Í∞ïÌïòÍ≤å

ÏãúÎèÑÌïú Ï†ëÍ∑ºÎ≤ïÎì§:
  1. Patch-level Œ± (V5.5/V5.6)
     - Ï†ïÏÉÅ Îç∞Ïù¥ÌÑ∞: pos_score ‚âà nopos_score
     - ‚Üí Œ±Ïóê gradient Ïã†Ìò∏ ÏóÜÏùå
     - ‚Üí ÌïôÏäµ Î∂àÍ∞Ä

  2. Inference-time Ï°∞Ï†ï (V5.7)
     - FeatureÏóê PEÍ∞Ä Ïù¥ÎØ∏ baked-in
     - ‚Üí rotation Î¨¥ÏùòÎØ∏
     - ‚Üí Í∞úÏÑ† ÏóÜÏùå

  3. Task-level ÌïôÏäµ (V5.8)
     - NLL lossÎäî "Ï†ïÏÉÅ fit" ÏµúÏ†ÅÌôî
     - ‚Üí PE ÎÇÆÏ∂îÎäî Î∞©Ìñ•ÏúºÎ°ú ÌïôÏäµ (Îçî ÏûêÏú†Î°úÏö¥ fit)
     - ‚Üí Anomaly detectionÍ≥º Ïó≠Î∞©Ìñ•
```

**Í∑ºÎ≥∏Ï†Å ÌïúÍ≥Ñ**:
- Anomaly detectionÏóê ÏµúÏ†ÅÏù∏ PEÎ•º Ï∞æÏúºÎ†§Î©¥ **anomaly Ï†ïÎ≥¥ ÌïÑÏöî**
- Normal-only trainingÏúºÎ°úÎäî Î∂àÍ∞ÄÎä•

### Best Configuration (Version 5 Final)

```bash
python run_moleflow.py \
    --use_whitening_adapter \
    --use_dia \
    --score_aggregation_mode top_k \
    --score_aggregation_top_k 3 \
    --use_tail_aware_loss \
    --tail_weight 0.3 \
    --experiment_name Version5-Final
```

### ÎÇ®ÏùÄ Í≥ºÏ†ú

1. **Screw ÌÅ¥ÎûòÏä§ ÏÑ±Îä• Í∞úÏÑ†**: PE Ïô∏ Îã§Î•∏ Ï†ëÍ∑º ÌïÑÏöî
2. **Pseudo-anomaly training**: CutPaste Îì±ÏúºÎ°ú anomaly Ïã†Ìò∏ Ï†úÍ≥µ
3. **Class-specific Ï≤òÎ¶¨**: Object vs Texture ÌÅ¥ÎûòÏä§ Íµ¨Î∂Ñ

---

## Screw ÌÅ¥ÎûòÏä§ Í∑ºÎ≥∏ ÏõêÏù∏ Ïû¨Î∂ÑÏÑù (2025-12-29)

### Diagnostics Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù

**Version5-RotationAug (screw as task 3) Î∂ÑÏÑù**:

| Metric | Normal | Anomaly | Ìï¥ÏÑù |
|--------|--------|---------|------|
| logdet_std | 72.28 | 57.18 | **AnomalyÍ∞Ä Îçî uniform** |
| log_pz var | 75,495 | 6,764 | **NormalÏù¥ 11x Îçî diverse** |
| ||z|| vs logdet corr | 0.27 | 0.26 | Ïú†ÏÇ¨ |
| ratio (anom/norm) | - | 0.79 | **"DEAD" scale ÏßÑÎã®** |

### ÌïµÏã¨ Î∞úÍ≤¨: Normal > Anomaly Variance

**ScrewÏùò ÌäπÏù¥Ï†ê**: Normal Ïù¥ÎØ∏ÏßÄÎì§Ïù¥ Anomaly Ïù¥ÎØ∏ÏßÄÎì§Î≥¥Îã§ **Îçî ÎÜíÏùÄ Î∂ÑÏÇ∞**ÏùÑ Í∞ÄÏßê

Ïù¥Í≤ÉÏùÄ NF Í∏∞Î∞ò Anomaly DetectionÏóêÏÑú ÏπòÎ™ÖÏ†ÅÏù∏ Î¨∏Ï†ú:
1. NFÎäî "Normal Î∂ÑÌè¨Î•º ÌïôÏäµÌïòÍ≥† Í∑∏ Î∂ÑÌè¨ÏóêÏÑú Î≤óÏñ¥ÎÇú Í≤ÉÏùÑ AnomalyÎ°ú ÌÉêÏßÄ"
2. NormalÏùò Î∂ÑÏÇ∞Ïù¥ ÎÜíÏúºÎ©¥ ‚Üí ÎÑìÏùÄ Î∂ÑÌè¨ ÌïôÏäµ ‚Üí AnomalyÎèÑ Í∑∏ ÏïàÏóê Ìè¨Ìï®
3. AnomalyÍ∞Ä Îçî ÏùºÍ¥ÄÏ†ÅÏù¥Î©¥ ‚Üí Ïò§ÌûàÎ†§ "Îçî normal"ÌïòÍ≤å Î≥¥ÏûÑ

**MVTec Screw Îç∞Ïù¥ÌÑ∞ÏÖã ÌäπÏÑ±**:
- Train/Test Normal: Îã§ÏñëÌïú Í∞ÅÎèÑ/Ï°∞Î™Ö/ÏúÑÏπòÏóêÏÑú Ï¥¨ÏòÅ
- Test Anomaly: ÌäπÏ†ï Í≤∞Ìï® Ïú†Ìòï (scratch_head, thread_side Îì±)Ïù¥ Îçî ÏùºÍ¥ÄÏ†ÅÏù∏ Ï°∞Í±¥ÏóêÏÑú Ï¥¨ÏòÅ

```
Normal Ïù¥ÎØ∏ÏßÄ Îã§ÏñëÏÑ±:
- 320Ïû• ÌïôÏäµ Ïù¥ÎØ∏ÏßÄ
- Îã§ÏñëÌïú ÌöåÏ†Ñ Í∞ÅÎèÑ
- Îã§ÏñëÌïú Ï°∞Î™Ö Ï°∞Í±¥
- log_pz variance = 75,495 (Îß§Ïö∞ ÌÅº)

Anomaly Ïù¥ÎØ∏ÏßÄ ÏùºÍ¥ÄÏÑ±:
- Í≤∞Ìï® Ïú†ÌòïÎ≥ÑÎ°ú Íµ∞ÏßëÌôîÎêú Ï¥¨ÏòÅ
- Îçî ÌÜµÏ†úÎêú ÌôòÍ≤Ω
- log_pz variance = 6,764 (ÏÉÅÎåÄÏ†ÅÏúºÎ°ú ÏûëÏùå)
```

### Screw vs Îã§Î•∏ ÌÅ¥ÎûòÏä§ ÎπÑÍµê

**Leather, Grid (Ïûò ÏûëÎèôÌïòÎäî ÌÅ¥ÎûòÏä§)**:
- Texture ÌÅ¥ÎûòÏä§ ‚Üí ÏúÑÏπò Î∂àÎ≥Ä Ìå®ÌÑ¥
- Normal/Anomaly Î™®Îëê ÏùºÍ¥ÄÏ†Å
- AnomalyÍ∞Ä ÌôïÏã§Ìïú Î∂ÑÌè¨ Ïù¥ÌÉà

**Screw (ÏûëÎèô ÏïàÌïòÎäî ÌÅ¥ÎûòÏä§)**:
- Object ÌÅ¥ÎûòÏä§ + ÌöåÏ†Ñ
- Normal ÏûêÏ≤¥Í∞Ä Îß§Ïö∞ Îã§Ïñë (ÌöåÏ†Ñ)
- AnomalyÍ∞Ä Ïò§ÌûàÎ†§ ÏùºÍ¥ÄÏ†Å

### Ïôú Ïù¥Ï†Ñ Ï†ëÍ∑ºÎ≤ïÎì§Ïù¥ Ïã§Ìå®ÌñàÎäîÍ∞Ä

| Ï†ëÍ∑ºÎ≤ï | Ïã§Ìå® Ïù¥Ïú† |
|--------|-----------|
| V5.5/V5.6 Dual Branch | NormalÎßåÏúºÎ°úÎäî pos/nopos Íµ¨Î∂Ñ ÌïôÏäµ Î∂àÍ∞Ä |
| V5.7 Multi-Orientation | FeatureÏóê Ïù¥ÎØ∏ PE baked-in |
| V5.8 TAPE | NLL ‚â† AD, PE ÎÇÆÏ∂îÎäî Î∞©Ìñ•ÏúºÎ°úÎßå ÌïôÏäµ |
| V6 Rotation Aug | PE Ï∂©Îèå + NormalÏù¥ Ïù¥ÎØ∏ Îã§ÏñëÌï¥ÏÑú Ìö®Í≥º ÏóÜÏùå |
| V6 No PE | PEÍ∞Ä Ïò§ÌûàÎ†§ ÎèÑÏõÄ Ï£ºÍ≥† ÏûàÏóàÏùå (0.39‚Üí0.31) |

### ~~Í∞ÄÏÑ§: Screw Î¨∏Ï†úÎäî "Îç∞Ïù¥ÌÑ∞ ÌäπÏÑ±" Î¨∏Ï†ú~~ (ÏàòÏ†ïÎê®)

**Ïù¥ Í∞ÄÏÑ§ÏùÄ ÌãÄÎ†∏Ïùå** - ÏïÑÎûò "Screw Î¨∏Ï†ú Ïû¨Î∂ÑÏÑù: V5 Ïª¥Ìè¨ÎÑåÌä∏Í∞Ä ÏõêÏù∏" ÏÑπÏÖò Ï∞∏Ï°∞

baseline_v8.1 (Îã®Ïàú Íµ¨Ï°∞, img_size 518)ÏóêÏÑú screw **0.67** Îã¨ÏÑ±!
‚Üí Îç∞Ïù¥ÌÑ∞ Î¨∏Ï†úÍ∞Ä ÏïÑÎãå **V5 Ïª¥Ìè¨ÎÑåÌä∏ (WhiteningAdapter, SpatialMixer, DIA)Í∞Ä ÏõêÏù∏**

### Îã§Ïùå Îã®Í≥Ñ Ï†úÏïà

1. **Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ïã¨Ìôî**:
   - Ïã§Ï†ú screw Ïù¥ÎØ∏ÏßÄÎì§ÏùÑ ÏãúÍ∞ÅÏ†ÅÏúºÎ°ú Î∂ÑÏÑù
   - Normal/Anomaly Í∞Ñ feature Î∂ÑÌè¨ ÏãúÍ∞ÅÌôî

2. **Ï†ëÍ∑ºÎ≤ï Ï†ÑÌôò Í≥†Î†§**:
   - NF ÎåÄÏã† Reconstruction-based Î∞©Î≤ï (AutoEncoder Îì±)
   - ÎòêÎäî Contrastive LearningÏúºÎ°ú anomaly Ïã†Ìò∏ ÏßÅÏ†ë ÌïôÏäµ

3. **Screw Ï†ÑÏö© Ï≤òÎ¶¨**:
   - Task-specific preprocessing
   - Rotation alignment (ÌÖåÏä§Ìä∏ Ïãú canonical orientation Ï†ïÎ†¨)

---

## V6 - Rotation Augmentation

### ÏïÑÏù¥ÎîîÏñ¥

Ïù¥Ï†Ñ Ï†ëÍ∑ºÎ≤ï (V5.5-V5.8)Ïù¥ Ïã§Ìå®Ìïú Ïù¥Ïú†:
- Normal-only trainingÏóêÏÑú PE ÏµúÏ†ÅÌôî Î∞©Ìñ•ÏùÑ ÌïôÏäµ Î∂àÍ∞Ä
- Model-level Î≥ÄÍ≤ΩÎ≥¥Îã§ **Data-level** Ï†ëÍ∑ºÏù¥ Îçî Ìö®Í≥ºÏ†ÅÏùº Ïàò ÏûàÏùå

**V6 Ï†ëÍ∑ºÎ≤ï**: Random rotation augmentation
- ÌïôÏäµ Ïãú Ïù¥ÎØ∏ÏßÄÎ•º ¬±180¬∞ ÎûúÎç§ ÌöåÏ†Ñ
- Î™®Îç∏Ïù¥ ÏûêÏó∞Ïä§ÎüΩÍ≤å rotation-invariant ÌäπÏÑ± ÌïôÏäµ
- Position EncodingÏùÄ Ïú†ÏßÄ (ÌöåÏ†ÑÎêú Ïù¥ÎØ∏ÏßÄÏóê PE Ï†ÅÏö©)

### Íµ¨ÌòÑ

**ÏàòÏ†ïÎêú ÌååÏùº**:

1. **moleflow/data/mvtec.py**:
   - `use_rotation_aug`, `rotation_degrees` ÌååÎùºÎØ∏ÌÑ∞ Ï∂îÍ∞Ä
   - Training transformÏóê `T.RandomRotation` Ï∂îÍ∞Ä

2. **moleflow/data/datasets.py**:
   - `create_task_dataset`Ïóê rotation ÏÑ§Ï†ï Ï†ÑÎã¨

3. **moleflow/config/ablation.py**:
   - `use_rotation_aug: bool = False`
   - `rotation_degrees: float = 180.0`
   - CLI arguments Ï∂îÍ∞Ä

4. **run_moleflow.py**:
   - `create_task_dataset` Ìò∏Ï∂ú Ïãú rotation ÏÑ§Ï†ï Ï†ÑÎã¨

### ÏÇ¨Ïö©Î≤ï

```bash
# Rotation augmentation ÌôúÏÑ±Ìôî (¬±180¬∞)
python run_moleflow.py \
    --use_rotation_aug \
    --rotation_degrees 180.0 \
    --experiment_name Version6-RotationAug

# Îã§Î•∏ ÌöåÏ†Ñ Î≤îÏúÑ (¬±90¬∞)
python run_moleflow.py \
    --use_rotation_aug \
    --rotation_degrees 90.0 \
    --experiment_name Version6-RotationAug-90
```

### Í∏∞ÎåÄ Ìö®Í≥º

| ÌÅ¥ÎûòÏä§ | ÏòàÏÉÅ | Ïù¥Ïú† |
|--------|------|------|
| Screw | Í∞úÏÑ† | ÌöåÏ†ÑÎêú Ï†ïÏÉÅ Ïù¥ÎØ∏ÏßÄÎ°ú ÌïôÏäµ ‚Üí ÌöåÏ†ÑÏóê Î∂àÎ≥Ä |
| Leather | Ïú†ÏßÄ/ÏÜåÌè≠ ÌïòÎùΩ | TextureÎäî ÌöåÏ†ÑÏóê ÏõêÎûò Î∂àÎ≥Ä |
| Grid | Ïú†ÏßÄ | Ï£ºÍ∏∞Ï†Å Ìå®ÌÑ¥ |
| Transistor | ? | Component ÏúÑÏπòÏóê Îî∞Îùº Îã§Î•º Ïàò ÏûàÏùå |

### V6 Ïã§Ìóò Í≤∞Í≥º

| Class | Baseline | RotationAug | Î≥ÄÌôî |
|-------|----------|-------------|------|
| leather | 1.0000 | 1.0000 | = |
| grid | 0.9365 | 0.8797 | ‚Üì0.06 |
| transistor | 0.8087 | 0.6558 | ‚Üì0.15 |
| screw | 0.3900 | 0.3898 | ‚âà |
| **Mean** | 0.7838 | 0.7313 | ‚Üì0.05 |

### Î∂ÑÏÑù: Rotation Augmentation Ïã§Ìå®

**Í≤∞Í≥º**: Screw Í∞úÏÑ† ÏóÜÏùå, Grid/Transistor Ïò§ÌûàÎ†§ ÏÑ±Îä• Ï†ÄÌïò

**ÏõêÏù∏: Position EncodingÍ≥ºÏùò Ï∂©Îèå**

```
Rotation Augmentation + Fixed PE = Î™®Ïàú

Ïù¥ÎØ∏ÏßÄ: 90¬∞ ÌöåÏ†ÑÎê®
  - ÏõêÎûò (0,0)Ïóê ÏûàÎçò Ìå®Ïπò ‚Üí (0,13)ÏúºÎ°ú Ïù¥Îèô

PE: Í≥†Ï†ï Í∑∏Î¶¨Îìú
  - (0,13) ÏúÑÏπòÏóê (0,13)Ïùò PE Ï†ÅÏö©

Î¨∏Ï†ú:
  - Í∞ôÏùÄ Ìå®ÏπòÍ∞Ä Îã§Î•∏ ÏúÑÏπòÏóêÏÑú Îã§Î•∏ PEÎ•º Î∞õÏùå
  - Î™®Îç∏: "Ïù¥ Ìå®ÏπòÎäî (0,0)ÏóêÏÑú Î≥∏ Ï†Å ÏûàÎäîÎç∞ Ïôú (0,13) PEÍ∞Ä Î∂ôÏñ¥ÏûàÏßÄ?"
  - ‚Üí ÌïôÏäµ ÌòºÎûÄ ‚Üí ÏÑ±Îä• Ï†ÄÌïò
```

**ScrewÍ∞Ä Í∞úÏÑ†ÎêòÏßÄ ÏïäÏùÄ Ïù¥Ïú†**:
- Rotation augmentationÏù¥ "rotation invariance"Î•º Ï£ºÏßÄ ÏïäÏùå
- PE Î∂àÏùºÏπòÎ°ú Ïù∏Ìï¥ Ïò§ÌûàÎ†§ ÌïôÏäµÏù¥ Î∞©Ìï¥Îê®
- Í∑ºÎ≥∏Ï†ÅÏúºÎ°ú screw Î¨∏Ï†úÎäî rotationÏù¥ ÏïÑÎãå Îã§Î•∏ ÏõêÏù∏Ïùº Ïàò ÏûàÏùå

### Í≤∞Î°†

**Rotation augmentationÏùÄ PEÏôÄ Ìï®Íªò ÏÇ¨Ïö© Ïãú Ïó≠Ìö®Í≥º**

Í∞ÄÎä•Ìïú Î∞©Ìñ•:
1. **Rotation Aug + No PE**: PE ÎπÑÌôúÏÑ±ÌôîÌïòÍ≥† rotationÎßå ÏÇ¨Ïö©
2. **Rotation Aug + Rotated PE**: PEÎèÑ Ìï®Íªò ÌöåÏ†Ñ (Íµ¨ÌòÑ Î≥µÏû°)
3. **Rotation Ìè¨Í∏∞**: Îã§Î•∏ Ï†ëÍ∑ºÎ≤ï ÌÉêÏÉâ

---

## Screw Î¨∏Ï†ú Ïû¨Î∂ÑÏÑù: V5 Ïª¥Ìè¨ÎÑåÌä∏Í∞Ä ÏõêÏù∏ (2025-12-29)

### Ï§ëÏöî Î∞úÍ≤¨: baseline_v8.1Ïù¥ screwÏóêÏÑú 0.67 Îã¨ÏÑ±!

Í∏∞Ï°¥ Î™®Îì† V5/V6 Ïã§ÌóòÏóêÏÑú screwÎäî 0.44-0.47 ÏàòÏ§ÄÏù¥ÏóàÎäîÎç∞,
**baseline_v8.1_lora_rank64_all_classes**ÏóêÏÑú **0.6741** Îã¨ÏÑ±!

### ÏÑ§Ï†ï ÎπÑÍµê

| Component | baseline_v8.1 (screw 0.67) | V5 (screw 0.44) |
|-----------|----------------------------|-----------------|
| img_size | **518** | 224 |
| WhiteningAdapter | ‚ùå ÏóÜÏùå | ‚úÖ ÏÇ¨Ïö© |
| SpatialContextMixer | ‚ùå ÏóÜÏùå | ‚úÖ ÏÇ¨Ïö© |
| DIA | ‚ùå ÏóÜÏùå | ‚úÖ ÏÇ¨Ïö© |
| scale_context | ‚ùå ÏóÜÏùå | ‚úÖ ÏÇ¨Ïö© |

### Í≤∞Î°†: V5 "Í∞úÏÑ†" Ïª¥Ìè¨ÎÑåÌä∏Îì§Ïù¥ screw ÏÑ±Îä• Ï†ÄÌïòÏùò ÏõêÏù∏

**1. WhiteningAdapter (LayerNorm)**
- LayerNormÏù¥ patch Í∞Ñ ÏÉÅÎåÄÏ†Å ÌÅ¨Í∏∞ Ï†ïÎ≥¥Î•º Ï†ïÍ∑úÌôî
- ÏûëÏùÄ Í≤∞Ìï®Ïùò ÎØ∏ÏÑ∏Ìïú Ï∞®Ïù¥Í∞Ä Ìù¨ÏÑùÎê®
- ScrewÏùò ÎØ∏ÏÑ∏ Í≤∞Ìï®Ïóê ÏπòÎ™ÖÏ†Å

**2. SpatialContextMixer (3x3 context)**
- 3x3 ÏòÅÏó≠ ÌèâÍ∑†/ÏßëÍ≥Ñ
- ÏûëÏùÄ Í≤∞Ìï®Ïù¥ Ï£ºÎ≥ÄÍ≥º ÏÑûÏó¨ blurÎê®
- ScrewÏùò scratch_head, thread_side Í∞ôÏùÄ ÏûëÏùÄ Í≤∞Ìï® ÌÉêÏßÄ Ïã§Ìå®

**3. DIA (Deep Invertible Adapter)**
- TaskÎ≥Ñ Î∂ÑÌè¨ Ï†ïÎ†¨ Î™©Ï†Å
- ScrewÏùò Îã§ÏñëÌïú Ï†ïÏÉÅ Î∂ÑÌè¨Î•º Ïò§ÌûàÎ†§ ÏôúÍ≥°Ìï† Ïàò ÏûàÏùå

**4. Image Size 224 vs 518**
- 518 Ìï¥ÏÉÅÎèÑÏóêÏÑú Îçî ÎßéÏùÄ ÏÑ∏Î∂Ä Ï†ïÎ≥¥ Î≥¥Ï°¥
- Screw ÎÇòÏÇ¨ÏÇ∞ Ìå®ÌÑ¥Ïù¥ 224ÏóêÏÑú ÏÜêÏã§

### Ìï¥Í≤∞ Î∞©Ïïà

**Option 1: Screw-specific config**
```bash
# Screw ÌïôÏäµ Ïãú V5 Ïª¥Ìè¨ÎÑåÌä∏ ÎπÑÌôúÏÑ±Ìôî
python run_moleflow.py \
    --task_classes screw \
    --no_whitening_adapter \
    --no_spatial_context \
    --no_dia \
    --img_size 518
```

**Option 2: Ï†ÑÏ≤¥ Íµ¨Ï°∞ Îã®ÏàúÌôî**
- V5 Ïª¥Ìè¨ÎÑåÌä∏Îì§Ïùò Ìö®Í≥º Ïû¨Í≤ÄÏ¶ù ÌïÑÏöî
- Îã§Î•∏ ÌÅ¥ÎûòÏä§ÏóêÏÑúÎèÑ Ïã§Ï†úÎ°ú ÎèÑÏõÄÏù¥ ÎêòÎäîÏßÄ ÌôïÏù∏
- Î∂àÌïÑÏöîÌïú Î≥µÏû°ÏÑ± Ï†úÍ±∞

**Option 3: Adaptive Components**
- ÌÅ¥ÎûòÏä§ ÌäπÏÑ±(texture vs object, large vs small defect)Ïóê Îî∞Îùº Ïª¥Ìè¨ÎÑåÌä∏ ÌôúÏÑ±Ìôî
- ÌïôÏäµÎêú gateÎ°ú Ïª¥Ìè¨ÎÑåÌä∏ ÏÇ¨Ïö© Ïó¨Î∂Ä Í≤∞Ï†ï

### Ïã§Ìóò Í≥ÑÌöç

1. **baseline_v8.1 Ïä§ÌÉÄÏùºÎ°ú screw Ïû¨Ïã§Ìóò** (img_size 518, no extra components)
2. **Í∞Å Ïª¥Ìè¨ÎÑåÌä∏Î≥Ñ ablation** (WhiteningAdapterÎßå, SpatialMixerÎßå, DIAÎßå ÌÖåÏä§Ìä∏)
3. **img_size Ìö®Í≥º Î∂ÑÎ¶¨ ÌÖåÏä§Ìä∏** (518 vs 224, ÎèôÏùº Ïª¥Ìè¨ÎÑåÌä∏)

---

## Version 6.1 - Spatial Transformer Network (STN) Ïã§Ìóò Í≤∞Í≥º (2025-12-29)

### Ïã§Ìóò Î™©Ï†Å
- Screw ÌÅ¥ÎûòÏä§Ïùò rotation Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÍ∏∞ ÏúÑÌï¥ STN ÎèÑÏûÖ
- Ïù¥ÎØ∏ÏßÄ Î†àÎ≤®ÏóêÏÑú ÏûêÎèô Ï†ïÎ†¨ ‚Üí PEÏôÄ ÏùºÍ¥ÄÏÑ± Ïú†ÏßÄ

### ÏÑ§Ï†ï
```bash
CUDA_VISIBLE_DEVICES=0 python run_moleflow.py --run_diagnostics \
    --task_classes leather grid transistor screw \
    --use_whitening_adapter --use_dia \
    --score_aggregation_mode top_k --score_aggregation_top_k 3 \
    --use_tail_aware_loss --tail_weight 0.3 \
    --use_stn --stn_mode rotation \
    --stn_hidden_dim 128 --stn_rotation_reg_weight 0.01 \
    --experiment_name Version6.1-STN
```

### Í≤∞Í≥º: STN Ïã§Ìå® ‚ùå

| Class | V5 Baseline | V6.1-STN | Ï∞®Ïù¥ |
|-------|-------------|----------|------|
| leather | **1.000** | 1.000 | 0.00 |
| grid | **0.942** | 0.923 | **-1.9%** |
| transistor | **0.824** | 0.795 | **-2.9%** |
| screw | **0.443** | 0.416 | **-2.7%** |
| **Average** | **0.802** | 0.784 | **-1.8%** |

**Í≤∞Î°†: STNÏù¥ ÏÑ±Îä•ÏùÑ Ïò§ÌûàÎ†§ Ï†ÄÌïòÏãúÌÇ¥**

### Ïã§Ìå® ÏõêÏù∏ Î∂ÑÏÑù

1. **Normal-only TrainingÏùò ÌïúÍ≥Ñ**
   - STNÏù¥ Ï†ïÏÉÅ Ïù¥ÎØ∏ÏßÄÎßåÏúºÎ°ú ÌïôÏäµÎê®
   - "Canonical orientation"Ïù¥ Î¨¥ÏóáÏù∏ÏßÄ Î™ÖÌôïÌïú supervision ÏóÜÏùå
   - Anomaly detection lossÍ∞Ä STNÏóê Ïú†Ïö©Ìïú gradient Ï†úÍ≥µÌïòÏßÄ Î™ªÌï®

2. **End-to-end ÌïôÏäµ Î¨∏Ï†ú**
   - RotationÏù¥ anomaly scoreÏóê ÏßÅÏ†ëÏ†Å ÏòÅÌñ• ÎØ∏ÎØ∏
   - NLL loss ÏµúÏÜåÌôîÏôÄ rotation alignmentÍ∞Ä ÏßÅÏ†ë Ïó∞Í≤∞ÎêòÏßÄ ÏïäÏùå

3. **Identity Ï¥àÍ∏∞Ìôî + Regularization Ïó≠Ìö®Í≥º**
   - rotation_reg_weight=0.01Î°ú Î≥ÄÌôò ÏµúÏÜåÌôî Ïú†ÎèÑ
   - Í≤∞Í≥ºÏ†ÅÏúºÎ°ú Í±∞Ïùò Î≥ÄÌôòÏù¥ ÏùºÏñ¥ÎÇòÏßÄ ÏïäÏïòÏùÑ Í∞ÄÎä•ÏÑ±
   - Í∑∏Îü¨ÎÇò STN Ïó∞ÏÇ∞ ÏûêÏ≤¥Í∞Ä featureÏóê ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä

4. **Ï∂îÍ∞Ä ÌååÎùºÎØ∏ÌÑ∞Ïùò Î∂ÄÏûëÏö©**
   - Localization networkÍ∞Ä Ïù¥ÎØ∏ÏßÄÏóê Î∂àÌïÑÏöîÌïú Î≥ÄÌòï Ï∂îÍ∞Ä
   - Feature extractor ÏûÖÎ†•Ïù¥ Ïò§ÏóºÎê®

### ÏãúÏÇ¨Ï†ê

- **Ïù¥ÎØ∏ÏßÄ Î†àÎ≤® Î≥ÄÌôòÏùÄ Í∑ºÎ≥∏Ï†Å Ìï¥Í≤∞Ï±ÖÏù¥ ÏïÑÎãò**
- **Screw Î¨∏Ï†úÏùò Í∑ºÎ≥∏ ÏõêÏù∏ÏùÄ rotationÏù¥ ÏïÑÎãê Ïàò ÏûàÏùå**
- Ïù¥Ï†Ñ Î∂ÑÏÑùÏóêÏÑú Î∞úÍ≤¨Ìïú Í≤ÉÏ≤òÎüº **V5 Ïª¥Ìè¨ÎÑåÌä∏Îì§(WhiteningAdapter, SpatialMixer, DIA)Ïù¥ ÏßÑÏßú ÏõêÏù∏**
- baseline_v8.1(Îã®Ïàú Íµ¨Ï°∞)Ïù¥ screw 0.67 Îã¨ÏÑ±Ìïú Í≤ÉÏù¥ Ï¶ùÍ±∞

### Îã§Ïùå Î∞©Ìñ•

1. **V5 Ïª¥Ìè¨ÎÑåÌä∏ Ï†úÍ±∞ Ïã§Ìóò**: WhiteningAdapter, SpatialMixer, DIA ÏóÜÏù¥ ÌïôÏäµ
2. **img_size 518Î°ú Î≥ÄÍ≤Ω**: Îçî ÎÜíÏùÄ Ìï¥ÏÉÅÎèÑÏóêÏÑú ÏÑ∏Î∂Ä Ï†ïÎ≥¥ Î≥¥Ï°¥
3. **Îã®ÏàúÌïú baselineÏúºÎ°ú ÌöåÍ∑Ä**: Î≥µÏû°Ìïú Ïª¥Ìè¨ÎÑåÌä∏Í∞Ä Ïò§ÌûàÎ†§ Ìï¥Î°úÏö∏ Ïàò ÏûàÏùå

---

## Hyperparameter Tuning Ïã§Ìóò Í≤∞Í≥º (2025-12-30)

### Ïã§Ìóò Î™©Ï†Å
V5-Final baselineÏùÑ Í∏∞Ï§ÄÏúºÎ°ú screw ÏÑ±Îä• Í∞úÏÑ†ÏùÑ ÏúÑÌïú hyperparameter ÌÉêÏÉâ

### Ïã§Ìóò Íµ¨ÏÑ± (24Í∞ú Ïã§Ìóò, GPU 0/1/4/5 Î≥ëÎ†¨)

| Round | Î≥ÄÍ≤Ω ÏöîÏÜå |
|-------|----------|
| 1 | V5 Components Ï†úÍ±∞ (NoWhitening, NoDIA, Simple, Baseline) |
| 2 | Score Aggregation (TopK 1/5/10, Mean) |
| 3 | Tail-aware Loss (NoTail, 0.1, 0.5, 0.7) |
| 4 | Model Capacity (Coupling 12/16, LoRA 32/128) |
| 5 | Learning Rate & Epochs (LR 5e-5/2e-4, Epochs 60/80) |
| 6 | Combined (Simple + Ï°∞Ìï©) |

### Í≤∞Í≥º: Screw AUC Top 5

| Rank | Experiment | Screw AUC | Avg AUC | ÎπÑÍ≥† |
|------|------------|-----------|---------|------|
| 1 | **HP-NoDIA** | **0.508** | 0.699 | Grid/Transistor ÎßùÍ∞ÄÏßê |
| 2 | **HP-NoTail** | **0.504** | 0.784 | **Í∑†Ìòï Ï¢ãÏùå ‚úì** |
| 3 | HP-Epochs80 | 0.482 | 0.810 | ÏµúÍ≥† ÌèâÍ∑† |
| 4 | HP-LR2e-4 | 0.477 | 0.806 | |
| 5 | HP-TopK1 | 0.475 | 0.791 | |
| - | V5-Final (Í∏∞Ï§Ä) | 0.443 | 0.802 | |

### ÌÅ¥ÎûòÏä§Î≥Ñ ÏÉÅÏÑ∏ ÎπÑÍµê

| Experiment | Leather | Grid | Transistor | Screw | Avg |
|------------|---------|------|------------|-------|-----|
| V5-Final | 1.00 | **0.94** | **0.82** | 0.44 | 0.80 |
| HP-NoTail | 1.00 | 0.88 | 0.75 | **0.50** | 0.78 |
| HP-NoDIA | 1.00 | 0.75 | 0.55 | **0.51** | 0.70 |
| HP-Epochs80 | 1.00 | 0.91 | 0.80 | 0.48 | **0.81** |

### ÌïµÏã¨ Î∞úÍ≤¨

1. **DIA Ï†úÍ±∞** ‚Üí Screw ‚Üë6% but Îã§Î•∏ ÌÅ¥ÎûòÏä§ ÌÅ¨Í≤å ÌïòÎùΩ
2. **Tail-aware loss Ï†úÍ±∞** ‚Üí Screw ‚Üë6%, Í∑†Ìòï Ïú†ÏßÄ ‚úì
3. **Mean aggregation** ‚Üí ÏôÑÏ†Ñ Ïã§Ìå® (Screw 0.04-0.07)
4. **TopK Ï¶ùÍ∞Ä (5, 10)** ‚Üí Screw ÌïòÎùΩ
5. **Epochs 80** ‚Üí Ï†ÑÏ≤¥ ÏÑ±Îä• Ìñ•ÏÉÅ

### Î∂ÑÏÑù

**Tail-aware lossÍ∞Ä screwÏóê Ìï¥Î°úÏö¥ Ïù¥Ïú†:**
- Tail lossÎäî ÏÉÅÏúÑ 5% high-loss patchÏóê ÏßëÏ§ë
- ScrewÎäî Ï†ïÏÉÅ Ïù¥ÎØ∏ÏßÄÎèÑ variationÏù¥ ÌÅº (rotation, position)
- High-loss patchÍ∞Ä Î∞òÎìúÏãú anomalyÍ∞Ä ÏïÑÎãò ‚Üí ÏûòÎ™ªÎêú Ïã†Ìò∏Î°ú ÌïôÏäµ
- Í≤∞Í≥ºÏ†ÅÏúºÎ°ú Ï†ïÏÉÅ/ÎπÑÏ†ïÏÉÅ Íµ¨Î∂Ñ Îä•Î†• Ï†ÄÌïò

**DIAÍ∞Ä screwÏóê Ìï¥Î°úÏö¥ Ïù¥Ïú†:**
- DIAÎäî taskÎ≥Ñ nonlinear adaptation Ï†úÍ≥µ
- Îã§Î•∏ ÌÅ¥ÎûòÏä§ÏóêÏÑúÎäî ÎèÑÏõÄÏù¥ ÎêòÏßÄÎßå
- ScrewÏùò ÎÜíÏùÄ intra-class varianceÏóêÏÑúÎäî overfitting Ïú†Î∞ú
- Ï†ïÏÉÅ Î∂ÑÌè¨Î•º ÎÑàÎ¨¥ tightÌïòÍ≤å ÌïôÏäµ ‚Üí Ï†ïÏÉÅÎèÑ anomalyÎ°ú ÌåêÏ†ï

### Ï∂îÏ≤ú ÏÑ§Ï†ï

**Best Trade-off: HP-NoTail**
```bash
--use_whitening_adapter --use_dia \
--score_aggregation_mode top_k --score_aggregation_top_k 3
# tail-aware loss Ï†úÍ±∞ (--use_tail_aware_loss ÏóÜÏùå)
```

- Screw: 0.443 ‚Üí **0.504** (+13.8% ÏÉÅÎåÄ Í∞úÏÑ†)
- Average: 0.802 ‚Üí 0.784 (-2.2%)
- Îã§Î•∏ ÌÅ¥ÎûòÏä§ ÏÑ±Îä•ÏùÄ ÏïΩÍ∞Ñ ÌïòÎùΩÌïòÏßÄÎßå screw Í∞úÏÑ† Ìö®Í≥ºÍ∞Ä Îçî ÌÅº

---

## V6 Ablation Experiments - Architecture Fundamentals

### Î∞∞Í≤Ω

HP ÌäúÎãù Í≤∞Í≥º Î∂ÑÏÑù ÌõÑ, ÏïÑÌÇ§ÌÖçÏ≤ò Í∑ºÎ≥∏Ï†ÅÏù∏ Î≥ÄÍ≤ΩÏùÑ ÌÜµÌïú ablation Ïã§Ìóò ÏßÑÌñâ.

### Ïã§Ìóò ÏÑ§Í≥Ñ

| Exp | Name | ÏÑ§Î™Ö |
|-----|------|------|
| 1 | **V6-NoLoRA** | NF subnetÏùò LoRAÎ•º ÏùºÎ∞ò LinearÎ°ú ÎåÄÏ≤¥ |
| 2 | **V6-TaskSeparated** | TaskÎ≥Ñ ÏôÑÏ†Ñ Î∂ÑÎ¶¨ ÌïôÏäµ (base Í≥µÏú† ÏóÜÏùå) |
| 1+2 | **V6-NoLoRA-TaskSep** | ÏúÑ Îëê Í∞ÄÏßÄ Ï°∞Ìï© |
| 3 | **V6-SpectralNorm** | SubnetÏóê Spectral Normalization Ï†ÅÏö© |

### ÏàòÏ†ïÎêú ÌååÏùº

1. **moleflow/config/ablation.py**
   - `use_regular_linear`: LoRA ÎåÄÏã† ÏùºÎ∞ò Linear ÏÇ¨Ïö©
   - `use_task_separated`: TaskÎ≥Ñ ÎèÖÎ¶Ω ÌõàÎ†®
   - `use_spectral_norm`: Spectral Normalization Ï†ÅÏö©

2. **moleflow/models/lora.py (MoLESubnet)**
   - `use_regular_linear=True`: nn.LinearÎ°ú ÎåÄÏ≤¥, taskÎ≥Ñ Î≥ÑÎèÑ layer ÏÉùÏÑ±
   - `use_spectral_norm=True`: nn.utils.spectral_norm Ï†ÅÏö©

3. **moleflow/models/mole_nf.py**
   - make_subnetÏóê V6 ÌîåÎûòÍ∑∏ Ï†ÑÎã¨
   - add_taskÏóêÏÑú task-separated Î™®Îìú Ï≤òÎ¶¨

4. **moleflow/trainer/continual_trainer.py**
   - Task-separated Î™®Îìú: task > 0ÎèÑ _train_base_task Ïä§ÌÉÄÏùºÎ°ú ÌõàÎ†®

### Í∏∞ÎåÄ Ìö®Í≥º

1. **V6-NoLoRA**: Low-rank constraint Ï†úÍ±∞Î°ú ÌëúÌòÑÎ†• Ï¶ùÍ∞Ä
2. **V6-TaskSeparated**: Task Í∞Ñ Í∞ÑÏÑ≠ ÏôÑÏ†Ñ Ï†úÍ±∞ (upper bound Ï∏°Ï†ï)
3. **V6-SpectralNorm**: Lipschitz Ï†úÏïΩÏúºÎ°ú Îçî ÏïàÏ†ïÏ†ÅÏù∏ flow

### Ïã§Ìñâ Ïä§ÌÅ¨Î¶ΩÌä∏

```bash
./run.sh  # GPU 0, 1, 4, 5ÏóêÏÑú 4Í∞ú Ïã§Ìóò Î≥ëÎ†¨ Ïã§Ìñâ
```

### Í≤∞Í≥º

(Ïã§Ìóò ÏôÑÎ£å ÌõÑ Í∏∞Î°ù ÏòàÏ†ï)

---

## Dataset Support - VISA & MPDD

### Í∞úÏöî

MVTec AD Ïô∏Ïóê VisA(Visual Anomaly)ÏôÄ MPDD(Metal Parts Defect Detection) Îç∞Ïù¥ÌÑ∞ÏÖã ÏßÄÏõê Ï∂îÍ∞Ä.

### Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï°∞

#### VisA Dataset (/Data/VISA)
- **Classes (12Í∞ú)**: candle, capsules, cashew, chewinggum, fryum, macaroni1, macaroni2, pcb1, pcb2, pcb3, pcb4, pipe_fryum
- **Íµ¨Ï°∞**: CSV Í∏∞Î∞ò split (`split_csv/1cls.csv`)
- **Ïù¥ÎØ∏ÏßÄ**: `{class}/Data/Images/{Normal|Anomaly}/*.JPG`
- **ÎßàÏä§ÌÅ¨**: `{class}/Data/Masks/Anomaly/*.png`

#### MPDD Dataset (/Data/mpdd)
- **Classes (6Í∞ú)**: bracket_black, bracket_brown, bracket_white, connector, metal_plate, tubes
- **Íµ¨Ï°∞**: MVTec-AD Ïä§ÌÉÄÏùº ÎîîÎ†âÌÜ†Î¶¨ Íµ¨Ï°∞
- **Ïù¥ÎØ∏ÏßÄ**: `{class}/{train|test}/{good|defect_type}/*.png`
- **ÎßàÏä§ÌÅ¨**: `{class}/ground_truth/{defect_type}/*_mask.png`

### ÏÉàÎ°ú Ï∂îÍ∞ÄÎêú ÌååÏùº

1. **moleflow/data/visa.py**
   - `VISA` ÌÅ¥ÎûòÏä§: CSV Í∏∞Î∞ò Îç∞Ïù¥ÌÑ∞ Î°úÎî©
   - `VISA_CLASS_NAMES`: 12Í∞ú ÌÅ¥ÎûòÏä§ Î™©Î°ù

2. **moleflow/data/mpdd.py**
   - `MPDD` ÌÅ¥ÎûòÏä§: MVTec-AD Ïä§ÌÉÄÏùº ÎîîÎ†âÌÜ†Î¶¨ Ïä§Ï∫î
   - `MPDD_CLASS_NAMES`: 6Í∞ú ÌÅ¥ÎûòÏä§ Î™©Î°ù

### ÏàòÏ†ïÎêú ÌååÏùº

1. **moleflow/data/datasets.py**
   - `DATASET_REGISTRY`: Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§ Î†àÏßÄÏä§Ìä∏Î¶¨
   - `get_dataset_class(name)`: Ïù¥Î¶ÑÏúºÎ°ú Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§ Î∞òÌôò
   - `get_class_names(name)`: Îç∞Ïù¥ÌÑ∞ÏÖãÏùò ÌÅ¥ÎûòÏä§ Î™©Î°ù Î∞òÌôò
   - `create_task_dataset()`: `args.dataset` Í∏∞Î∞òÏúºÎ°ú ÏûêÎèô ÏÑ†ÌÉù

2. **moleflow/data/__init__.py**
   - VISA, MPDD Í¥ÄÎ†® export Ï∂îÍ∞Ä

3. **moleflow/__init__.py**
   - VISA, MPDD, Ïú†Ìã∏Î¶¨Ìã∞ Ìï®Ïàò export

4. **run_moleflow.py**
   - `--dataset` Ïù∏Ïûê Ï∂îÍ∞Ä (mvtec, visa, mpdd)
   - Î°úÍ∑∏Ïóê dataset Ï†ïÎ≥¥ Ï∂úÎ†•

### ÏÇ¨Ïö©Î≤ï

```bash
# VisA Îç∞Ïù¥ÌÑ∞ÏÖãÏúºÎ°ú Ïã§Ìóò
python run_moleflow.py \
    --dataset visa \
    --data_path /Data/VISA \
    --task_classes candle capsules cashew

# MPDD Îç∞Ïù¥ÌÑ∞ÏÖãÏúºÎ°ú Ïã§Ìóò
python run_moleflow.py \
    --dataset mpdd \
    --data_path /Data/mpdd \
    --task_classes bracket_black bracket_brown connector

# Í∏∞Î≥∏ MVTec (Î≥ÄÍ≤Ω ÏóÜÏùå)
python run_moleflow.py \
    --dataset mvtec \
    --data_path /Data/MVTecAD \
    --task_classes leather grid transistor
```

### Í≤ÄÏ¶ù Í≤∞Í≥º

```
VISA candle train samples: 900
VISA candle test samples: 200
MPDD bracket_black train samples: 289
MPDD bracket_black test samples: 79
```

---

## Bug Fix - VISA/MPDD Îç∞Ïù¥ÌÑ∞ÏÖã ÌèâÍ∞Ä Ïò§Î•ò ÏàòÏ†ï (2025-12-31)

### Î¨∏Ï†ú
- VISA/MPDD Îç∞Ïù¥ÌÑ∞ÏÖãÏúºÎ°ú ÌïôÏäµ ÌõÑ **test Îã®Í≥ÑÏóêÏÑú ÏóêÎü¨ Î∞úÏÉù**
- ÌèâÍ∞Ä Ìï®ÏàòÍ∞Ä MVTEC Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ ÌïòÎìúÏΩîÎî©ÌïòÏó¨ ÏÇ¨Ïö©

### ÏõêÏù∏
`moleflow/evaluation/evaluator.py`Ïùò `evaluate_class`ÏôÄ `evaluate_routing_performance` Ìï®ÏàòÍ∞Ä `args.dataset` Í∞íÍ≥º Í¥ÄÍ≥ÑÏóÜÏù¥ Ìï≠ÏÉÅ MVTEC Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§Î•º ÏÇ¨Ïö©:

```python
# Î¨∏Ï†ú ÏΩîÎìú
from moleflow.data.mvtec import MVTEC
test_dataset = MVTEC(args.data_path, class_name=class_name, ...)
```

### Ìï¥Í≤∞Ï±Ö
`args.dataset`Ïóê Îî∞Îùº Ï†ÅÏ†àÌïú Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§Î•º ÎèôÏ†ÅÏúºÎ°ú ÏÑ†ÌÉùÌïòÎèÑÎ°ù ÏàòÏ†ï:

```python
# ÏàòÏ†ïÎêú ÏΩîÎìú
from moleflow.data.datasets import get_dataset_class

dataset_name = getattr(args, 'dataset', 'mvtec')
DatasetClass = get_dataset_class(dataset_name)
test_dataset = DatasetClass(args.data_path, class_name=class_name, ...)
```

### ÏàòÏ†ïÎêú ÌååÏùº
- `moleflow/evaluation/evaluator.py`
  - `evaluate_class()` Ìï®Ïàò
  - `evaluate_routing_performance()` Ìï®Ïàò

---
