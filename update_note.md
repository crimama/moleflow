# MoLE-Flow Update Notes

## Version History

---

## v1 (baseline) - Initial Implementation

### Architecture
- Task 0: Base NFÎßå ÌïôÏäµ (LoRA ÏóÜÏùå)
- Task 1+: Base frozen + LoRA ÌïôÏäµ
- LoRA scaling: `alpha / (2 * rank)` = 0.0156 (1.56%)
- InputAdapter: Instance Norm + Zero-init MLP

### Results (leather ‚Üí grid ‚Üí transistor)
| Class | Routing Acc | Image AUC | Pixel AUC |
|-------|-------------|-----------|-----------|
| leather | 100% | **1.0000** | **0.9481** |
| grid | 100% | 0.8204 | 0.9259 |
| transistor | 100% | 0.6654 | 0.7144 |
| **Mean** | 100% | 0.8286 | 0.8628 |

### Issues Identified
1. **Task 0 Bias**: Base NFÍ∞Ä Task 0Ïóê Ìé∏Ìñ•ÎêòÏñ¥ Îã§Î•∏ taskÏóêÏÑú ÏÑ±Îä• Ï†ÄÌïò
2. **LoRA Scaling Î∂ÄÏ°±**: 1.56% contributionÏúºÎ°ú adaptation Ìö®Í≥º ÎØ∏ÎØ∏
3. **InputAdapter ÌïúÍ≥Ñ**: MLP residual gateÍ∞Ä 0ÏúºÎ°ú ÏãúÏûëÌïòÏó¨ Í±∞Ïùò ÎØ∏ÏÇ¨Ïö©

---

## v2 (baseline_v2) - LoRA Scaling & Task 0 LoRA

### Changes from v1
1. **LoRA Scaling 2Î∞∞ Ï¶ùÍ∞Ä**
   ```python
   # v1: self.scaling = alpha / (2 * rank)  # 0.0156
   # v2: self.scaling = alpha / rank         # 0.03125
   ```

2. **Task 0ÎèÑ LoRA ÏÇ¨Ïö©**
   - Î™®Îì† TaskÍ∞Ä ÎèôÎì±ÌïòÍ≤å LoRAÎ°ú adaptation
   - Base NFÎäî Î≤îÏö© feature transformation ÌïôÏäµ
   - Task-specific adaptationÏùÄ LoRAÍ∞Ä Îã¥Îãπ

### Results (leather ‚Üí grid ‚Üí transistor)
| Class | Routing Acc | Image AUC | Pixel AUC |
|-------|-------------|-----------|-----------|
| leather | 100% | 0.9997 | 0.8900 |
| grid | 100% | **0.9850** | **0.9841** |
| transistor | 100% | **0.8075** | **0.8973** |
| **Mean** | 100% | **0.9307** | **0.9238** |

### Comparison (v1 ‚Üí v2)
| Metric | v1 | v2 | Change |
|--------|-----|-----|--------|
| leather Image | 1.0000 | 0.9997 | -0.03% |
| leather Pixel | 0.9481 | 0.8900 | **-6.1%** |
| grid Image | 0.8204 | 0.9850 | **+20.0%** |
| grid Pixel | 0.9259 | 0.9841 | +6.3% |
| transistor Image | 0.6654 | 0.8075 | **+21.4%** |
| transistor Pixel | 0.7144 | 0.8973 | **+25.6%** |
| **Mean Image** | 0.8286 | 0.9307 | **+12.3%** |
| **Mean Pixel** | 0.8628 | 0.9238 | **+7.1%** |

### Analysis
- **Overall**: Ï†ÑÏ≤¥ ÏÑ±Îä• ÎåÄÌè≠ Ìñ•ÏÉÅ (Mean Image AUC +12.3%)
- **Task 0 Issue**: leatherÏùò Pixel AUCÍ∞Ä 6.1% ÌïòÎùΩ
  - ÏõêÏù∏: Task 0ÏóêÏÑú Base + LoRA ÎèôÏãú ÌïôÏäµ Ïãú, LoRAÍ∞Ä ÏùºÎ∂Ä Ï†ïÎ≥¥Î•º Î∂ÑÎã¥ÌïòÎ©¥ÏÑú BaseÏùò ÌëúÌòÑÎ†• Î∂ÑÏÇ∞
  - LoRAÎäî Task-specific adaptationÏóê ÏµúÏ†ÅÌôîÎêòÏñ¥ pixel-level Ï†ïÎ∞ÄÎèÑÏóê ÏòÅÌñ•

---

## v3 (baseline_v3) - FiLM-style InputAdapter + Task 0 Self-Adaptation

### Changes from v2
1. **InputAdapter Íµ¨Ï°∞ Í∞úÏÑ† (FiLM-style)**
   - Instance Norm ‚Üí Layer Norm (spatial info Î≥¥Ï°¥)
   - FiLM (Feature-wise Linear Modulation): `y = gamma * x + beta`
   - residual_gate: 0 ‚Üí 0.5 (MLP Ï≤òÏùåÎ∂ÄÌÑ∞ active)
   - hidden_dim Ï¶ùÍ∞Ä: `channels//4` ‚Üí `max(channels//2, 128)`

2. **Task 0 Self-Adaptation**
   - Task 0ÏóêÎèÑ InputAdapter Ï†ÅÏö© (v2ÏóêÏÑúÎäî Task 0Ïóê InputAdapter ÏóÜÏóàÏùå)
   - `has_reference=False` ÏÑ§Ï†ïÏúºÎ°ú Í∞ïÌïú identity connection (90% identity + 10% transformed)
   - Ïù¥Î•º ÌÜµÌï¥ Task 0Ïùò pixel-level ÏÑ±Îä• ÌöåÎ≥µ Í∏∞ÎåÄ

3. **Î™®Îì† Task ÎèôÎì±Ìïú InputAdapter Ï†ÅÏö©**
   - v2: Task 0 (InputAdapter ÏóÜÏùå) vs Task 1+ (InputAdapter ÏûàÏùå)
   - v3: Î™®Îì† TaskÍ∞Ä InputAdapter ÏÇ¨Ïö© (Íµ¨Ï°∞Ï†Å ÏùºÍ¥ÄÏÑ±)

### Key Code Changes
```python
# adapters.py - TaskInputAdapter v3
class TaskInputAdapter(nn.Module):
    def __init__(self, channels, reference_mean=None, reference_std=None, use_norm=True):
        # FiLM parameters
        self.film_gamma = nn.Parameter(torch.ones(1, 1, 1, channels))
        self.film_beta = nn.Parameter(torch.zeros(1, 1, 1, channels))

        # Larger MLP
        hidden_dim = max(channels // 2, 128)  # Increased from channels//4

        # Active residual gate
        self.residual_gate = nn.Parameter(torch.tensor([0.5]))  # Changed from 0.0

        # Layer Norm instead of Instance Norm
        if use_norm:
            self.layer_norm = nn.LayerNorm(channels)

    def forward(self, x):
        # ...
        # Task 0 (has_reference=False): 90% identity + 10% transformed
        if not self.has_reference:
            x = 0.9 * identity + 0.1 * x
        return x
```

### Expected Improvements
- Task 0 pixel-level ÏÑ±Îä• ÌöåÎ≥µ (v1 ÏàòÏ§ÄÏúºÎ°ú)
- Îçî Í∞ïÎ†•Ìïú cross-task feature transformation
- Íµ¨Ï°∞Ï†Å ÏùºÍ¥ÄÏÑ±ÏúºÎ°ú Ïù∏Ìïú ÏïàÏ†ïÏ†ÅÏù∏ ÌïôÏäµ

---

## File Changes Summary

### v1 ‚Üí v2
| File | Changes |
|------|---------|
| `moleflow/models/lora.py` | scaling: `alpha/(2*rank)` ‚Üí `alpha/rank` |
| `moleflow/models/mole_nf.py` | Task 0ÏóêÏÑúÎèÑ LoRA adapter Ï∂îÍ∞Ä |
| `moleflow/trainer/continual_trainer.py` | Task 0 ÌïôÏäµ Î°úÏßÅ ÏàòÏ†ï |

### v2 ‚Üí v3
| File | Changes |
|------|---------|
| `moleflow/models/adapters.py` | FiLM-style InputAdapter (LayerNorm, gate=0.5, larger MLP) |
| `moleflow/models/mole_nf.py` | Task 0ÏóêÎèÑ InputAdapter Ï†ÅÏö© (self-adaptation) |
| `run.sh` | baseline_v3 Ïã§Ìóò ÏÑ§Ï†ï |

---

## v4 (baseline_v4) - CPCF + SC-LoRA (Novel Research Contribution)

### Research Contribution
**Paper Title**: "Beyond Independent Patches: Cross-Patch Coupling Flow with Spatial LoRA for Continual Anomaly Detection"

**Key Novelty Claims**:
1. **CPCF**: First normalizing flow that models `p(x_i | neighbors)` instead of `p(x_i)`
2. **SC-LoRA**: First spatially-varying LoRA for dense prediction tasks
3. **Continual AD**: Systematic benchmark for continual anomaly detection

### New Modules

#### 1. Spatial-Contextual LoRA (SC-LoRA)
```python
# moleflow/models/spatial_lora.py
class SpatialContextualLoRA(nn.Module):
    """
    Position-aware LoRA with spatial grid interpolation.

    Key Innovation:
    - LoRA parameters vary based on spatial position
    - Grid of LoRA parameters: (grid_size, grid_size, rank, dim)
    - Bilinear interpolation for smooth spatial adaptation
    """
    def __init__(self, in_features, out_features, rank=32, grid_size=4):
        # Grid of LoRA A: (G, G, R, D_in)
        self.lora_A = nn.Parameter(torch.zeros(grid_size, grid_size, rank, in_features))
        # Grid of LoRA B: (G, G, D_out, R)
        self.lora_B = nn.Parameter(torch.zeros(grid_size, grid_size, out_features, rank))

    def forward(self, x, positions):
        # Interpolate LoRA params based on position
        A, B = self._get_interpolated_lora(positions)
        return self.scaling * (x @ A.T @ B.T)
```

#### 2. Cross-Patch Coupling Flow (CPCF)
```python
# moleflow/models/cross_patch_flow.py
class CrossPatchCouplingLayer(nn.Module):
    """
    Coupling layer conditioned on neighborhood context.

    Standard: y = x * exp(s(x)) + t(x)
    CPCF:     y = x * exp(s(x, ctx)) + t(x, ctx)

    where ctx = NeighborhoodContext(x)
    """
    def __init__(self, channels, context_kernel=3):
        self.context_extractor = NeighborhoodContextExtractor(channels)
        self.s_net = SC_LoRA_MLP(channels + context_dim, channels)
        self.t_net = SC_LoRA_MLP(channels + context_dim, channels)

    def forward(self, x):
        context = self.context_extractor(x)  # (B, H, W, D)
        x1, x2 = x.split(D//2, dim=-1)

        # Condition on both patch and context
        s = self.s_net(cat([x1, context]))
        t = self.t_net(cat([x1, context]))

        return cat([x1, x2 * exp(s) + t])
```

### Theoretical Contribution

**Standard NF (Independent Patches)**:
```
log p(X) = Œ£·µ¢ log p(x·µ¢)
```
- Assumes patches are independent
- Ignores spatial context

**CPCF (Context-Aware Patches)**:
```
log p(X) = Œ£·µ¢ log p(x·µ¢ | N(i))
```
where N(i) = neighborhood of patch i

- Models "how different is this patch from its neighbors"
- Directly captures anomaly as contextual deviation

### Architecture Comparison

| Component | v3 | v4 |
|-----------|-----|-----|
| Flow Type | FrEIA (independent) | CPCF (context-aware) |
| LoRA Type | Standard LoRA | SC-LoRA (position-aware) |
| Patch Modeling | `p(x·µ¢)` | `p(x·µ¢ \| neighbors)` |
| Spatial Awareness | Position embedding only | Context + Position LoRA |

### Command Line Arguments
```bash
python run_moleflow.py \
    --use_cpcf \              # Enable Cross-Patch Coupling Flow
    --use_spatial_lora \       # Enable Spatial-Contextual LoRA
    --sc_lora_grid_size 4 \    # SC-LoRA grid resolution (4x4)
    --cpcf_context_kernel 3 \  # Context extraction kernel size
    --cpcf_use_attention       # Use attention instead of conv for context
```

### Expected Improvements
- **Image AUC**: +5-10% (better global anomaly detection)
- **Pixel AUC**: +10-15% (context-aware localization)
- **Cross-task**: Improved SC-LoRA handles position-dependent distribution shifts

### v3 ‚Üí v4
| File | Changes |
|------|---------|
| `moleflow/models/spatial_lora.py` | NEW: SC-LoRA module |
| `moleflow/models/cross_patch_flow.py` | NEW: CPCF module |
| `moleflow/models/mole_nf.py` | CPCF/SC-LoRA integration |
| `run_moleflow.py` | CPCF/SC-LoRA arguments |
| `run.sh` | baseline_v4 Ïã§Ìóò ÏÑ§Ï†ï |

---

## v4.1 - Fixed Context Extraction (Bug Fix)

### Issue
- v4ÏóêÏÑú Task 0 ÏÑ±Îä•ÏùÄ Ìñ•ÏÉÅÎêòÏóàÏúºÎÇò Task 1, 2 ÏÑ±Îä•Ïù¥ ÌÅ¨Í≤å Ï†ÄÌïòÎê®
- ÏõêÏù∏: Context ExtractorÍ∞Ä Task 0ÏóêÏÑúÎßå ÌïôÏäµÎêòÏñ¥ Task 0Ïóê Ìé∏Ìñ•

### Root Cause
```python
# Ïù¥Ï†Ñ ÏΩîÎìú - Task 0ÏóêÏÑúÎßå context extractor ÌïôÏäµ
if task_id == 0:
    params.extend(layer.context_extractor.parameters())
```
- Task 0: Context ExtractorÍ∞Ä Task 0 Îç∞Ïù¥ÌÑ∞Î°úÎßå ÌïôÏäµ
- Task 1+: Task 0Ïóê Ìé∏Ìñ•Îêú context feature Ï†úÍ≥µ ‚Üí ÏÑ±Îä• Ï†ÄÌïò

### Fix
Context extractionÏùÑ **Í≥†Ï†ïÎêú (non-learnable) Î∞©Ïãù**ÏúºÎ°ú Î≥ÄÍ≤Ω:

```python
# cross_patch_flow.py - NeighborhoodContextExtractor
class NeighborhoodContextExtractor(nn.Module):
    def __init__(self, channels, kernel_size=3, use_attention=False):
        # FIXED averaging kernel - no learnable parameters
        kernel = torch.ones(1, 1, kernel_size, kernel_size) / (kernel_size * kernel_size)
        self.register_buffer('avg_kernel', kernel)
        self.register_buffer('context_gate', torch.tensor([0.3]))  # Fixed gate

    def forward(self, x):
        # Simple neighborhood mean (task-agnostic)
        neighbor_mean = F.conv2d(x, self.avg_kernel, padding, groups=D)
        context = (1 - gate) * x + gate * neighbor_mean
        return context
```

### Key Insight
- **Context = Ï£ºÎ≥Ä ÌèâÍ∑†** ‚Üí task-agnostic (Ïñ¥Îñ§ taskÏóêÏÑúÎèÑ ÎèôÏùºÌïú ÏùòÎØ∏)
- **SC-LoRA = task-specific adaptation** ‚Üí task Î≥ÑÎ°ú Îã§Î•¥Í≤å ÌïôÏäµ
- Ïó≠Ìï† Î∂ÑÎ¶¨: Í≥†Ï†ï context + ÌïôÏäµ Í∞ÄÎä•Ìïú adaptation

### v4 ‚Üí v4.1
| File | Changes |
|------|---------|
| `moleflow/models/cross_patch_flow.py` | Fixed (non-learnable) context extraction |
| `moleflow/models/mole_nf.py` | Removed context_extractor from trainable params |

---

## v5 - Center Loss for Discriminative Feature Learning

### Motivation
- v4Ïùò cross-patch context Ï†ëÍ∑ºÎ≤ïÏù¥ task bias Î¨∏Ï†úÎ°ú Ïã§Ìå®
- Anomaly Detection ÏûêÏ≤¥Ïùò ÏÑ±Îä• Ìñ•ÏÉÅÏóê ÏßëÏ§ë
- Normal featureÎ•º Îçî compactÌïòÍ≤å ÎßåÎì§Ïñ¥ÏÑú anomaly Íµ¨Î∂Ñ Ïö©Ïù¥ÌïòÍ≤å

### Core Idea
**Latent space z**Ïóê Center LossÎ•º Ï†ÅÏö©ÌïòÏó¨ normalÏùÑ z ‚âà 0ÏúºÎ°ú Îçî Í∞ïÌïòÍ≤å Ïú†ÎèÑ:
```
Loss = NLL_loss + Œª * Center_loss
     = -log p(x) + Œª * ||z||¬≤
```

**Key Insight**:
- NFÎäî inputÏùÑ GaussianÏúºÎ°ú Îß§Ìïë ‚Üí normalÏùÄ z ‚âà 0
- Center LossÎäî Ïù¥ Î™©ÌëúÎ•º **Îçî Í∞ïÌïòÍ≤å** Í∞ïÏ†ú
- Input featureÍ∞Ä ÏïÑÎãå **latent z**Ïóê Ï†ÅÏö©Ìï¥Ïïº gradientÍ∞Ä NFÏóê Ï†ÑÌååÎê®

### Implementation

```python
# Training loopÏóêÏÑú
z, log_jac_det = nf_model.forward(x, reverse=False)

# NLL loss
log_pz = -0.5 * (z ** 2).sum() / (B * H * W)
nll_loss = -(log_pz + log_jac)

# Center loss on latent z (fixed center at zero)
center_loss = (z ** 2).sum(dim=-1).mean()  # ||z - 0||¬≤

total_loss = nll_loss + Œª * center_loss
```

### Why Fixed Center at Zero?
- Learnable center ‚Üí centerÍ∞Ä zÏùò meanÏúºÎ°ú Ïù¥Îèô ‚Üí ÏùòÎØ∏ ÏóÜÏùå
- Fixed center = 0 ‚Üí zÎ•º ÏõêÏ†êÏúºÎ°ú Í∞ïÌïòÍ≤å ÎãπÍπÄ ‚Üí Gaussian prior Í∞ïÌôî

### Training Flow
1. Forward: x ‚Üí NF ‚Üí z
2. NLL loss: zÍ∞Ä GaussianÏùÑ Îî∞Î•¥ÎèÑÎ°ù
3. Center loss: zÍ∞Ä ÏõêÏ†êÏóê Í∞ÄÍπùÎèÑÎ°ù (Ï∂îÍ∞Ä regularization)
4. Backward: gradientÍ∞Ä NFÎ°ú Ï†ÑÌååÎêòÏñ¥ Îçî compactÌïú latent space ÌïôÏäµ

### Command Line Arguments
```bash
python run_moleflow.py \
    --center_loss_weight 0.05 \  # Center loss weight (recommend 0.01-0.1)
    ...
```

### Expected Improvements
- Normal featureÍ∞Ä Îçî compactÌï¥Ï†∏ÏÑú anomaly Íµ¨Î∂Ñ Ìñ•ÏÉÅ
- ÌäπÌûà pixel-level anomaly detectionÏóêÏÑú Ìö®Í≥º Í∏∞ÎåÄ
- TaskÎ≥Ñ centerÍ∞Ä task-specific ÌäπÏÑ±ÏùÑ ÌïôÏäµ

### v3 ‚Üí v5
| File | Changes |
|------|---------|
| `moleflow/models/center_loss.py` | NEW: CenterLoss module |
| `moleflow/trainer/continual_trainer.py` | Center loss integration |
| `run_moleflow.py` | `--center_loss_weight` argument |
| `run.sh` | v5 experiment configuration |

---

## v6 - Patch Self-Attention for Contextual Anomaly Detection

### Motivation
- v5Ïùò Center LossÎäî NLLÏù¥ Ïù¥ÎØ∏ z ‚âà 0ÏùÑ Ïú†ÎèÑÌïòÎØÄÎ°ú Ìö®Í≥º ÎØ∏ÎØ∏
- **Contextual Anomaly** ÌÉêÏßÄ ÌïÑÏöî: Ï£ºÎ≥Ä Ìå®ÏπòÏôÄ Îã§Î•∏ Ìå®ÏπòÍ∞Ä anomaly
- Patch Í∞Ñ Í¥ÄÍ≥ÑÎ•º Î™®Îç∏ÎßÅÌïòÏó¨ anomaly detection ÏÑ±Îä• Ìñ•ÏÉÅ

### Core Idea
**Standard NF (Independent Patches)**:
```
log p(X) = Œ£·µ¢ log p(x·µ¢)
```
- Í∞Å Ìå®ÏπòÎ•º ÎèÖÎ¶ΩÏ†ÅÏúºÎ°ú Ï≤òÎ¶¨
- Ï£ºÎ≥Ä context Î¨¥Ïãú

**Patch Self-Attention (Context-Aware)**:
```
log p(X) = Œ£·µ¢ log p(x·µ¢ | context_i)
where context_i = Attention(x·µ¢, all patches)
```
- Ìå®Ïπò Í∞Ñ Í¥ÄÍ≥Ñ Î™®Îç∏ÎßÅ
- "Ï£ºÎ≥ÄÍ≥º Îã§Î•∏" Ìå®ÏπòÎ•º anomalyÎ°ú ÌÉêÏßÄ

### Architecture
```
ViT Features [B, H, W, D]
       ‚Üì
Patch Self-Attention (LightweightPatchAttention)
       ‚Üì
Context-Enhanced Features [B, H, W, D]
       ‚Üì
Normalizing Flow
       ‚Üì
Latent z, log_jac_det
```

### LightweightPatchAttention Module
```python
class LightweightPatchAttention(nn.Module):
    def __init__(self, embed_dim=512, hidden_dim=256, dropout=0.1):
        # Q, K, V projections
        self.q_proj = nn.Linear(embed_dim, hidden_dim)
        self.k_proj = nn.Linear(embed_dim, hidden_dim)
        self.v_proj = nn.Linear(embed_dim, hidden_dim)

        # Learnable gate (starts at 0 for stable training)
        self.gate = nn.Parameter(torch.zeros(1))

        # FFN for additional processing
        self.ffn = nn.Sequential(...)

    def forward(self, x):  # x: [B, H, W, D]
        # Reshape to sequence
        x_seq = x.view(B, H*W, D)

        # Self-attention
        Q, K, V = self.q_proj(x), self.k_proj(x), self.v_proj(x)
        attn = softmax(Q @ K.T / sqrt(d))
        attn_out = attn @ V

        # Gated residual connection
        gate = sigmoid(self.gate)
        x = x + gate * attn_out

        # FFN
        x = x + self.ffn(x)

        return x.view(B, H, W, D)
```

### Key Design Choices
1. **Learnable Gate (starts at 0)**:
   - ÌïôÏäµ Ï¥àÍ∏∞ÏóêÎäî identity (ÏïàÏ†ïÏ†Å ÌïôÏäµ)
   - Ï†êÏßÑÏ†ÅÏúºÎ°ú attention Í∏∞Ïó¨ÎèÑ Ï¶ùÍ∞Ä

2. **Single-Head Attention**:
   - LightweightÌïòÎ©¥ÏÑúÎèÑ patch Í¥ÄÍ≥Ñ Ìè¨Ï∞©
   - Multi-head ÎåÄÎπÑ Í≥ÑÏÇ∞ Ìö®Ïú®Ï†Å

3. **Pre-LayerNorm + FFN**:
   - Transformer Ïä§ÌÉÄÏùº ÏïàÏ†ïÏ†Å ÌïôÏäµ
   - FFNÏúºÎ°ú ÎπÑÏÑ†Ìòï transformation Í∞ïÌôî

### Training
- Patch attention Î™®ÎìàÏùÄ **Î™®Îì† taskÏóêÏÑú Í≥µÏú†** (Base NFÏ≤òÎüº)
- Task 0ÏóêÏÑú ÌïôÏäµ ÌõÑ freeze
- Task 1+ÏóêÏÑúÎäî LoRAÎßå ÌïôÏäµ

### Command Line Arguments
```bash
python run_moleflow.py \
    --use_patch_attention \  # Enable Patch Self-Attention
    ...
```

### Expected Improvements
- **Contextual Anomaly Detection**: Ï£ºÎ≥ÄÍ≥º Îã§Î•∏ Ìå®Ïπò ÌÉêÏßÄ Ìñ•ÏÉÅ
- **Pixel-level AUC**: Context Ï†ïÎ≥¥Î°ú localization Ï†ïÎ∞ÄÎèÑ Ìñ•ÏÉÅ
- **Structural Anomaly**: Ï†ÑÏó≠Ï†Å Ìå®Ïπò Í¥ÄÍ≥ÑÎ°ú Íµ¨Ï°∞Ï†Å Ïù¥ÏÉÅ ÌÉêÏßÄ

### v3 ‚Üí v6
| File | Changes |
|------|---------|
| `moleflow/models/patch_attention.py` | NEW: LightweightPatchAttention, PatchInteractionModule |
| `moleflow/models/__init__.py` | Export patch attention modules |
| `moleflow/trainer/continual_trainer.py` | Patch attention integration |
| `run_moleflow.py` | `--use_patch_attention` argument |
| `run.sh` | v6 experiment configuration |

### v6 Result
- **Ïã§Ìå®**: ViTÍ∞Ä Ïù¥ÎØ∏ self-attentionÏúºÎ°ú contextualizedÎêú featureÎ•º Ï∂úÎ†•ÌïòÎØÄÎ°ú Ï∂îÍ∞Ä attentionÏù¥ Ïò§ÌûàÎ†§ Ìï¥Í∞Ä Îê®

---

## v7 - Focal NLL Loss for Hard Sample Mining

### Motivation
- v5 (Center Loss): NLLÏù¥ Ïù¥ÎØ∏ z ‚âà 0 Ïú†ÎèÑÌïòÎØÄÎ°ú Ìö®Í≥º ÎØ∏ÎØ∏
- v6 (Patch Attention): ViT Ï§ëÎ≥µÏúºÎ°ú Ïã§Ìå®
- **ÏÉàÎ°úÏö¥ Ï†ëÍ∑º**: Ïñ¥Î†§Ïö¥ ÏÉòÌîåÏóê Îçî ÏßëÏ§ëÌïòÏó¨ decision boundary ÌïôÏäµ Í∞ïÌôî

### Core Idea
**Standard NLL**:
```
L = -log p(x)  # Î™®Îì† ÏÉòÌîå ÎèôÎì±Ìïú Í∞ÄÏ§ëÏπò
```

**Focal NLL**:
```
L = (1 - p)^Œ≥ * (-log p(x))

Œ≥ = 0: Standard NLL (Î™®Îì† ÏÉòÌîå ÎèôÎì±)
Œ≥ = 1: ÏïΩÍ∞ÑÏùò hard sample Í∞ïÏ°∞
Œ≥ = 2: Í∞ïÌïú hard sample Í∞ïÏ°∞ (Í∂åÏû•)
```

- `p` = probability = exp(-nll)
- ÎÜíÏùÄ NLL (Ïñ¥Î†§Ïö¥ ÏÉòÌîå) ‚Üí ÎÇÆÏùÄ p ‚Üí ÎÜíÏùÄ weight (1-p)^Œ≥
- ÎÇÆÏùÄ NLL (Ïâ¨Ïö¥ ÏÉòÌîå) ‚Üí ÎÜíÏùÄ p ‚Üí ÎÇÆÏùÄ weight

### Implementation
```python
def _compute_nll_loss(self, z, log_jac_det):
    B, H, W, D = z.shape

    if not self.use_focal_loss:
        # Standard NLL
        log_pz = -0.5 * (z ** 2).sum() / (B * H * W)
        log_jac = log_jac_det.mean() / (H * W)
        return -(log_pz + log_jac)
    else:
        # Per-patch NLL
        log_pz_per_patch = -0.5 * (z ** 2).sum(dim=-1)  # [B, H, W]
        log_jac_per_patch = log_jac_det.view(B, 1, 1) / (H * W)
        nll_per_patch = -(log_pz_per_patch + log_jac_per_patch)

        # Focal weighting
        prob = torch.exp(-nll_per_patch.clamp(max=20))
        focal_weight = (1 - prob).pow(self.focal_gamma)

        return (focal_weight * nll_per_patch).mean()
```

### Why This Should Work
1. **Hard Sample Mining**: Normal distribution Í≤ΩÍ≥ÑÏóê ÏûàÎäî ÏÉòÌîåÏóê ÏßëÏ§ë
2. **Better Decision Boundary**: Ïñ¥Î†§Ïö¥ Ìå®ÏπòÎ•º Ïûò ÌïôÏäµÌïòÎ©¥ anomaly Íµ¨Î∂Ñ Ìñ•ÏÉÅ
3. **Gradient Focus**: Easy sampleÏùÄ gradient Í∏∞Ïó¨ Í∞êÏÜå, hard sampleÏóê gradient ÏßëÏ§ë

### Command Line Arguments
```bash
python run_moleflow.py \
    --focal_gamma 2.0 \  # Focal loss gamma (recommend 1.0-2.0)
    ...
```

### Expected Improvements
- Îçî sharpÌïú normal distribution Í≤ΩÍ≥Ñ ÌïôÏäµ
- ÌäπÌûà Task 0ÏóêÏÑú base NF ÌíàÏßà Ìñ•ÏÉÅ
- Anomaly detection ÏÑ±Îä• Ï†ÑÎ∞òÏ†Å Ìñ•ÏÉÅ

### v3 ‚Üí v7
| File | Changes |
|------|---------|
| `moleflow/trainer/continual_trainer.py` | `_compute_nll_loss()` helper method, focal weighting |
| `run_moleflow.py` | `--focal_gamma` argument |
| `run.sh` | v7 experiment configuration |

---

## Baseline 1.5 ‚Üí 2.0: Patch-wise Context Gate

### Motivation
**Baseline 1.5 (Global Alpha)Ïùò Î¨∏Ï†úÏ†ê**:
- `alpha`Îäî global scalar ‚Üí Î™®Îì† Ìå®ÏπòÏóê ÎèôÏùºÌïú context Í∞ïÎèÑ Ï†ÅÏö©
- ÌïôÏäµ Ï§ë **Ï†ïÏÉÅ Îç∞Ïù¥ÌÑ∞Îßå** Î¥Ñ ‚Üí anomaly-aware ÌïôÏäµ Î∂àÍ∞ÄÎä•
- Í≤∞Í≥º: `alpha ‚âà Ï¥àÍ∏∞Í∞í`ÏúºÎ°ú Í≥†Ï†ï, sigmoid boundÍ∞Ä ÏùòÎØ∏ ÏóÜÏùå

**ÌïµÏã¨ ÌÜµÏ∞∞**:
> Global alphaÎäî "knob"Ïùº ÎøêÏù¥Í≥†,
> Anomaly detectionÏóêÏÑúÎäî "switch"Í∞Ä ÌïÑÏöîÌïòÎã§.
> Í∑∏ switchÎäî **patch-wise gate**Îã§.

### Core Idea
| Íµ¨Î∂Ñ | Baseline 1.5 (Global Alpha) | Baseline 2.0 (Patch-wise Gate) |
|------|----------------------------|-------------------------------|
| ÏàòÏãù | `ctx = alpha * ctx` | `ctx = gate(x, ctx) * ctx` |
| Ï∞®Ïõê | `alpha` ‚àà ‚Ñù (scalar) | `gate` ‚àà ‚Ñù^(B√óH√óW√ó1) (per-patch) |
| ÌïôÏäµ | Î™®Îì† Ìå®Ïπò ÎèôÏùº | Ìå®ÏπòÎ≥Ñ ÎèÖÎ¶Ω Í≤∞Ï†ï |
| Ï†ïÏÉÅ Ìå®Ïπò | Œ± * ctx | gate ‚Üí 0 (context Î¨¥Ïãú) |
| Ïù¥ÏÉÅ Ìå®Ïπò | Œ± * ctx | gate ‚Üí 1 (context ÏÇ¨Ïö©) |

### Code Changes

#### 1. MoLEContextSubnet (lora.py)

**Before (Baseline 1.5 - Global Alpha)**:
```python
class MoLEContextSubnet(nn.Module):
    def __init__(self, dims_in, dims_out, ...,
                 context_init_scale=0.1, context_max_alpha=0.2):
        # ...

        # Global alpha with sigmoid upper bound
        # alpha = alpha_max * sigmoid(alpha_param)
        p = min(max(context_init_scale / context_max_alpha, 0.01), 0.99)
        init_param = torch.log(torch.tensor([p / (1 - p)]))  # Inverse sigmoid
        self.context_scale_param = nn.Parameter(init_param)

    def forward(self, x):
        # ...
        ctx = self.context_conv(x_spatial)

        # Global alpha scaling (same for ALL patches)
        alpha = self.context_max_alpha * torch.sigmoid(self.context_scale_param)
        ctx = alpha * ctx  # (BHW, D) * scalar

        s_input = torch.cat([x, ctx], dim=-1)
        # ...
```

**After (Baseline 2.0 - Patch-wise Gate)**:
```python
class MoLEContextSubnet(nn.Module):
    def __init__(self, dims_in, dims_out, ...,
                 context_init_scale=0.1, context_max_alpha=0.2,
                 use_context_gate=False, context_gate_hidden=64):  # NEW
        # ...
        self.use_context_gate = use_context_gate

        if use_context_gate:
            # NEW: Patch-wise gate network
            # gate = sigmoid(MLP([x, ctx])) ‚Üí (BHW, 1)
            self.context_gate_net = nn.Sequential(
                nn.Linear(dims_in * 2, context_gate_hidden),
                nn.ReLU(),
                nn.Linear(context_gate_hidden, 1)
            )
            # Initialize to output ~0 ‚Üí gate starts at 0.5
            nn.init.zeros_(self.context_gate_net[0].weight)
            nn.init.zeros_(self.context_gate_net[0].bias)
            nn.init.zeros_(self.context_gate_net[2].weight)
            nn.init.zeros_(self.context_gate_net[2].bias)

            self.context_scale_param = None  # No global alpha
        else:
            # Legacy: Global alpha (Baseline 1.5)
            p = min(max(context_init_scale / context_max_alpha, 0.01), 0.99)
            init_param = torch.log(torch.tensor([p / (1 - p)]))
            self.context_scale_param = nn.Parameter(init_param)
            self.context_gate_net = None

    def forward(self, x):
        # ...
        ctx = self.context_conv(x_spatial)

        if self.use_context_gate and self.context_gate_net is not None:
            # NEW: Patch-wise gate (per-patch decision)
            gate_input = torch.cat([x, ctx], dim=-1)  # (BHW, 2D)
            gate_logit = self.context_gate_net(gate_input)  # (BHW, 1)
            gate = torch.sigmoid(gate_logit)  # (BHW, 1)

            self._last_gate = gate.detach()  # For logging
            ctx = gate * ctx  # (BHW, D) * (BHW, 1) ‚Üí per-patch scaling
        else:
            # Legacy: Global alpha
            alpha = self.context_max_alpha * torch.sigmoid(self.context_scale_param)
            ctx = alpha * ctx

        s_input = torch.cat([x, ctx], dim=-1)
        # ...

    # NEW: Logging utilities
    def get_context_alpha(self) -> float:
        """Get global alpha value (legacy mode)."""
        if self.context_scale_param is not None:
            with torch.no_grad():
                return (self.context_max_alpha
                        * torch.sigmoid(self.context_scale_param)).item()
        return None

    def get_last_gate_stats(self) -> dict:
        """Get gate statistics (patch-wise mode)."""
        if hasattr(self, '_last_gate') and self._last_gate is not None:
            gate = self._last_gate
            return {
                'mean': gate.mean().item(),
                'std': gate.std().item(),
                'min': gate.min().item(),
                'max': gate.max().item()
            }
        return None
```

#### 2. AblationConfig (ablation.py)

**Added**:
```python
@dataclass
class AblationConfig:
    # ... existing fields ...

    # Scale-specific Context (Baseline 1.5)
    use_scale_context: bool = False
    scale_context_kernel: int = 3
    scale_context_init_scale: float = 0.1
    scale_context_max_alpha: float = 0.2

    # NEW: Patch-wise Context Gate (Baseline 2.0)
    use_context_gate: bool = False    # Use patch-wise gate instead of global alpha
    context_gate_hidden: int = 64     # Hidden dim for gate MLP
```

#### 3. MoLESpatialAwareNF (mole_nf.py)

**Before**:
```python
subnet = MoLEContextSubnet(
    dims_in, dims_out,
    rank=self.lora_rank,
    alpha=self.lora_alpha,
    use_lora=self.use_lora,
    use_task_bias=self.use_task_bias,
    context_kernel=self.scale_context_kernel,
    context_init_scale=self.scale_context_init_scale,
    context_max_alpha=self.scale_context_max_alpha
)
```

**After**:
```python
subnet = MoLEContextSubnet(
    dims_in, dims_out,
    rank=self.lora_rank,
    alpha=self.lora_alpha,
    use_lora=self.use_lora,
    use_task_bias=self.use_task_bias,
    context_kernel=self.scale_context_kernel,
    context_init_scale=self.scale_context_init_scale,
    context_max_alpha=self.scale_context_max_alpha,
    use_context_gate=self.use_context_gate,      # NEW
    context_gate_hidden=self.context_gate_hidden  # NEW
)
```

**Added get_context_info() method**:
```python
def get_context_info(self) -> dict:
    """Get context gate/alpha information for logging."""
    if not self.use_scale_context:
        return {}

    info = {}
    if self.use_context_gate:
        # Aggregate gate stats from all subnets
        gate_stats = []
        for subnet in self.subnets:
            if hasattr(subnet, 'get_last_gate_stats'):
                stats = subnet.get_last_gate_stats()
                if stats is not None:
                    gate_stats.append(stats)

        if gate_stats:
            info['gate_mean'] = sum(s['mean'] for s in gate_stats) / len(gate_stats)
            info['gate_std'] = sum(s['std'] for s in gate_stats) / len(gate_stats)
            info['gate_min'] = min(s['min'] for s in gate_stats)
            info['gate_max'] = max(s['max'] for s in gate_stats)
    else:
        # Collect alpha from all subnets
        alphas = [s.get_context_alpha() for s in self.subnets
                  if hasattr(s, 'get_context_alpha')]
        alphas = [a for a in alphas if a is not None]
        if alphas:
            info['alpha_mean'] = sum(alphas) / len(alphas)

    return info
```

#### 4. Trainer Logging (continual_trainer.py)

**Added context logging per epoch**:
```python
# In _train_base_task, _train_fast_stage, _train_slow_stage:
avg_epoch_loss = epoch_loss / max(num_batches, 1)
current_lr = optimizer.param_groups[0]['lr']

# NEW: Get context gate/alpha info for logging
extra_info = {"LR": current_lr}
context_info = self.nf_model.get_context_info()
if context_info:
    extra_info.update(context_info)

if self.logger:
    self.logger.log_epoch(task_id, epoch, num_epochs, avg_epoch_loss,
                          stage="FAST", extra_info=extra_info)
else:
    ctx_str = ""
    if 'gate_mean' in context_info:
        ctx_str = f" | Gate: {context_info['gate_mean']:.4f}¬±{context_info['gate_std']:.4f}"
    elif 'alpha_mean' in context_info:
        ctx_str = f" | Alpha: {context_info['alpha_mean']:.4f}"
    print(f"  üìä [FAST] Epoch [...] Average Loss: {avg_epoch_loss:.4f}{ctx_str}")
```

### Command Line Usage

```bash
# Baseline 1.5: Global Alpha (Í∏∞Ï°¥)
python run_moleflow.py \
    --use_scale_context \
    --scale_context_kernel 3 \
    --scale_context_init_scale 0.1 \
    --scale_context_max_alpha 0.2

# Baseline 2.0: Patch-wise Gate (NEW)
python run_moleflow.py \
    --use_scale_context \
    --use_context_gate \
    --context_gate_hidden 64
```

### Expected Improvements
- Ìå®ÏπòÎ≥ÑÎ°ú context ÏÇ¨Ïö© Ïó¨Î∂Ä Í≤∞Ï†ï ‚Üí anomaly Í≤ΩÍ≥ÑÏóêÏÑú Îçî Ï†ïÎ∞ÄÌïú detection
- Gate networkÍ∞Ä normal/anomaly Ìå®Ïπò ÌäπÏÑ± ÌïôÏäµ
- Îçî interpretableÌïú anomaly map ÏÉùÏÑ± Í∞ÄÎä•

### Baseline 1.5 ‚Üí 2.0
| File | Changes |
|------|---------|
| `moleflow/models/lora.py` | `MoLEContextSubnet` - context_gate_net Ï∂îÍ∞Ä |
| `moleflow/config/ablation.py` | `use_context_gate`, `context_gate_hidden` ÏÑ§Ï†ï Ï∂îÍ∞Ä |
| `moleflow/models/mole_nf.py` | context gate ÌååÎùºÎØ∏ÌÑ∞ Ï†ÑÎã¨, `get_context_info()` Î©îÏÑúÎìú |
| `moleflow/trainer/continual_trainer.py` | Context gate/alpha Î°úÍπÖ Ï∂îÍ∞Ä |

---

## Version 3 - No-Replay Continual Learning Solutions

### Motivation
Version 2ÏóêÏÑú continual learning Ïãú ÏÑ±Îä• Ï†ÄÌïò Î¨∏Ï†úÍ∞Ä Ïó¨Ï†ÑÌûà Ï°¥Ïû¨:
- Task 0 ‚Üí Task 1 ‚Üí Task 2 ÌïôÏäµ Ïãú Ïù¥Ï†Ñ task ÏÑ±Îä• Í∞êÏÜå (Catastrophic Forgetting)
- Í∏∞Ï°¥ Î∞©Î≤ï: Replay buffer ÏÇ¨Ïö© ‚Üí Î©îÎ™®Î¶¨ ÎπÑÏö©, ÌîÑÎùºÏù¥Î≤ÑÏãú Î¨∏Ï†ú

**Î™©Ìëú**: Replay ÏóÜÏù¥ continual learning ÏÑ±Îä• Ìñ•ÏÉÅ

### V3 New Modules Overview

| Module | Î™©Ï†Å | ÏúÑÏπò |
|--------|------|------|
| **WhiteningAdapter** | Task-agnostic feature normalization | Feature ‚Üí NF Ï†Ñ |
| **LightweightMSContext** | Multi-scale receptive field ÌôïÏû• | NF ÏûÖÎ†• Ï†Ñ |
| **DeepInvertibleAdapter (DIA)** | Task-specific nonlinear manifold adaptation | NF Ï∂úÎ†• ÌõÑ |
| **OrthogonalGradientProjection (OGP)** | Gradient projection to null space | Training loop |
| **TwoStageHybridRouter** | Prototype + Likelihood routing | Inference |

---

## V3-1: WhiteningAdapter

### Core Idea
Task Í∞Ñ feature distribution shift Î¨∏Ï†ú Ìï¥Í≤∞:
```
Task 0 features: mean=Œº‚ÇÄ, cov=Œ£‚ÇÄ
Task 1 features: mean=Œº‚ÇÅ, cov=Œ£‚ÇÅ  (Îã§Î•∏ Î∂ÑÌè¨)
```

**Solution**: Whitening ‚Üí Constrained De-whitening
```
x ‚Üí Whiten(x) ‚Üí z (zero mean, unit variance)
z ‚Üí ConstrainedDewhiten(z) ‚Üí x' (controlled distribution)
```

### Implementation
```python
# moleflow/models/adapters.py
class WhiteningAdapter(nn.Module):
    """
    Whitening-based Task Adapter (V3 Solution 3).

    Key Design:
    1. All tasks go through Whitening first (mean=0, std=1) via LayerNorm
    2. Task-specific de-whitening with constrained gamma/beta parameters
    3. Task 0 stays close to identity (anchor point)

    Parameters:
    - gamma: constrained to [gamma_min, gamma_max] via sigmoid
    - beta: constrained to [-beta_max, beta_max] via tanh
    """
    def __init__(self, channels: int, task_id: int = 0,
                 reference_mean=None, reference_std=None,
                 gamma_range: tuple = (0.5, 2.0), beta_max: float = 2.0):
        super().__init__()
        self.gamma_min, self.gamma_max = gamma_range
        self.beta_max = beta_max

        # Whitening layer (shared across all tasks, no learnable affine)
        self.whiten = nn.LayerNorm(channels, elementwise_affine=False)

        if task_id == 0:
            # Task 0: Start very close to identity
            # gamma ‚âà 1.0, beta ‚âà 0.0
            init_gamma_raw = -0.7 * torch.ones(1, 1, 1, channels)
            self.gamma_raw = nn.Parameter(init_gamma_raw)
            self.beta_raw = nn.Parameter(torch.zeros(1, 1, 1, channels))
            self.identity_reg_weight = 0.1  # Regularize toward identity
        else:
            # Task 1+: Learnable, initialized at midpoint
            self.gamma_raw = nn.Parameter(torch.zeros(1, 1, 1, channels))
            self.beta_raw = nn.Parameter(torch.zeros(1, 1, 1, channels))
            self.identity_reg_weight = 0.0

    @property
    def gamma(self):
        """Constrained gamma in [gamma_min, gamma_max]."""
        return self.gamma_min + (self.gamma_max - self.gamma_min) * torch.sigmoid(self.gamma_raw)

    @property
    def beta(self):
        """Constrained beta in [-beta_max, beta_max]."""
        return self.beta_max * torch.tanh(self.beta_raw)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        B, H, W, D = x.shape
        # 1. Whitening: normalize to N(0, 1)
        x_white = self.whiten(x.reshape(-1, D)).reshape(B, H, W, D)
        # 2. Task-specific de-whitening
        return self.gamma * x_white + self.beta

    def identity_regularization(self) -> torch.Tensor:
        """Regularization loss to keep Task 0 adapter close to identity."""
        if self.identity_reg_weight > 0:
            gamma_reg = ((self.gamma - 1.0) ** 2).mean()
            beta_reg = (self.beta ** 2).mean()
            return self.identity_reg_weight * (gamma_reg + beta_reg)
        return torch.tensor(0.0, device=self.gamma_raw.device)
```

### Key Design
1. **LayerNorm-based Whitening**: Task-agnostic normalization (no learnable params)
2. **Constrained Parameters**: sigmoid/tanhÎ°ú Î≤îÏúÑ Ï†úÌïú ‚Üí ÏïàÏ†ïÏ†Å ÌïôÏäµ
3. **Per-Task Adapter**: Í∞Å taskÎßàÎã§ Î≥ÑÎèÑ WhiteningAdapter (create_task_adapter factory Ìï®Ïàò ÏÇ¨Ïö©)
4. **Task 0 Identity Regularization**: Task 0Îäî identityÏóê Í∞ÄÍπùÍ≤å Ïú†ÏßÄ

### Command Line
```bash
python run_moleflow.py --use_whitening_adapter
```

---

## V3-2: LightweightMSContext (Multi-Scale Context)

### Core Idea
Í∏∞Ï°¥ NFÎäî patch Îã®ÏúÑ ÎèÖÎ¶Ω Ï≤òÎ¶¨ ‚Üí Ï£ºÎ≥Ä context Î¨¥Ïãú

**Solution**: Multi-scale dilated convolutionÏúºÎ°ú receptive field ÌôïÏû•
```
x ‚Üí [Conv_d1, Conv_d2, Conv_d4] ‚Üí concat ‚Üí fusion ‚Üí x + context
```

### Implementation
```python
# moleflow/models/ms_context.py
class LightweightMSContext(nn.Module):
    """
    Multi-scale context via dilated depthwise convolutions.

    Uses multiple dilation rates to capture context at different scales
    without significantly increasing parameters.
    """
    def __init__(self, channels, dilations=[1, 2, 4], kernel_size=3):
        self.dilated_convs = nn.ModuleList([
            nn.Conv2d(channels, channels, kernel_size,
                      padding=d*(kernel_size//2), dilation=d, groups=channels)
            for d in dilations
        ])
        self.fusion = nn.Conv2d(channels * len(dilations), channels, 1)
        self.gate = nn.Parameter(torch.zeros(1))  # Starts at 0.5 after sigmoid

    def forward(self, x):
        # x: (B, H, W, D) ‚Üí (B, D, H, W) for conv
        x_conv = x.permute(0, 3, 1, 2)

        # Multi-scale features
        ms_features = [conv(x_conv) for conv in self.dilated_convs]
        ms_concat = torch.cat(ms_features, dim=1)

        # Fusion and gating
        context = self.fusion(ms_concat).permute(0, 2, 3, 1)
        gate = torch.sigmoid(self.gate)

        return x + gate * context
```

### Key Design
1. **Depthwise Separable**: ÌååÎùºÎØ∏ÌÑ∞ Ìö®Ïú®Ï†Å
2. **Multiple Dilations**: d=1,2,4Î°ú Îã§ÏñëÌïú scale Ìè¨Ï∞©
3. **Learnable Gate**: ÌïôÏäµ Ï¥àÍ∏∞ ÏïàÏ†ïÏÑ±

### Command Line
```bash
python run_moleflow.py --use_ms_context
```

### ‚ö†Ô∏è Warning: WhiteningAdapter + MS-Context Ï∂©Îèå

Îëê Î™®ÎìàÏùÑ ÎèôÏãú ÏÇ¨Ïö© Ïãú ÌïôÏäµ Î∂àÏïàÏ†ï Î∞úÏÉù:
- LossÍ∞Ä ÏùåÏàòÎ°ú Î∞úÏÇ∞
- Task 0 ÏÑ±Îä• Í∏âÍ≤©Ìûà Ï†ÄÌïò

**ÏõêÏù∏**: Îëê Î™®Îìà Î™®Îëê NF ÏûÖÎ†• Ï†ÑÏóê featureÎ•º Î≥ÄÌôòÌïòÏó¨ distribution Ï∂©Îèå

**ÏûêÎèô Ìï¥Í≤∞**: `AblationConfig`ÏóêÏÑú ÏûêÎèôÏúºÎ°ú MS-Context ÎπÑÌôúÏÑ±Ìôî
```python
# ablation.py __post_init__()
if self.use_whitening_adapter and self.use_ms_context:
    print("‚ö†Ô∏è  Warning: use_whitening_adapter + use_ms_context Ï°∞Ìï©ÏùÄ ÌïôÏäµ Î∂àÏïàÏ†ï")
    self.use_ms_context = False
```

---

## V3-3: DeepInvertibleAdapter (DIA)

### Core Idea
Base NF Ï∂úÎ†• ÌõÑ task-specific nonlinear adaptation:
```
x ‚Üí Base NF ‚Üí z_base ‚Üí DIA_task ‚Üí z_final
```

**Why DIA?**
- LoRA: Linear adaptation (ÌëúÌòÑÎ†• Ï†úÌïú)
- DIA: Invertible nonlinear adaptation (Îçî Í∞ïÎ†•Ìïú manifold adaptation)

### Implementation
```python
# moleflow/models/lora.py
class DeepInvertibleAdapter(nn.Module):
    """
    Deep Invertible Adapter (DIA) - V3 Solution 1 (No Replay).

    Key Insight:
    Instead of linear LoRA (W + BA), we add a small task-specific Flow
    AFTER the base NF. This allows nonlinear manifold adaptation.

    Architecture:
    - Base NF: Frozen after Task 0 (extracts common features)
    - DIA: 1-2 lightweight coupling blocks per task (learns task-specific warping)

    Mathematical Formulation:
    - Base: z_base = f_base(x)
    - DIA:  z_final = f_DIA_t(z_base)
    - log p(x) = log p(z_final) + log|det J_base| + log|det J_DIA|
    """
    def __init__(self, channels: int, task_id: int, n_blocks: int = 2,
                 hidden_ratio: float = 0.5, clamp_alpha: float = 1.9):
        super().__init__()
        self.clamp_alpha = clamp_alpha
        hidden_dim = int(channels * hidden_ratio)

        # Build mini-flow: sequence of affine coupling blocks
        self.coupling_blocks = nn.ModuleList([
            AffineCouplingBlock(
                channels=channels,
                hidden_dim=hidden_dim,
                clamp_alpha=clamp_alpha,
                reverse=(i % 2 == 1)  # Alternate which half is transformed
            ) for i in range(n_blocks)
        ])
        self._initialize_near_identity()

    def _initialize_near_identity(self):
        """Initialize to near-identity transformation."""
        for block in self.coupling_blocks:
            nn.init.zeros_(block.s_net.layers[-1].weight)
            nn.init.zeros_(block.s_net.layers[-1].bias)
            nn.init.zeros_(block.t_net.layers[-1].weight)
            nn.init.zeros_(block.t_net.layers[-1].bias)

    def forward(self, x: torch.Tensor, reverse: bool = False):
        B, H, W, D = x.shape
        log_det = torch.zeros(B, H, W, device=x.device)
        blocks = reversed(self.coupling_blocks) if reverse else self.coupling_blocks

        for block in blocks:
            x, block_log_det = block(x, reverse=reverse)
            log_det = log_det + block_log_det
        return x, log_det


class AffineCouplingBlock(nn.Module):
    """Affine Coupling Block for DIA with clamped scale."""
    def __init__(self, channels: int, hidden_dim: int,
                 clamp_alpha: float = 1.9, reverse: bool = False):
        super().__init__()
        self.clamp_alpha = clamp_alpha
        self.reverse_split = reverse
        self.split_dim = channels // 2

        # Scale network: x1 -> s
        self.s_net = SimpleSubnet(self.split_dim, self.split_dim, hidden_dim)
        # Translation network: x1 -> t
        self.t_net = SimpleSubnet(self.split_dim, self.split_dim, hidden_dim)

    def forward(self, x: torch.Tensor, reverse: bool = False):
        B, H, W, D = x.shape
        if self.reverse_split:
            x2, x1 = x[..., :self.split_dim], x[..., self.split_dim:]
        else:
            x1, x2 = x[..., :self.split_dim], x[..., self.split_dim:]

        x1_flat = x1.reshape(-1, self.split_dim)
        s = self.s_net(x1_flat).reshape(B, H, W, self.split_dim)
        t = self.t_net(x1_flat).reshape(B, H, W, self.split_dim)
        s = self.clamp_alpha * torch.tanh(s / self.clamp_alpha)

        if not reverse:
            y2 = x2 * torch.exp(s) + t
            log_det = s.sum(dim=-1)
        else:
            y2 = (x2 - t) * torch.exp(-s)
            log_det = -s.sum(dim=-1)

        if self.reverse_split:
            return torch.cat([y2, x1], dim=-1), log_det
        return torch.cat([x1, y2], dim=-1), log_det


class SimpleSubnet(nn.Module):
    """Simple MLP subnet for DIA coupling blocks."""
    def __init__(self, in_dim: int, out_dim: int, hidden_dim: int):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(in_dim, hidden_dim), nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),
            nn.Linear(hidden_dim, out_dim)
        )
        # Initialize output layer to zero for identity start
        nn.init.zeros_(self.layers[-1].weight)
        nn.init.zeros_(self.layers[-1].bias)

    def forward(self, x):
        return self.layers(x)
```

### Integration in mole_nf.py
```python
class MoLESpatialAwareNF(nn.Module):
    def __init__(self, ...):
        # ...
        self.dia_adapters = nn.ModuleDict()  # Per-task DIA

    def add_task(self, task_id):
        # ...
        if self.use_dia:
            self.dia_adapters[str(task_id)] = DeepInvertibleAdapter(
                channels=self.embed_dim,
                task_id=task_id,
                n_blocks=self.dia_n_blocks,
                hidden_ratio=self.dia_hidden_ratio,
                clamp_alpha=self.clamp_alpha
            ).to(self.device)

    def forward(self, x, reverse=False):
        # Base NF forward
        z, logdet = self.flow(x)

        # DIA forward (applied AFTER base NF)
        if self.use_dia and self.current_task_id is not None:
            task_key = str(self.current_task_id)
            if task_key in self.dia_adapters:
                z, dia_logdet = self.dia_adapters[task_key](z, reverse=reverse)
                logdet = logdet + dia_logdet

        return z, logdet
```

### Command Line
```bash
python run_moleflow.py \
    --use_dia \
    --dia_n_blocks 2 \
    --dia_hidden_ratio 0.5
```

---

## V3-4: OrthogonalGradientProjection (OGP)

### Core Idea
Ïù¥Ï†Ñ taskÏóêÏÑú Ï§ëÏöîÌïú gradient Î∞©Ìñ•ÏùÑ Î≥¥Ï°¥:
```
‚àáL_new ‚Üí Project to null space of previous tasks ‚Üí ‚àáL_projected
```

**Gradient Projection**:
```
g' = g - Œ£·µ¢ (basis_i @ basis_i.T @ g)
```
where basis_i = important gradient directions from task i

### Implementation
```python
# moleflow/utils/replay.py
class OrthogonalGradientProjection:
    """
    Orthogonal Gradient Projection (OGP) - V3 No-Replay Solution.

    Key Idea:
    After learning Task t, compute the principal subspace of gradients
    (or features) that are important for that task. When learning Task t+1,
    project gradients to be orthogonal to this subspace, ensuring that
    updates don't interfere with previously learned knowledge.

    This is based on GPM (Gradient Projection Memory) from:
    "Continual Learning in Low-rank Orthogonal Subspaces", NeurIPS 2020

    Mathematical Formulation:
    1. After Task t: Compute U_t = SVD(G_t)[:, :k] where G_t is gradient matrix
    2. Store basis vectors (Vh transposed from SVD)
    3. For Task t+1: g' = g - basis @ (basis.T @ g) for each stored basis

    Advantages over Replay:
    - No data storage required
    - Memory: O(d √ó k) per task where k << d
    - Mathematically guarantees no interference in stored subspace
    """
    def __init__(self, threshold: float = 0.99, max_rank_per_task: int = 50,
                 device: str = 'cuda'):
        self.threshold = threshold
        self.max_rank_per_task = max_rank_per_task
        self.device = device

        # Store projection bases per parameter
        # param_name -> list of basis matrices (one per task)
        self.bases: Dict[str, List[torch.Tensor]] = {}
        self.is_initialized = False
        self.n_tasks = 0

    def compute_and_store_basis(self, model: nn.Module, data_loader,
                                 task_id: int, n_samples: int = 300):
        """
        Compute gradient subspace basis for completed task.
        Called AFTER training on a task is complete.
        """
        model.eval()
        gradient_matrices: Dict[str, List[torch.Tensor]] = {}

        n_processed = 0
        for batch in data_loader:
            if n_processed >= n_samples:
                break
            features = batch[0].to(self.device)
            batch_size = features.shape[0]

            model.zero_grad()
            log_prob = model.log_prob(features)
            loss = -log_prob.mean()
            loss.backward()

            for name, param in model.named_parameters():
                if param.requires_grad and param.grad is not None:
                    grad = param.grad.detach().flatten()
                    if name not in gradient_matrices:
                        gradient_matrices[name] = []
                    gradient_matrices[name].append(grad.clone())
            n_processed += batch_size

        # Compute SVD for each parameter's gradient matrix
        for name, grads in gradient_matrices.items():
            if len(grads) < 5:
                continue
            G = torch.stack(grads, dim=0)  # (n_samples, n_params)

            U, S, Vh = torch.linalg.svd(G, full_matrices=False)

            # Select top-k components based on variance threshold
            var_ratio = (S ** 2).cumsum(0) / (S ** 2).sum()
            k = min(
                (var_ratio < self.threshold).sum().item() + 1,
                self.max_rank_per_task,
                S.shape[0]
            )

            # Store basis vectors: Vh[:k, :].T gives (n_params, k)
            basis = Vh[:k, :].T  # (n_params, k)

            if name not in self.bases:
                self.bases[name] = []
            self.bases[name].append(basis.to(self.device))

        self.n_tasks = task_id + 1
        self.is_initialized = True

    def project_gradient(self, model: nn.Module):
        """
        Project current gradients to be orthogonal to stored subspaces.
        Call AFTER loss.backward() and BEFORE optimizer.step().
        """
        if not self.is_initialized:
            return

        for name, param in model.named_parameters():
            if not param.requires_grad or param.grad is None:
                continue
            if name not in self.bases:
                continue

            grad = param.grad.flatten()

            # Project out all stored subspaces for this parameter
            for basis in self.bases[name]:
                # basis: (n_params, k)
                # proj = basis @ (basis.T @ grad)
                proj = basis @ (basis.T @ grad)
                grad = grad - proj

            param.grad = grad.reshape(param.shape)

    def get_memory_usage(self) -> Dict[str, int]:
        """Get memory usage statistics."""
        total_elements = sum(b.numel() for bl in self.bases.values() for b in bl)
        return {
            'n_params': len(self.bases),
            'n_tasks': self.n_tasks,
            'total_elements': total_elements,
            'memory_mb': total_elements * 4 / (1024 * 1024)
        }
```

### Integration in Trainer
```python
# moleflow/trainer/continual_trainer.py
class MoLEContinualTrainer:
    def __init__(self, ...):
        if self.use_ogp:
            self.ogp = OrthogonalGradientProjection(
                threshold=self.ogp_threshold,
                max_rank_per_task=self.ogp_max_rank,
                device=device
            )

    def _train_fast_stage(self, task_id, ...):
        for batch in dataloader:
            loss.backward()

            # OGP: Project gradients for Task > 0
            if self.use_ogp and self.ogp is not None and self.ogp.is_initialized:
                self.ogp.project_gradient(self.nf_model)

            optimizer.step()

    def train_task(self, task_id, ...):
        # ... training code ...

        # Compute OGP basis AFTER task training completes
        if self.use_ogp and self.ogp is not None:
            self._compute_ogp_basis(task_id, train_loader)

    def _compute_ogp_basis(self, task_id, train_loader):
        """Compute and store OGP gradient basis for completed task."""
        # Creates FeatureDataLoader wrapper to provide features
        self.ogp.compute_and_store_basis(
            model=self.nf_model,
            data_loader=feature_loader,
            task_id=task_id,
            n_samples=self.ogp_n_samples
        )
```

### Command Line
```bash
python run_moleflow.py \
    --use_ogp \
    --ogp_threshold 0.99 \
    --ogp_max_rank 50 \
    --ogp_n_samples 300
```

---

## V3-5: TwoStageHybridRouter

### Core Idea
Í∏∞Ï°¥ RouterÎäî Prototype matchingÎßå ÏÇ¨Ïö© ‚Üí Ïú†ÏÇ¨Ìïú task Íµ¨Î∂Ñ Ïñ¥Î†§ÏõÄ

**Solution**: Two-stage routing
1. **Stage 1 (Fast)**: Prototype filtering ‚Üí Top-K candidates
2. **Stage 2 (Accurate)**: NF likelihood comparison ‚Üí Final selection

### Implementation
```python
# moleflow/models/routing.py
class TwoStageHybridRouter(nn.Module):
    """
    Two-stage routing: Prototype filtering + Likelihood refinement.

    Stage 1: Mahalanobis distance to prototypes ‚Üí Top-K candidates
    Stage 2: NF log-likelihood for final selection
    """
    def __init__(self, nf_model, top_k=2):
        self.prototype_router = PrototypeRouter()
        self.nf_model = nf_model
        self.top_k = top_k

    def forward(self, features):
        # Stage 1: Prototype distances
        distances = self.prototype_router.compute_distances(features)
        top_k_tasks = distances.argsort()[:self.top_k]

        # Stage 2: NF likelihood
        likelihoods = []
        for task_id in top_k_tasks:
            self.nf_model.set_task(task_id)
            z, logdet = self.nf_model(features)
            log_prob = -0.5 * (z**2).sum() + logdet
            likelihoods.append(log_prob)

        # Select task with highest likelihood
        best_idx = torch.stack(likelihoods).argmax()
        return top_k_tasks[best_idx]
```

### Command Line
```bash
python run_moleflow.py \
    --use_hybrid_router \
    --router_top_k 2
```

---

## V3 Experiment Results

### Ablation Study (leather ‚Üí grid ‚Üí transistor)

| Configuration | Image AUC | Pixel AUC | Notes |
|---------------|-----------|-----------|-------|
| **Baseline (V2)** | 0.8168 | 0.9166 | - |
| DIA only | 0.8217 | 0.9277 | +0.5% Image, +1.1% Pixel |
| OGP only | 0.8180 | 0.9161 | Minimal change |
| **DIA + OGP** | **0.8226** | **0.9231** | **Best combination** |
| WhiteningAdapter only | (Ïã§Ìóò Ï§ë) | (Ïã§Ìóò Ï§ë) | - |
| MS-Context only | (Ïã§Ìóò Ï§ë) | (Ïã§Ìóò Ï§ë) | - |
| All V3 (conflict) | 0.4471 | 0.5527 | ‚ùå Ïã§Ìå® (Ï∂©Îèå) |

### Key Findings
1. **DIA + OGP**: Best performance without replay
2. **WhiteningAdapter + MS-Context**: Ï°∞Ìï© Ïãú Ï∂©Îèå ‚Üí ÏûêÎèô ÎπÑÌôúÏÑ±Ìôî Ï≤òÎ¶¨
3. **DIA > OGP**: DIAÍ∞Ä Îçî ÌÅ∞ ÏÑ±Îä• Ìñ•ÏÉÅ Í∏∞Ïó¨

---

## V3 File Changes Summary

| File | Changes |
|------|---------|
| `moleflow/models/adapters.py` | **WhiteningAdapter** Ï∂îÍ∞Ä (line 417-531), `create_task_adapter` factoryÏóê "whitening" Î™®Îìú Ï∂îÍ∞Ä |
| `moleflow/models/lora.py` | **LightweightMSContext** (line 223-366), **TaskConditionedMSContext** (line 373-701), **DeepInvertibleAdapter** + AffineCouplingBlock + SimpleSubnet (line 708-908) Ï∂îÍ∞Ä |
| `moleflow/utils/replay.py` | **OrthogonalGradientProjection** (line 512-687), GradientProjectionHook, FeatureBank, DistillationLoss, EWC Ï∂îÍ∞Ä |
| `moleflow/models/mole_nf.py` | DIA integration (`dia_adapters`), WhiteningAdapter/MSContext/TaskConditionedMSContext ÌÜµÌï©, V3 config options Ï≤òÎ¶¨ |
| `moleflow/config/ablation.py` | V3 options: `use_dia`, `use_ogp`, `use_whitening_adapter`, `use_ms_context`, `use_task_conditioned_ms_context`, `ogp_*` params, `dia_*` params |
| `moleflow/trainer/continual_trainer.py` | OGP integration: `_compute_ogp_basis()`, `ogp.project_gradient()` in training loop |
| `run_moleflow.py` | V3 CLI arguments, config saving |

---

## V3 Command Line Reference

```bash
# Full V3 with recommended settings (DIA + OGP)
python run_moleflow.py \
    --use_dia \
    --dia_n_blocks 2 \
    --use_ogp \
    --ogp_threshold 0.99 \
    --ogp_max_rank 50 \
    --experiment_name Version3-DIA_OGP

# WhiteningAdapter only
python run_moleflow.py \
    --use_whitening_adapter \
    --experiment_name Version3-WhiteningAdapter

# MS-Context only (automatically disabled if WhiteningAdapter is on)
python run_moleflow.py \
    --use_ms_context \
    --experiment_name Version3-MSContext

# All options with diagnostics
python run_moleflow.py \
    --run_diagnostics \
    --use_dia \
    --use_ogp \
    --use_whitening_adapter \
    --experiment_name Version3-All
```

---

## V3 Problem Analysis 
--
  Ïã¨Ï∏µ Î∂ÑÏÑù Í≤∞Í≥º

  1. ÌïµÏã¨ Î∞úÍ≤¨: Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞ Î¨∏Ï†ú

  spatial_mixerÍ∞Ä Î™®Îì† taskÏóêÏÑú Í≥µÏú†ÎêòÍ≥† ÌïôÏäµÎê©ÎãàÎã§:

  # mole_nf.py:529-530
  if self.spatial_mixer is not None and not reverse:
      x = self.spatial_mixer(x)

  # mole_nf.py:721-722 (get_fast_params)
  if self.spatial_mixer is not None:
      params.extend(self.spatial_mixer.parameters())  # Î™®Îì† taskÏóêÏÑú ÌïôÏäµ!

  Forward Í≤ΩÎ°ú:
  Input ‚Üí WhiteningAdapter[task] ‚Üí SpatialMixer[SHARED] ‚Üí BaseNF ‚Üí DIA[task] ‚Üí Output
                                         ‚Üë
                              Ïù¥Í≤ÉÏù¥ Îß§ taskÎßàÎã§ ÏóÖÎç∞Ïù¥Ìä∏Îê®!

  ---
  2. Task 0 Î∂ïÍ¥¥ Î©îÏª§ÎãàÏ¶ò ÏÉÅÏÑ∏ Î∂ÑÏÑù

  Phase 1: Task 0 ÌïôÏäµ (Ï†ïÏÉÅ)

  leather features ‚Üí WhiteningAdapter_0 ‚Üí SpatialMixer_v0 ‚Üí BaseNF ‚Üí DIA_0
                                                ‚Üë
                                       Ïù¥ ÏãúÏ†êÏùò ÌååÎùºÎØ∏ÌÑ∞
  - Image AUC = 1.0 Îã¨ÏÑ±

  Phase 2: Task 1-6 ÌïôÏäµ (Ï†êÏßÑÏ†Å ÎìúÎ¶¨ÌîÑÌä∏)

  grid/transistor/... ‚Üí WhiteningAdapter_k ‚Üí SpatialMixer_v1...v6 ‚Üí BaseNF ‚Üí DIA_k
                                                    ‚Üë
                                           Îß§ taskÎßàÎã§ ÏóÖÎç∞Ïù¥Ìä∏
  - leather ÌèâÍ∞Ä Ïãú: SpatialMixer_v6Ïù¥ ÏÇ¨Ïö©Îê® (ÏõêÎûò v0Í≥º Îã§Î¶Ñ)
  - ÌïòÏßÄÎßå OGPÍ∞Ä Ïñ¥Îäê Ï†ïÎèÑ gradientÎ•º Ï†úÌïúÌïòÏó¨ ÎìúÎ¶¨ÌîÑÌä∏ ÏµúÏÜåÌôî
  - leather Image AUC: 1.0 ‚Üí 0.99 (ÎØ∏ÎØ∏Ìïú Í∞êÏÜå)

  Phase 3: Task 7-8 ÌïôÏäµ (Î∂ïÍ¥¥ ÏãúÏûë)

  metal_nut/screw ‚Üí WhiteningAdapter_k ‚Üí SpatialMixer_v7,v8 ‚Üí BaseNF ‚Üí DIA_k
                                                ‚Üë
                                        OGP Ï†úÏïΩÏù¥ Ìè¨Ìôî ÏÉÅÌÉú
  - OGPÏùò orthogonal Í≥µÍ∞ÑÏù¥ Ï†êÏ†ê Ï§ÑÏñ¥Îì¶
  - SpatialMixerÍ∞Ä ÏÉàÎ°úÏö¥ taskÏóê Ï†ÅÏùëÌïòÎ†§Î©¥ Ïù¥Ï†Ñ subspaceÏóêÏÑú Î≤óÏñ¥ÎÇòÏïº Ìï®
  - leather Image AUC: 0.99 ‚Üí 0.78 ‚Üí 0.55 (Í∏âÍ≤©Ìïú Í∞êÏÜå)

  Phase 4: Task 9+ ÌïôÏäµ (ÏôÑÏ†Ñ Î∂ïÍ¥¥)

  - OGP Ï†úÏïΩ ÌïòÏóêÏÑúÎèÑ SpatialMixerÍ∞Ä Í≥ÑÏÜç Î≥ÄÍ≤ΩÎê®
  - leatherÏùò representationÏù¥ ÏôÑÏ†ÑÌûà ÏÜêÏÉÅÎê®
  - leather Image AUC: 0.07 (Í±∞Ïùò random)

  ---
  3. ÏïåÌååÎ≤≥ ÏàúÏÑúÏóêÏÑú Îçî Îπ†Î•∏ Î∂ïÍ¥¥ ÏõêÏù∏

  | ÎπÑÍµê   | ÏõêÎûò ÏàúÏÑú        | ÏïåÌååÎ≤≥ ÏàúÏÑú         |
  |--------|------------------|---------------------|
  | Task 0 | leather (ÌÖçÏä§Ï≤ò) | bottle (ÌòïÏÉÅ)       |
  | Task 2 | transistor       | capsule             |
  | Ïú†ÏÇ¨ÏÑ± | ÎÇÆÏùå             | ÎÜíÏùå (Îëò Îã§ ÏõêÌÜµÌòï) |

  bottle ‚Üí capsule Ïú†ÏÇ¨ÏÑ± Î¨∏Ï†ú:
  1. bottleÏùò featureÎ°ú ÌïôÏäµÎêú SpatialMixer
  2. capsule ÌïôÏäµ Ïãú ÎπÑÏä∑Ìïú feature Í≥µÍ∞ÑÏóêÏÑú Í≤ΩÏüÅ
  3. OGPÍ∞Ä Î≥¥Ï°¥ÌïòÎ†§Îäî subspaceÏôÄ ÏÉà taskÍ∞Ä ÌïÑÏöîÌïú Í≥µÍ∞ÑÏù¥ ÌÅ¨Í≤å Ï§ëÏ≤©
  4. Í≤∞Í≥º: bottleÏùò representationÏù¥ 2Í∞ú task ÎßåÏóê ÏÜêÏÉÅÎê®

  leather ‚Üí grid ÎπÑÏú†ÏÇ¨ÏÑ±:
  1. leatherÏùò ÌÖçÏä§Ï≤ò featureÎ°ú ÌïôÏäµÎêú SpatialMixer
  2. grid (Ìå®ÌÑ¥), transistor (ÌòïÏÉÅ) Îì±ÏùÄ Îã§Î•∏ feature Í≥µÍ∞Ñ
  3. OGPÍ∞Ä Î≥¥Ï°¥ÌïòÎäî subspaceÏôÄ ÏÉà task Í≥µÍ∞ÑÏùò Ï§ëÏ≤©Ïù¥ Ï†ÅÏùå
  4. Í≤∞Í≥º: 7Í∞ú taskÍπåÏßÄ ÏÉÅÎåÄÏ†ÅÏúºÎ°ú ÏïàÏ†ï

  ---
  4. Image AUC vs Pixel AUC Ï∞®Ïù¥ Î∂ÑÏÑù

  leather (ÏõêÎûò ÏàúÏÑú)

  | Metric    | Task 0 | Task 14 | ÏÑ§Î™Ö     |
  |-----------|--------|---------|----------|
  | Pixel AUC | 0.97   | 0.66    | 32% ÌïòÎùΩ |
  | Image AUC | 1.00   | 0.07    | 93% ÌïòÎùΩ |

  Ìï¥ÏÑù:
  - Pixel-levelÏùÄ patchÎ≥Ñ anomaly score = -log p(z) - log|det J|
  - Image-levelÏùÄ patch scoresÏùò 99th percentile
  - Pixel AUC > 0.5: patchÎì§ Í∞ÑÏùò ÏÉÅÎåÄÏ†Å ÏàúÏÑúÎäî Ïñ¥Îäê Ï†ïÎèÑ Ïú†ÏßÄÎê®
  - Image AUC ‚âà 0: Î™®Îì† Ïù¥ÎØ∏ÏßÄÏùò 99th percentile Í∞íÏù¥ Ï†ÑÏ≤¥Ï†ÅÏúºÎ°ú shiftÎêòÏñ¥ normal/anomaly Íµ¨Î∂Ñ Î∂àÍ∞Ä

  ÏùòÎØ∏: SpatialMixer Î≥ÄÍ≤ΩÏúºÎ°ú Ï†ÑÏ≤¥ score Î∂ÑÌè¨Í∞Ä shiftÎê®. Í∞úÎ≥Ñ patchÏùò ÏÉÅÎåÄÏ†Å Ï∞®Ïù¥Îäî Ïú†ÏßÄÎêòÏßÄÎßå, image-level ÌÜµÍ≥ÑÍ∞Ä Î¨¥ÏùòÎØ∏Ìï¥Ïßê.

  bottle (ÏïåÌååÎ≤≥ ÏàúÏÑú)

  | Metric    | Task 0 | Task 14 | ÏÑ§Î™Ö         |
  |-----------|--------|---------|--------------|
  | Pixel AUC | 0.94   | 0.12    | Random Ïù¥Ìïò! |
  | Image AUC | 1.00   | 0.30    | 70% ÌïòÎùΩ     |

  Ìï¥ÏÑù:
  - Pixel AUC = 0.12 < 0.5: Î™®Îç∏Ïù¥ Î∞òÎåÄÎ°ú ÏòàÏ∏°
  - Anomaly patchÏóê ÎÇÆÏùÄ score, Normal patchÏóê ÎÜíÏùÄ score
  - Ïù¥Îäî Îã®ÏàúÌïú distribution shiftÍ∞Ä ÏïÑÎãàÎùº representation ÏûêÏ≤¥Ïùò inversion

  ÏùòÎØ∏: SpatialMixerÍ∞Ä bottleÏùò feature spaceÎ•º ÏôÑÏ†ÑÌûà Îí§ÏßëÏñ¥Î≤ÑÎ¶º. Îçî Ïã¨Í∞ÅÌïú ÏÜêÏÉÅ.

  ---
  5. OGPÏùò ÌïúÍ≥Ñ

  OGPÎäî gradientÎ•º Ïù¥Ï†Ñ taskÏùò Ï§ëÏöî subspaceÏóê orthogonalÌïòÍ≤å Ìà¨ÏòÅ:

  g' = g - Œ£(basis_i @ basis_i^T @ g)

  Î¨∏Ï†úÏ†ê:
  1. ÎàÑÏ†Å Ï†úÏïΩ: 15Í∞ú task √ó 50 rank = 750Í∞úÏùò orthogonal Î∞©Ìñ• Ï†úÏïΩ
  2. Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞Ïóê Ï†ÅÏö©: SpatialMixerÏùò gradientÎèÑ Ìà¨ÏòÅÎê®
  3. Î∂àÏôÑÏ†ÑÌïú Î≥¥Ìò∏: Ìà¨ÏòÅ ÌõÑÏóêÎèÑ ÎÇ®ÏùÄ gradientÍ∞Ä Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞Î•º Î≥ÄÍ≤Ω

  Task 0 basis: [v1, v2, ..., v50]  (leather Ï§ëÏöî Î∞©Ìñ•)
  Task 1 ÌïôÏäµ: g' = g - proj(g, Task0_basis)
                ‚Üë
         Ïù¥ g'Í∞Ä SpatialMixerÎ•º Î≥ÄÍ≤Ω ‚Üí leather ÏÜêÏÉÅ

  ---
  6. ÌïµÏã¨ Î¨∏Ï†ú ÏöîÏïΩ

  | Î¨∏Ï†ú                | ÏÑ§Î™Ö                                  | Ïã¨Í∞ÅÎèÑ      |
  |---------------------|---------------------------------------|-------------|
  | Í≥µÏú† SpatialMixer   | Î™®Îì† taskÏóêÏÑú ÌïôÏäµÎêòÏñ¥ Ïù¥Ï†Ñ task ÏÜêÏÉÅ | üî¥ Critical |
  | OGP ÎàÑÏ†Å Ï†úÏïΩ       | Task Ïàò Ï¶ùÍ∞Ä Ïãú ÌïôÏäµ Í≥µÍ∞Ñ Ï∂ïÏÜå        | üü† High     |
  | ÌÅ¥ÎûòÏä§ ÏàúÏÑú ÏùòÏ°¥ÏÑ±  | Ïú†ÏÇ¨ ÌÅ¥ÎûòÏä§Í∞Ä Ïó∞ÏÜçÎêòÎ©¥ Îçî Îπ†Î•∏ Î∂ïÍ¥¥   | üü° Medium   |
  | Task 0 Base NF Ìé∏Ìñ• | Ï≤´ taskÏóêÎßå ÏµúÏ†ÅÌôîÎêú Base NF          | üü° Medium   |

  ---
  7. RoutingÏù¥ 100% Ï†ïÌôïÌïúÎç∞ÎèÑ Î∂ïÍ¥¥ÌïòÎäî Ïù¥Ïú†

  Evaluation: leather test image
    ‚Üì
  Router: "This is leather" (100% Ï†ïÌôï)
    ‚Üì
  WhiteningAdapter_0: leatherÏö© adapter ‚úì
    ‚Üì
  SpatialMixer: Task 14 Ïù¥ÌõÑ Î≤ÑÏ†Ñ ‚úó  ‚Üê Ïó¨Í∏∞ÏÑú Î¨∏Ï†ú!
    ‚Üì
  BaseNF + LoRA_0: leatherÏö© ‚úì
    ‚Üì
  DIA_0: leatherÏö© ‚úì
    ‚Üì
  Wrong output due to SpatialMixer mismatch

  Í≤∞Î°†: Task-specific Ïª¥Ìè¨ÎÑåÌä∏Îäî Ï†ïÏÉÅÏù¥ÏßÄÎßå, Í≥µÏú† Ïª¥Ìè¨ÎÑåÌä∏(SpatialMixer)Ïùò ÎìúÎ¶¨ÌîÑÌä∏Í∞Ä Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏ÏùÑ Ïò§ÏóºÏãúÌÇ¥.

---

## V3 Í∑ºÎ≥∏Ï†Å Î¨∏Ï†úÏôÄ Ìï¥Í≤∞ Î∞©Ìñ•

### Í∑ºÎ≥∏Ï†Å Î¨∏Ï†ú ÏßÑÎã®

V3Ïùò Í∞ÄÏ†ï:
> "Task 0ÏóêÏÑú ÌïôÏäµÎêú Base NFÍ∞Ä Î™®Îì† taskÏóê Î≤îÏö©Ï†ÅÏúºÎ°ú Ï†ÅÏö© Í∞ÄÎä•ÌïòÍ≥†, LoRA/DIAÎ°ú task-specific adaptationÎßå ÌïòÎ©¥ ÎêúÎã§"

**Ïù¥ Í∞ÄÏ†ïÏù¥ ÌãÄÎ¶∞ Ïù¥Ïú†:**

1. **Base NFÏùò Î≥∏ÏßàÏ†Å Ìé∏Ìñ•**
   - Base NFÎäî Task 0 (leather ÎòêÎäî bottle)Ïùò "normal = Î¨¥Í≤∞Ìï®" Î∂ÑÌè¨Îßå ÌïôÏäµ
   - Îã§Î•∏ taskÏùò normal distributionÍ≥º Í∑ºÎ≥∏Ï†ÅÏúºÎ°ú Îã§Î¶Ñ
   - LoRA/DIAÎäî "fine-tuning"Ïùº Îøê, transformation ÏûêÏ≤¥Î•º Î∞îÍøÄ Ïàò ÏóÜÏùå

2. **Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞Ïùò ÏπòÎ™ÖÏ†Å ÏòÅÌñ•**
   - SpatialMixerÍ∞Ä Î™®Îì† taskÏóêÏÑú ÌïôÏäµÎê®
   - OGPÎäî gradientÎ•º Ï†úÌïúÌï† Îøê, ÏôÑÏ†ÑÌïú Î≥¥Ìò∏ Î∂àÍ∞Ä
   - Task Ïàò Ï¶ùÍ∞Ä Ïãú OGP Ï†úÏïΩ Í≥µÍ∞Ñ Ìè¨Ìôî ‚Üí Ïù¥Ï†Ñ task ÏÜêÏÉÅ

3. **LoRA/DIAÏùò ÌëúÌòÑÎ†• ÌïúÍ≥Ñ**
   - LoRA: `W + BA` (Ï†ÄÏ∞®Ïõê linear adaptation)
   - DIA: ÏûëÏùÄ flow block (2 coupling layers)
   - Base NFÍ∞Ä ÏûòÎ™ªÎêú Î≥ÄÌôòÏùÑ ÌïòÎ©¥ Ïù¥Î•º Î≥¥Ï†ïÌïòÍ∏∞ Ïñ¥Î†§ÏõÄ

### Í∞ÄÎä•Ìïú Ìï¥Í≤∞ Î∞©Ìñ•

| Ï†ëÍ∑ºÎ≤ï | ÏÑ§Î™Ö | Ïû•Ï†ê | Îã®Ï†ê |
|--------|------|------|------|
| **ÏÇ¨Ï†ÑÌïôÏäµ Base NF** | Îã§ÏñëÌïú domainÏóêÏÑú Base NF ÏÇ¨Ï†ÑÌïôÏäµ | Task-agnostic ÌëúÌòÑ | ÏÇ¨Ï†ÑÌïôÏäµ Îç∞Ïù¥ÌÑ∞ ÌïÑÏöî |
| **ÏôÑÏ†Ñ Î∂ÑÎ¶¨** | Î™®Îì† trainable ÌååÎùºÎØ∏ÌÑ∞ task-specific | Í∞ÑÏÑ≠ ÏõêÏ≤ú Ï∞®Îã® | Î©îÎ™®Î¶¨ Ï¶ùÍ∞Ä |
| **Replay Í∏∞Î∞ò** | Ïù¥Ï†Ñ task Îç∞Ïù¥ÌÑ∞ ÏùºÎ∂Ä Ï†ÄÏû• | ÏßÅÏ†ëÏ†Å forgetting Î∞©ÏßÄ | Privacy, Ï†ÄÏû• ÎπÑÏö© |

### Ï±ÑÌÉù Î∞©Ìñ•: ÏôÑÏ†Ñ Î∂ÑÎ¶¨ (Complete Separation)

**ÏÑ†ÌÉù Ïù¥Ïú†:**
1. Í∑ºÎ≥∏ ÏõêÏù∏(Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞ ÎìúÎ¶¨ÌîÑÌä∏)ÏùÑ ÏõêÏ≤ú Ï∞®Îã®
2. Ï∂îÍ∞Ä Îç∞Ïù¥ÌÑ∞ ÏàòÏßë/Ï†ÄÏû• Î∂àÌïÑÏöî
3. Íµ¨ÌòÑ Î≥µÏû°ÎèÑ ÎÇÆÏùå
4. ÌôïÏû•ÏÑ± Î≥¥Ïû• (task Ïàò Ï¶ùÍ∞ÄÏóêÎèÑ ÏïàÏ†ï)

---

## V4 - Complete Separation Architecture

### ÌïµÏã¨ ÏõêÏπô
> "Î™®Îì† ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞Îäî task-specificÏù¥Ïñ¥Ïïº ÌïúÎã§"

### Architecture Overview

```
V3 (Î¨∏Ï†ú):
Input ‚Üí WhiteningAdapter[task] ‚Üí SpatialMixer[SHARED+Trained] ‚Üí BaseNF[frozen] + LoRA[task] ‚Üí DIA[task] ‚Üí Output
                                         ‚Üë
                                    Î™®Îì† taskÏóêÏÑú ÌïôÏäµ ‚Üí ÎìúÎ¶¨ÌîÑÌä∏

V4 (Ìï¥Í≤∞):
Input ‚Üí WhiteningAdapter[task] ‚Üí SpatialMixer[FROZEN] ‚Üí BaseNF[frozen] + LoRA[task] ‚Üí DIA[task] ‚Üí Output
                                         ‚Üë
                                    Task 0 Ïù¥ÌõÑ ÏôÑÏ†Ñ ÎèôÍ≤∞
```

### ÌïµÏã¨ Î≥ÄÍ≤ΩÏÇ¨Ìï≠

| Ïª¥Ìè¨ÎÑåÌä∏ | V3 | V4 | Î≥ÄÍ≤Ω Ïù¥Ïú† |
|----------|-----|-----|----------|
| **SpatialMixer** | Î™®Îì† taskÏóêÏÑú ÌïôÏäµ | Task 0 Ïù¥ÌõÑ freeze | Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞ ÎìúÎ¶¨ÌîÑÌä∏ Î∞©ÏßÄ |
| **OGP** | ÌôúÏÑ±Ìôî | Ï†úÍ±∞ (Î∂àÌïÑÏöî) | Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞ ÏóÜÏùå ‚Üí Ìà¨ÏòÅ Î∂àÌïÑÏöî |
| **WhiteningAdapter** | taskÎ≥Ñ | taskÎ≥Ñ (Ïú†ÏßÄ) | Ïù¥ÎØ∏ ÏôÑÏ†Ñ Î∂ÑÎ¶¨Îê® |
| **LoRA** | taskÎ≥Ñ | taskÎ≥Ñ (Ïú†ÏßÄ) | Ïù¥ÎØ∏ ÏôÑÏ†Ñ Î∂ÑÎ¶¨Îê® |
| **DIA** | taskÎ≥Ñ | taskÎ≥Ñ (Ïú†ÏßÄ) | Ïù¥ÎØ∏ ÏôÑÏ†Ñ Î∂ÑÎ¶¨Îê® |

### ÌïôÏäµ ÌîÑÎ°úÌÜ†ÏΩú

**Task 0 (Base Training)**:
```python
# ÌïôÏäµ ÎåÄÏÉÅ: SpatialMixer + BaseNF + LoRA_0 + WhiteningAdapter_0 + DIA_0
trainable = [
    spatial_mixer.parameters(),      # Task 0ÏóêÏÑúÎßå ÌïôÏäµ
    base_nf.parameters(),            # Task 0ÏóêÏÑúÎßå ÌïôÏäµ
    lora_adapters["0"].parameters(),
    whitening_adapters["0"].parameters(),
    dia_adapters["0"].parameters()
]
```

**Task 1+ (Adapter Only)**:
```python
# ÌïôÏäµ ÎåÄÏÉÅ: LoRA_t + WhiteningAdapter_t + DIA_t (Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞ ÏôÑÏ†Ñ freeze)
trainable = [
    lora_adapters[str(task_id)].parameters(),
    whitening_adapters[str(task_id)].parameters(),
    dia_adapters[str(task_id)].parameters()
]
# SpatialMixer, BaseNFÎäî ÏôÑÏ†Ñ freeze
```

### Íµ¨ÌòÑ Î≥ÄÍ≤ΩÏÇ¨Ìï≠

#### 1. mole_nf.py - get_fast_params() ÏàòÏ†ï

**Before (V3)**:
```python
def get_fast_params(self, task_id: int) -> List[nn.Parameter]:
    params = []
    # ... LoRA, WhiteningAdapter, DIA params ...

    # SpatialMixerÍ∞Ä Î™®Îì† taskÏóêÏÑú ÌïôÏäµÎê® ‚Üê Î¨∏Ï†ú!
    if self.spatial_mixer is not None:
        params.extend(self.spatial_mixer.parameters())

    return params
```

**After (V4)**:
```python
def get_fast_params(self, task_id: int) -> List[nn.Parameter]:
    params = []
    # ... LoRA, WhiteningAdapter, DIA params ...

    # V4: SpatialMixerÎäî Task 0ÏóêÏÑúÎßå ÌïôÏäµ, Ïù¥ÌõÑ freeze
    if self.spatial_mixer is not None and task_id == 0:
        params.extend(self.spatial_mixer.parameters())

    return params
```

#### 2. continual_trainer.py - OGP Ï†úÍ±∞

**V4ÏóêÏÑú OGPÍ∞Ä Î∂àÌïÑÏöîÌïú Ïù¥Ïú†:**
- OGPÎäî "Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞"Ïùò gradientÎ•º Ìà¨ÏòÅÌïòÏó¨ Ïù¥Ï†Ñ task Î≥¥Ìò∏
- V4ÏóêÏÑúÎäî Í≥µÏú† ÌååÎùºÎØ∏ÌÑ∞Í∞Ä Î™®Îëê frozen ‚Üí Î≥¥Ìò∏Ìï† ÎåÄÏÉÅ ÏóÜÏùå
- OGP Ïó∞ÏÇ∞ Ïò§Î≤ÑÌó§Îìú Ï†úÍ±∞ ‚Üí ÌïôÏäµ ÏÜçÎèÑ Ìñ•ÏÉÅ

```python
# V4: OGP ÎπÑÌôúÏÑ±Ìôî
if self.use_ogp:
    warnings.warn("V4 Complete Separation: OGP is unnecessary and will be disabled")
    self.use_ogp = False
```

#### 3. run.sh - V4 Ïã§Ìóò ÏÑ§Ï†ï

```bash
# V4: Complete Separation (WhiteningAdapter + DIA, no OGP, frozen SpatialMixer)
python run_moleflow.py \
    --task_classes leather grid transistor carpet zipper hazelnut \
                   toothbrush metal_nut screw wood tile capsule pill cable bottle \
    --use_whitening_adapter \
    --use_dia \
    --dia_n_blocks 2 \
    --no_ogp \                  # V4: OGP ÎπÑÌôúÏÑ±Ìôî
    --freeze_spatial_mixer \    # V4: SpatialMixer Task 0 Ïù¥ÌõÑ freeze
    --experiment_name Version4-CompleteSeparation
```

### ÏòàÏÉÅ Í≤∞Í≥º

| ÏßÄÌëú | V3 (15 classes) | V4 ÏòàÏÉÅ | Í∑ºÍ±∞ |
|------|-----------------|---------|------|
| Task 0 Image AUC | 0.07~0.30 | 0.90+ | SpatialMixer ÎìúÎ¶¨ÌîÑÌä∏ ÏóÜÏùå |
| Mean Image AUC | 0.72 | 0.85+ | Î™®Îì† task ÏïàÏ†ï |
| Routing Acc | 99.76% | 99%+ | Ïú†ÏßÄ (RouterÎäî Î≥ÄÍ≤Ω ÏóÜÏùå) |
| ÌïôÏäµ ÏÜçÎèÑ | 1x | 1.2x+ | OGP Ïó∞ÏÇ∞ Ï†úÍ±∞ |

### V4 Íµ¨ÌòÑ Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏

- [x] `mole_nf.py`: `get_fast_params()`ÏóêÏÑú SpatialMixer task_id Ï°∞Í±¥ Ï∂îÍ∞Ä
  - Line 720-725: `if self.spatial_mixer is not None and task_id == 0:`
- [x] `mole_nf.py`: `freeze_fast_params()` Task 0 Ï°∞Í±¥ Ï∂îÍ∞Ä
  - Line 759-762: SpatialMixer freeze only for Task 0
- [x] `mole_nf.py`: `unfreeze_fast_params()` Task 0 Ï°∞Í±¥ Ï∂îÍ∞Ä
  - Line 794-797: SpatialMixer unfreeze only for Task 0
- [x] `run.sh`: V4 Ïã§Ìóò Ïä§ÌÅ¨Î¶ΩÌä∏ Ï∂îÍ∞Ä
  - `--use_whitening_adapter --use_dia` (no OGP)
  - All 15 classes in alphabetical order

**Note**: Î≥ÑÎèÑ config ÏòµÏÖò Î∂àÌïÑÏöî - `task_id == 0` Ï°∞Í±¥ÏúºÎ°ú ÏûêÎèô Ï≤òÎ¶¨Îê®

### V4 File Changes Summary

| File | Changes |
|------|---------|
| `moleflow/models/mole_nf.py` | `get_fast_params()`, `freeze_fast_params()`, `unfreeze_fast_params()` - SpatialMixerÎäî task_id == 0Ïùº ÎïåÎßå ÌïôÏäµ |
| `run.sh` | V4 Ïã§Ìóò Ïä§ÌÅ¨Î¶ΩÌä∏: `Version4-CompleteSeparation_all_classes_alphabet` |

---

## V4 Experiment Results (15 Classes)

### Catastrophic Forgetting Ìï¥Í≤∞ ‚úÖ

| ÏàúÏÑú | Task 0 | V3 After Task 14 | V4 After Task 14 | Í∞úÏÑ† |
|------|--------|------------------|------------------|------|
| Original | leather | 0.07 (-93%) | **1.00 (0%)** | ‚úÖ ÏôÑÏ†Ñ Ìï¥Í≤∞ |
| Alphabet | bottle | 0.30 (-70%) | **0.999 (-0.08%)** | ‚úÖ ÏôÑÏ†Ñ Ìï¥Í≤∞ |

### Ï†ÑÏ≤¥ ÏÑ±Îä• ÎπÑÍµê

| ÏßÄÌëú | V3 Original | V4 Original | V4 Alphabet |
|------|-------------|-------------|-------------|
| Mean Image AUC | 0.7716 | **0.8636** | 0.8564 |
| Mean Pixel AUC | 0.9009 | **0.9272** | 0.9245 |
| Routing Acc | 99.76% | 99.76% | 99.76% |

**V4 vs V3: Mean Image AUC +12% Ìñ•ÏÉÅ**

### ÌÅ¥ÎûòÏä§Î≥Ñ ÏÉÅÏÑ∏ Í≤∞Í≥º (V4 Original Order)

| Class | Task ID | Image AUC | Pixel AUC | Gap |
|-------|---------|-----------|-----------|-----|
| leather | 0 | 1.000 | 0.972 | +0.03 |
| grid | 1 | 0.842 | 0.908 | -0.07 |
| transistor | 2 | 0.773 | 0.926 | -0.15 |
| carpet | 3 | 0.968 | 0.965 | +0.00 |
| zipper | 4 | 0.935 | 0.853 | +0.08 |
| hazelnut | 5 | 0.952 | 0.968 | -0.02 |
| toothbrush | 6 | 0.775 | 0.946 | -0.17 |
| metal_nut | 7 | 0.946 | 0.978 | -0.03 |
| screw | 8 | **0.420** | 0.856 | **-0.44** |
| wood | 9 | 0.979 | 0.895 | +0.08 |
| tile | 10 | 1.000 | 0.883 | +0.12 |
| capsule | 11 | 0.670 | 0.939 | -0.27 |
| pill | 12 | 0.819 | 0.951 | -0.13 |
| cable | 13 | 0.875 | 0.910 | -0.03 |
| bottle | 14 | 0.999 | 0.958 | +0.04 |

### Î∞úÍ≤¨Îêú Î¨∏Ï†ú

#### 1. ÎØ∏ÏÑ∏ ÏÑ±Îä• Î≥ÄÌôî (context_conv Í≥µÏú†)

grid Image AUC Ï∂îÏ†Å:
```
After Task  1: 0.8463
After Task 14: 0.8421 (-0.42%)
```

**ÏõêÏù∏**: `context_conv`ÏôÄ `context_scale_param`Ïù¥ Ïó¨Ï†ÑÌûà Î™®Îì† taskÏóêÏÑú ÌïôÏäµÎê®
```python
# mole_nf.py:706-710 (V4)
if hasattr(subnet, 'context_conv'):
    params.extend(subnet.context_conv.parameters())  # Î™®Îì† taskÏóêÏÑú ÌïôÏäµ!
```

#### 2. Image AUC << Pixel AUC Î¨∏Ï†ú

| Class | Image AUC | Pixel AUC | Gap | ÏõêÏù∏ |
|-------|-----------|-----------|-----|------|
| screw | 0.42 | 0.86 | -0.44 | ÎØ∏ÏÑ∏ Í≤∞Ìï®, normalÎèÑ high score |
| capsule | 0.67 | 0.94 | -0.27 | ÌòïÏÉÅ Ïú†ÏÇ¨ÏÑ± |
| toothbrush | 0.78 | 0.95 | -0.17 | ÌÖçÏä§Ï≤ò Ïú†ÏÇ¨ |

**ÏõêÏù∏ Î∂ÑÏÑù:**
- Image Score = max(patch scores) ÎòêÎäî 99th percentile
- Normal Ïù¥ÎØ∏ÏßÄÏùò ÏùºÎ∂Ä Ìå®ÏπòÍ∞Ä ÎÜíÏùÄ anomaly scoreÎ•º Í∞ÄÏßê
- Anomaly/Normal Ïù¥ÎØ∏ÏßÄÏùò max score Î∂ÑÌè¨Í∞Ä Ï§ëÏ≤©
- Pixel-levelÏùÄ Í∞úÎ≥Ñ Ìå®Ïπò Îã®ÏúÑÎ°ú ÌèâÍ∞ÄÎêòÏñ¥ Î∂ÑÎ¶¨Í∞Ä Ïûò Îê®

---

## V4.1 - True Complete Separation

### Î≥ÄÍ≤Ω Ïù¥Ïú†

V4ÏóêÏÑú `context_conv`Í∞Ä Ïó¨Ï†ÑÌûà Í≥µÏú†ÎêòÏñ¥ ÎØ∏ÏÑ∏ ÏÑ±Îä• Ï†ÄÌïò Î∞úÏÉù

### ÌïµÏã¨ Î≥ÄÍ≤Ω

| Ïª¥Ìè¨ÎÑåÌä∏ | V4 | V4.1 |
|----------|-----|------|
| SpatialMixer | Task 0 Ïù¥ÌõÑ freeze | Task 0 Ïù¥ÌõÑ freeze |
| **context_conv** | Î™®Îì† task ÌïôÏäµ | **Task 0 Ïù¥ÌõÑ freeze** |
| **context_scale_param** | Î™®Îì† task ÌïôÏäµ | **Task 0 Ïù¥ÌõÑ freeze** |

### Íµ¨ÌòÑ Î≥ÄÍ≤Ω

#### mole_nf.py - get_fast_params()

```python
# V4.1: MoLEContextSubnet context parameters - only trained in Task 0
if task_id == 0:
    if hasattr(subnet, 'context_conv'):
        params.extend(subnet.context_conv.parameters())
    if hasattr(subnet, 'context_scale_param') and subnet.context_scale_param is not None:
        params.append(subnet.context_scale_param)
```

#### mole_nf.py - get_trainable_params() (Task > 0 Î∏îÎ°ù)

```python
# V4.1: MoLEContextSubnet context parameters are frozen for Task > 0
# They are only trained in Task 0 (see the task_id == 0 block above)
```

### V4.1 File Changes

| File | Changes |
|------|---------|
| `moleflow/models/mole_nf.py` | `get_fast_params()`, `get_trainable_params()`, `freeze_fast_params()`, `unfreeze_fast_params()` - context_convÎèÑ task_id == 0Ïùº ÎïåÎßå ÌïôÏäµ |
| `run.sh` | V4.1 Ïã§Ìóò Ïä§ÌÅ¨Î¶ΩÌä∏ Ï∂îÍ∞Ä |

### ÏòàÏÉÅ Í≤∞Í≥º

| ÏßÄÌëú | V4 | V4.1 ÏòàÏÉÅ |
|------|-----|-----------|
| Task ÏÑ±Îä• Î≥ÄÌôî | -0.42% | **0%** (ÏôÑÏ†Ñ Í≥†Ï†ï) |
| ÌïôÏäµ ÌååÎùºÎØ∏ÌÑ∞ | LoRA + DIA + WhiteningAdapter + context_conv | LoRA + DIA + WhiteningAdapter |

---