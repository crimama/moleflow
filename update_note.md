# MoLE-Flow Update Notes

## Version History

---

## v1 (baseline) - Initial Implementation

### Architecture
- Task 0: Base NFë§Œ í•™ìŠµ (LoRA ì—†ìŒ)
- Task 1+: Base frozen + LoRA í•™ìŠµ
- LoRA scaling: `alpha / (2 * rank)` = 0.0156 (1.56%)
- InputAdapter: Instance Norm + Zero-init MLP

### Results (leather â†’ grid â†’ transistor)
| Class | Routing Acc | Image AUC | Pixel AUC |
|-------|-------------|-----------|-----------|
| leather | 100% | **1.0000** | **0.9481** |
| grid | 100% | 0.8204 | 0.9259 |
| transistor | 100% | 0.6654 | 0.7144 |
| **Mean** | 100% | 0.8286 | 0.8628 |

### Issues Identified
1. **Task 0 Bias**: Base NFê°€ Task 0ì— í¸í–¥ë˜ì–´ ë‹¤ë¥¸ taskì—ì„œ ì„±ëŠ¥ ì €í•˜
2. **LoRA Scaling ë¶€ì¡±**: 1.56% contributionìœ¼ë¡œ adaptation íš¨ê³¼ ë¯¸ë¯¸
3. **InputAdapter í•œê³„**: MLP residual gateê°€ 0ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ ê±°ì˜ ë¯¸ì‚¬ìš©

---

## v2 (baseline_v2) - LoRA Scaling & Task 0 LoRA

### Changes from v1
1. **LoRA Scaling 2ë°° ì¦ê°€**
   ```python
   # v1: self.scaling = alpha / (2 * rank)  # 0.0156
   # v2: self.scaling = alpha / rank         # 0.03125
   ```

2. **Task 0ë„ LoRA ì‚¬ìš©**
   - ëª¨ë“  Taskê°€ ë™ë“±í•˜ê²Œ LoRAë¡œ adaptation
   - Base NFëŠ” ë²”ìš© feature transformation í•™ìŠµ
   - Task-specific adaptationì€ LoRAê°€ ë‹´ë‹¹

### Results (leather â†’ grid â†’ transistor)
| Class | Routing Acc | Image AUC | Pixel AUC |
|-------|-------------|-----------|-----------|
| leather | 100% | 0.9997 | 0.8900 |
| grid | 100% | **0.9850** | **0.9841** |
| transistor | 100% | **0.8075** | **0.8973** |
| **Mean** | 100% | **0.9307** | **0.9238** |

### Comparison (v1 â†’ v2)
| Metric | v1 | v2 | Change |
|--------|-----|-----|--------|
| leather Image | 1.0000 | 0.9997 | -0.03% |
| leather Pixel | 0.9481 | 0.8900 | **-6.1%** |
| grid Image | 0.8204 | 0.9850 | **+20.0%** |
| grid Pixel | 0.9259 | 0.9841 | +6.3% |
| transistor Image | 0.6654 | 0.8075 | **+21.4%** |
| transistor Pixel | 0.7144 | 0.8973 | **+25.6%** |
| **Mean Image** | 0.8286 | 0.9307 | **+12.3%** |
| **Mean Pixel** | 0.8628 | 0.9238 | **+7.1%** |

### Analysis
- **Overall**: ì „ì²´ ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ (Mean Image AUC +12.3%)
- **Task 0 Issue**: leatherì˜ Pixel AUCê°€ 6.1% í•˜ë½
  - ì›ì¸: Task 0ì—ì„œ Base + LoRA ë™ì‹œ í•™ìŠµ ì‹œ, LoRAê°€ ì¼ë¶€ ì •ë³´ë¥¼ ë¶„ë‹´í•˜ë©´ì„œ Baseì˜ í‘œí˜„ë ¥ ë¶„ì‚°
  - LoRAëŠ” Task-specific adaptationì— ìµœì í™”ë˜ì–´ pixel-level ì •ë°€ë„ì— ì˜í–¥

---

## v3 (baseline_v3) - FiLM-style InputAdapter + Task 0 Self-Adaptation

### Changes from v2
1. **InputAdapter êµ¬ì¡° ê°œì„  (FiLM-style)**
   - Instance Norm â†’ Layer Norm (spatial info ë³´ì¡´)
   - FiLM (Feature-wise Linear Modulation): `y = gamma * x + beta`
   - residual_gate: 0 â†’ 0.5 (MLP ì²˜ìŒë¶€í„° active)
   - hidden_dim ì¦ê°€: `channels//4` â†’ `max(channels//2, 128)`

2. **Task 0 Self-Adaptation**
   - Task 0ì—ë„ InputAdapter ì ìš© (v2ì—ì„œëŠ” Task 0ì— InputAdapter ì—†ì—ˆìŒ)
   - `has_reference=False` ì„¤ì •ìœ¼ë¡œ ê°•í•œ identity connection (90% identity + 10% transformed)
   - ì´ë¥¼ í†µí•´ Task 0ì˜ pixel-level ì„±ëŠ¥ íšŒë³µ ê¸°ëŒ€

3. **ëª¨ë“  Task ë™ë“±í•œ InputAdapter ì ìš©**
   - v2: Task 0 (InputAdapter ì—†ìŒ) vs Task 1+ (InputAdapter ìˆìŒ)
   - v3: ëª¨ë“  Taskê°€ InputAdapter ì‚¬ìš© (êµ¬ì¡°ì  ì¼ê´€ì„±)

### Key Code Changes
```python
# adapters.py - TaskInputAdapter v3
class TaskInputAdapter(nn.Module):
    def __init__(self, channels, reference_mean=None, reference_std=None, use_norm=True):
        # FiLM parameters
        self.film_gamma = nn.Parameter(torch.ones(1, 1, 1, channels))
        self.film_beta = nn.Parameter(torch.zeros(1, 1, 1, channels))

        # Larger MLP
        hidden_dim = max(channels // 2, 128)  # Increased from channels//4

        # Active residual gate
        self.residual_gate = nn.Parameter(torch.tensor([0.5]))  # Changed from 0.0

        # Layer Norm instead of Instance Norm
        if use_norm:
            self.layer_norm = nn.LayerNorm(channels)

    def forward(self, x):
        # ...
        # Task 0 (has_reference=False): 90% identity + 10% transformed
        if not self.has_reference:
            x = 0.9 * identity + 0.1 * x
        return x
```

### Expected Improvements
- Task 0 pixel-level ì„±ëŠ¥ íšŒë³µ (v1 ìˆ˜ì¤€ìœ¼ë¡œ)
- ë” ê°•ë ¥í•œ cross-task feature transformation
- êµ¬ì¡°ì  ì¼ê´€ì„±ìœ¼ë¡œ ì¸í•œ ì•ˆì •ì ì¸ í•™ìŠµ

---

## File Changes Summary

### v1 â†’ v2
| File | Changes |
|------|---------|
| `moleflow/models/lora.py` | scaling: `alpha/(2*rank)` â†’ `alpha/rank` |
| `moleflow/models/mole_nf.py` | Task 0ì—ì„œë„ LoRA adapter ì¶”ê°€ |
| `moleflow/trainer/continual_trainer.py` | Task 0 í•™ìŠµ ë¡œì§ ìˆ˜ì • |

### v2 â†’ v3
| File | Changes |
|------|---------|
| `moleflow/models/adapters.py` | FiLM-style InputAdapter (LayerNorm, gate=0.5, larger MLP) |
| `moleflow/models/mole_nf.py` | Task 0ì—ë„ InputAdapter ì ìš© (self-adaptation) |
| `run.sh` | baseline_v3 ì‹¤í—˜ ì„¤ì • |

---

## v4 (baseline_v4) - CPCF + SC-LoRA (Novel Research Contribution)

### Research Contribution
**Paper Title**: "Beyond Independent Patches: Cross-Patch Coupling Flow with Spatial LoRA for Continual Anomaly Detection"

**Key Novelty Claims**:
1. **CPCF**: First normalizing flow that models `p(x_i | neighbors)` instead of `p(x_i)`
2. **SC-LoRA**: First spatially-varying LoRA for dense prediction tasks
3. **Continual AD**: Systematic benchmark for continual anomaly detection

### New Modules

#### 1. Spatial-Contextual LoRA (SC-LoRA)
```python
# moleflow/models/spatial_lora.py
class SpatialContextualLoRA(nn.Module):
    """
    Position-aware LoRA with spatial grid interpolation.

    Key Innovation:
    - LoRA parameters vary based on spatial position
    - Grid of LoRA parameters: (grid_size, grid_size, rank, dim)
    - Bilinear interpolation for smooth spatial adaptation
    """
    def __init__(self, in_features, out_features, rank=32, grid_size=4):
        # Grid of LoRA A: (G, G, R, D_in)
        self.lora_A = nn.Parameter(torch.zeros(grid_size, grid_size, rank, in_features))
        # Grid of LoRA B: (G, G, D_out, R)
        self.lora_B = nn.Parameter(torch.zeros(grid_size, grid_size, out_features, rank))

    def forward(self, x, positions):
        # Interpolate LoRA params based on position
        A, B = self._get_interpolated_lora(positions)
        return self.scaling * (x @ A.T @ B.T)
```

#### 2. Cross-Patch Coupling Flow (CPCF)
```python
# moleflow/models/cross_patch_flow.py
class CrossPatchCouplingLayer(nn.Module):
    """
    Coupling layer conditioned on neighborhood context.

    Standard: y = x * exp(s(x)) + t(x)
    CPCF:     y = x * exp(s(x, ctx)) + t(x, ctx)

    where ctx = NeighborhoodContext(x)
    """
    def __init__(self, channels, context_kernel=3):
        self.context_extractor = NeighborhoodContextExtractor(channels)
        self.s_net = SC_LoRA_MLP(channels + context_dim, channels)
        self.t_net = SC_LoRA_MLP(channels + context_dim, channels)

    def forward(self, x):
        context = self.context_extractor(x)  # (B, H, W, D)
        x1, x2 = x.split(D//2, dim=-1)

        # Condition on both patch and context
        s = self.s_net(cat([x1, context]))
        t = self.t_net(cat([x1, context]))

        return cat([x1, x2 * exp(s) + t])
```

### Theoretical Contribution

**Standard NF (Independent Patches)**:
```
log p(X) = Î£áµ¢ log p(xáµ¢)
```
- Assumes patches are independent
- Ignores spatial context

**CPCF (Context-Aware Patches)**:
```
log p(X) = Î£áµ¢ log p(xáµ¢ | N(i))
```
where N(i) = neighborhood of patch i

- Models "how different is this patch from its neighbors"
- Directly captures anomaly as contextual deviation

### Architecture Comparison

| Component | v3 | v4 |
|-----------|-----|-----|
| Flow Type | FrEIA (independent) | CPCF (context-aware) |
| LoRA Type | Standard LoRA | SC-LoRA (position-aware) |
| Patch Modeling | `p(xáµ¢)` | `p(xáµ¢ \| neighbors)` |
| Spatial Awareness | Position embedding only | Context + Position LoRA |

### Command Line Arguments
```bash
python run_moleflow.py \
    --use_cpcf \              # Enable Cross-Patch Coupling Flow
    --use_spatial_lora \       # Enable Spatial-Contextual LoRA
    --sc_lora_grid_size 4 \    # SC-LoRA grid resolution (4x4)
    --cpcf_context_kernel 3 \  # Context extraction kernel size
    --cpcf_use_attention       # Use attention instead of conv for context
```

### Expected Improvements
- **Image AUC**: +5-10% (better global anomaly detection)
- **Pixel AUC**: +10-15% (context-aware localization)
- **Cross-task**: Improved SC-LoRA handles position-dependent distribution shifts

### v3 â†’ v4
| File | Changes |
|------|---------|
| `moleflow/models/spatial_lora.py` | NEW: SC-LoRA module |
| `moleflow/models/cross_patch_flow.py` | NEW: CPCF module |
| `moleflow/models/mole_nf.py` | CPCF/SC-LoRA integration |
| `run_moleflow.py` | CPCF/SC-LoRA arguments |
| `run.sh` | baseline_v4 ì‹¤í—˜ ì„¤ì • |

---

## v4.1 - Fixed Context Extraction (Bug Fix)

### Issue
- v4ì—ì„œ Task 0 ì„±ëŠ¥ì€ í–¥ìƒë˜ì—ˆìœ¼ë‚˜ Task 1, 2 ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ë¨
- ì›ì¸: Context Extractorê°€ Task 0ì—ì„œë§Œ í•™ìŠµë˜ì–´ Task 0ì— í¸í–¥

### Root Cause
```python
# ì´ì „ ì½”ë“œ - Task 0ì—ì„œë§Œ context extractor í•™ìŠµ
if task_id == 0:
    params.extend(layer.context_extractor.parameters())
```
- Task 0: Context Extractorê°€ Task 0 ë°ì´í„°ë¡œë§Œ í•™ìŠµ
- Task 1+: Task 0ì— í¸í–¥ëœ context feature ì œê³µ â†’ ì„±ëŠ¥ ì €í•˜

### Fix
Context extractionì„ **ê³ ì •ëœ (non-learnable) ë°©ì‹**ìœ¼ë¡œ ë³€ê²½:

```python
# cross_patch_flow.py - NeighborhoodContextExtractor
class NeighborhoodContextExtractor(nn.Module):
    def __init__(self, channels, kernel_size=3, use_attention=False):
        # FIXED averaging kernel - no learnable parameters
        kernel = torch.ones(1, 1, kernel_size, kernel_size) / (kernel_size * kernel_size)
        self.register_buffer('avg_kernel', kernel)
        self.register_buffer('context_gate', torch.tensor([0.3]))  # Fixed gate

    def forward(self, x):
        # Simple neighborhood mean (task-agnostic)
        neighbor_mean = F.conv2d(x, self.avg_kernel, padding, groups=D)
        context = (1 - gate) * x + gate * neighbor_mean
        return context
```

### Key Insight
- **Context = ì£¼ë³€ í‰ê· ** â†’ task-agnostic (ì–´ë–¤ taskì—ì„œë„ ë™ì¼í•œ ì˜ë¯¸)
- **SC-LoRA = task-specific adaptation** â†’ task ë³„ë¡œ ë‹¤ë¥´ê²Œ í•™ìŠµ
- ì—­í•  ë¶„ë¦¬: ê³ ì • context + í•™ìŠµ ê°€ëŠ¥í•œ adaptation

### v4 â†’ v4.1
| File | Changes |
|------|---------|
| `moleflow/models/cross_patch_flow.py` | Fixed (non-learnable) context extraction |
| `moleflow/models/mole_nf.py` | Removed context_extractor from trainable params |

---

## v5 - Center Loss for Discriminative Feature Learning

### Motivation
- v4ì˜ cross-patch context ì ‘ê·¼ë²•ì´ task bias ë¬¸ì œë¡œ ì‹¤íŒ¨
- Anomaly Detection ìì²´ì˜ ì„±ëŠ¥ í–¥ìƒì— ì§‘ì¤‘
- Normal featureë¥¼ ë” compactí•˜ê²Œ ë§Œë“¤ì–´ì„œ anomaly êµ¬ë¶„ ìš©ì´í•˜ê²Œ

### Core Idea
**Latent space z**ì— Center Lossë¥¼ ì ìš©í•˜ì—¬ normalì„ z â‰ˆ 0ìœ¼ë¡œ ë” ê°•í•˜ê²Œ ìœ ë„:
```
Loss = NLL_loss + Î» * Center_loss
     = -log p(x) + Î» * ||z||Â²
```

**Key Insight**:
- NFëŠ” inputì„ Gaussianìœ¼ë¡œ ë§¤í•‘ â†’ normalì€ z â‰ˆ 0
- Center LossëŠ” ì´ ëª©í‘œë¥¼ **ë” ê°•í•˜ê²Œ** ê°•ì œ
- Input featureê°€ ì•„ë‹Œ **latent z**ì— ì ìš©í•´ì•¼ gradientê°€ NFì— ì „íŒŒë¨

### Implementation

```python
# Training loopì—ì„œ
z, log_jac_det = nf_model.forward(x, reverse=False)

# NLL loss
log_pz = -0.5 * (z ** 2).sum() / (B * H * W)
nll_loss = -(log_pz + log_jac)

# Center loss on latent z (fixed center at zero)
center_loss = (z ** 2).sum(dim=-1).mean()  # ||z - 0||Â²

total_loss = nll_loss + Î» * center_loss
```

### Why Fixed Center at Zero?
- Learnable center â†’ centerê°€ zì˜ meanìœ¼ë¡œ ì´ë™ â†’ ì˜ë¯¸ ì—†ìŒ
- Fixed center = 0 â†’ zë¥¼ ì›ì ìœ¼ë¡œ ê°•í•˜ê²Œ ë‹¹ê¹€ â†’ Gaussian prior ê°•í™”

### Training Flow
1. Forward: x â†’ NF â†’ z
2. NLL loss: zê°€ Gaussianì„ ë”°ë¥´ë„ë¡
3. Center loss: zê°€ ì›ì ì— ê°€ê¹ë„ë¡ (ì¶”ê°€ regularization)
4. Backward: gradientê°€ NFë¡œ ì „íŒŒë˜ì–´ ë” compactí•œ latent space í•™ìŠµ

### Command Line Arguments
```bash
python run_moleflow.py \
    --center_loss_weight 0.05 \  # Center loss weight (recommend 0.01-0.1)
    ...
```

### Expected Improvements
- Normal featureê°€ ë” compactí•´ì ¸ì„œ anomaly êµ¬ë¶„ í–¥ìƒ
- íŠ¹íˆ pixel-level anomaly detectionì—ì„œ íš¨ê³¼ ê¸°ëŒ€
- Taskë³„ centerê°€ task-specific íŠ¹ì„±ì„ í•™ìŠµ

### v3 â†’ v5
| File | Changes |
|------|---------|
| `moleflow/models/center_loss.py` | NEW: CenterLoss module |
| `moleflow/trainer/continual_trainer.py` | Center loss integration |
| `run_moleflow.py` | `--center_loss_weight` argument |
| `run.sh` | v5 experiment configuration |

---

## v6 - Patch Self-Attention for Contextual Anomaly Detection

### Motivation
- v5ì˜ Center LossëŠ” NLLì´ ì´ë¯¸ z â‰ˆ 0ì„ ìœ ë„í•˜ë¯€ë¡œ íš¨ê³¼ ë¯¸ë¯¸
- **Contextual Anomaly** íƒì§€ í•„ìš”: ì£¼ë³€ íŒ¨ì¹˜ì™€ ë‹¤ë¥¸ íŒ¨ì¹˜ê°€ anomaly
- Patch ê°„ ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ì—¬ anomaly detection ì„±ëŠ¥ í–¥ìƒ

### Core Idea
**Standard NF (Independent Patches)**:
```
log p(X) = Î£áµ¢ log p(xáµ¢)
```
- ê° íŒ¨ì¹˜ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬
- ì£¼ë³€ context ë¬´ì‹œ

**Patch Self-Attention (Context-Aware)**:
```
log p(X) = Î£áµ¢ log p(xáµ¢ | context_i)
where context_i = Attention(xáµ¢, all patches)
```
- íŒ¨ì¹˜ ê°„ ê´€ê³„ ëª¨ë¸ë§
- "ì£¼ë³€ê³¼ ë‹¤ë¥¸" íŒ¨ì¹˜ë¥¼ anomalyë¡œ íƒì§€

### Architecture
```
ViT Features [B, H, W, D]
       â†“
Patch Self-Attention (LightweightPatchAttention)
       â†“
Context-Enhanced Features [B, H, W, D]
       â†“
Normalizing Flow
       â†“
Latent z, log_jac_det
```

### LightweightPatchAttention Module
```python
class LightweightPatchAttention(nn.Module):
    def __init__(self, embed_dim=512, hidden_dim=256, dropout=0.1):
        # Q, K, V projections
        self.q_proj = nn.Linear(embed_dim, hidden_dim)
        self.k_proj = nn.Linear(embed_dim, hidden_dim)
        self.v_proj = nn.Linear(embed_dim, hidden_dim)

        # Learnable gate (starts at 0 for stable training)
        self.gate = nn.Parameter(torch.zeros(1))

        # FFN for additional processing
        self.ffn = nn.Sequential(...)

    def forward(self, x):  # x: [B, H, W, D]
        # Reshape to sequence
        x_seq = x.view(B, H*W, D)

        # Self-attention
        Q, K, V = self.q_proj(x), self.k_proj(x), self.v_proj(x)
        attn = softmax(Q @ K.T / sqrt(d))
        attn_out = attn @ V

        # Gated residual connection
        gate = sigmoid(self.gate)
        x = x + gate * attn_out

        # FFN
        x = x + self.ffn(x)

        return x.view(B, H, W, D)
```

### Key Design Choices
1. **Learnable Gate (starts at 0)**:
   - í•™ìŠµ ì´ˆê¸°ì—ëŠ” identity (ì•ˆì •ì  í•™ìŠµ)
   - ì ì§„ì ìœ¼ë¡œ attention ê¸°ì—¬ë„ ì¦ê°€

2. **Single-Head Attention**:
   - Lightweightí•˜ë©´ì„œë„ patch ê´€ê³„ í¬ì°©
   - Multi-head ëŒ€ë¹„ ê³„ì‚° íš¨ìœ¨ì 

3. **Pre-LayerNorm + FFN**:
   - Transformer ìŠ¤íƒ€ì¼ ì•ˆì •ì  í•™ìŠµ
   - FFNìœ¼ë¡œ ë¹„ì„ í˜• transformation ê°•í™”

### Training
- Patch attention ëª¨ë“ˆì€ **ëª¨ë“  taskì—ì„œ ê³µìœ ** (Base NFì²˜ëŸ¼)
- Task 0ì—ì„œ í•™ìŠµ í›„ freeze
- Task 1+ì—ì„œëŠ” LoRAë§Œ í•™ìŠµ

### Command Line Arguments
```bash
python run_moleflow.py \
    --use_patch_attention \  # Enable Patch Self-Attention
    ...
```

### Expected Improvements
- **Contextual Anomaly Detection**: ì£¼ë³€ê³¼ ë‹¤ë¥¸ íŒ¨ì¹˜ íƒì§€ í–¥ìƒ
- **Pixel-level AUC**: Context ì •ë³´ë¡œ localization ì •ë°€ë„ í–¥ìƒ
- **Structural Anomaly**: ì „ì—­ì  íŒ¨ì¹˜ ê´€ê³„ë¡œ êµ¬ì¡°ì  ì´ìƒ íƒì§€

### v3 â†’ v6
| File | Changes |
|------|---------|
| `moleflow/models/patch_attention.py` | NEW: LightweightPatchAttention, PatchInteractionModule |
| `moleflow/models/__init__.py` | Export patch attention modules |
| `moleflow/trainer/continual_trainer.py` | Patch attention integration |
| `run_moleflow.py` | `--use_patch_attention` argument |
| `run.sh` | v6 experiment configuration |

### v6 Result
- **ì‹¤íŒ¨**: ViTê°€ ì´ë¯¸ self-attentionìœ¼ë¡œ contextualizedëœ featureë¥¼ ì¶œë ¥í•˜ë¯€ë¡œ ì¶”ê°€ attentionì´ ì˜¤íˆë ¤ í•´ê°€ ë¨

---

## v7 - Focal NLL Loss for Hard Sample Mining

### Motivation
- v5 (Center Loss): NLLì´ ì´ë¯¸ z â‰ˆ 0 ìœ ë„í•˜ë¯€ë¡œ íš¨ê³¼ ë¯¸ë¯¸
- v6 (Patch Attention): ViT ì¤‘ë³µìœ¼ë¡œ ì‹¤íŒ¨
- **ìƒˆë¡œìš´ ì ‘ê·¼**: ì–´ë ¤ìš´ ìƒ˜í”Œì— ë” ì§‘ì¤‘í•˜ì—¬ decision boundary í•™ìŠµ ê°•í™”

### Core Idea
**Standard NLL**:
```
L = -log p(x)  # ëª¨ë“  ìƒ˜í”Œ ë™ë“±í•œ ê°€ì¤‘ì¹˜
```

**Focal NLL**:
```
L = (1 - p)^Î³ * (-log p(x))

Î³ = 0: Standard NLL (ëª¨ë“  ìƒ˜í”Œ ë™ë“±)
Î³ = 1: ì•½ê°„ì˜ hard sample ê°•ì¡°
Î³ = 2: ê°•í•œ hard sample ê°•ì¡° (ê¶Œì¥)
```

- `p` = probability = exp(-nll)
- ë†’ì€ NLL (ì–´ë ¤ìš´ ìƒ˜í”Œ) â†’ ë‚®ì€ p â†’ ë†’ì€ weight (1-p)^Î³
- ë‚®ì€ NLL (ì‰¬ìš´ ìƒ˜í”Œ) â†’ ë†’ì€ p â†’ ë‚®ì€ weight

### Implementation
```python
def _compute_nll_loss(self, z, log_jac_det):
    B, H, W, D = z.shape

    if not self.use_focal_loss:
        # Standard NLL
        log_pz = -0.5 * (z ** 2).sum() / (B * H * W)
        log_jac = log_jac_det.mean() / (H * W)
        return -(log_pz + log_jac)
    else:
        # Per-patch NLL
        log_pz_per_patch = -0.5 * (z ** 2).sum(dim=-1)  # [B, H, W]
        log_jac_per_patch = log_jac_det.view(B, 1, 1) / (H * W)
        nll_per_patch = -(log_pz_per_patch + log_jac_per_patch)

        # Focal weighting
        prob = torch.exp(-nll_per_patch.clamp(max=20))
        focal_weight = (1 - prob).pow(self.focal_gamma)

        return (focal_weight * nll_per_patch).mean()
```

### Why This Should Work
1. **Hard Sample Mining**: Normal distribution ê²½ê³„ì— ìˆëŠ” ìƒ˜í”Œì— ì§‘ì¤‘
2. **Better Decision Boundary**: ì–´ë ¤ìš´ íŒ¨ì¹˜ë¥¼ ì˜ í•™ìŠµí•˜ë©´ anomaly êµ¬ë¶„ í–¥ìƒ
3. **Gradient Focus**: Easy sampleì€ gradient ê¸°ì—¬ ê°ì†Œ, hard sampleì— gradient ì§‘ì¤‘

### Command Line Arguments
```bash
python run_moleflow.py \
    --focal_gamma 2.0 \  # Focal loss gamma (recommend 1.0-2.0)
    ...
```

### Expected Improvements
- ë” sharpí•œ normal distribution ê²½ê³„ í•™ìŠµ
- íŠ¹íˆ Task 0ì—ì„œ base NF í’ˆì§ˆ í–¥ìƒ
- Anomaly detection ì„±ëŠ¥ ì „ë°˜ì  í–¥ìƒ

### v3 â†’ v7
| File | Changes |
|------|---------|
| `moleflow/trainer/continual_trainer.py` | `_compute_nll_loss()` helper method, focal weighting |
| `run_moleflow.py` | `--focal_gamma` argument |
| `run.sh` | v7 experiment configuration |

---

## Baseline 1.5 â†’ 2.0: Patch-wise Context Gate

### Motivation
**Baseline 1.5 (Global Alpha)ì˜ ë¬¸ì œì **:
- `alpha`ëŠ” global scalar â†’ ëª¨ë“  íŒ¨ì¹˜ì— ë™ì¼í•œ context ê°•ë„ ì ìš©
- í•™ìŠµ ì¤‘ **ì •ìƒ ë°ì´í„°ë§Œ** ë´„ â†’ anomaly-aware í•™ìŠµ ë¶ˆê°€ëŠ¥
- ê²°ê³¼: `alpha â‰ˆ ì´ˆê¸°ê°’`ìœ¼ë¡œ ê³ ì •, sigmoid boundê°€ ì˜ë¯¸ ì—†ìŒ

**í•µì‹¬ í†µì°°**:
> Global alphaëŠ” "knob"ì¼ ë¿ì´ê³ ,
> Anomaly detectionì—ì„œëŠ” "switch"ê°€ í•„ìš”í•˜ë‹¤.
> ê·¸ switchëŠ” **patch-wise gate**ë‹¤.

### Core Idea
| êµ¬ë¶„ | Baseline 1.5 (Global Alpha) | Baseline 2.0 (Patch-wise Gate) |
|------|----------------------------|-------------------------------|
| ìˆ˜ì‹ | `ctx = alpha * ctx` | `ctx = gate(x, ctx) * ctx` |
| ì°¨ì› | `alpha` âˆˆ â„ (scalar) | `gate` âˆˆ â„^(BÃ—HÃ—WÃ—1) (per-patch) |
| í•™ìŠµ | ëª¨ë“  íŒ¨ì¹˜ ë™ì¼ | íŒ¨ì¹˜ë³„ ë…ë¦½ ê²°ì • |
| ì •ìƒ íŒ¨ì¹˜ | Î± * ctx | gate â†’ 0 (context ë¬´ì‹œ) |
| ì´ìƒ íŒ¨ì¹˜ | Î± * ctx | gate â†’ 1 (context ì‚¬ìš©) |

### Code Changes

#### 1. MoLEContextSubnet (lora.py)

**Before (Baseline 1.5 - Global Alpha)**:
```python
class MoLEContextSubnet(nn.Module):
    def __init__(self, dims_in, dims_out, ...,
                 context_init_scale=0.1, context_max_alpha=0.2):
        # ...

        # Global alpha with sigmoid upper bound
        # alpha = alpha_max * sigmoid(alpha_param)
        p = min(max(context_init_scale / context_max_alpha, 0.01), 0.99)
        init_param = torch.log(torch.tensor([p / (1 - p)]))  # Inverse sigmoid
        self.context_scale_param = nn.Parameter(init_param)

    def forward(self, x):
        # ...
        ctx = self.context_conv(x_spatial)

        # Global alpha scaling (same for ALL patches)
        alpha = self.context_max_alpha * torch.sigmoid(self.context_scale_param)
        ctx = alpha * ctx  # (BHW, D) * scalar

        s_input = torch.cat([x, ctx], dim=-1)
        # ...
```

**After (Baseline 2.0 - Patch-wise Gate)**:
```python
class MoLEContextSubnet(nn.Module):
    def __init__(self, dims_in, dims_out, ...,
                 context_init_scale=0.1, context_max_alpha=0.2,
                 use_context_gate=False, context_gate_hidden=64):  # NEW
        # ...
        self.use_context_gate = use_context_gate

        if use_context_gate:
            # NEW: Patch-wise gate network
            # gate = sigmoid(MLP([x, ctx])) â†’ (BHW, 1)
            self.context_gate_net = nn.Sequential(
                nn.Linear(dims_in * 2, context_gate_hidden),
                nn.ReLU(),
                nn.Linear(context_gate_hidden, 1)
            )
            # Initialize to output ~0 â†’ gate starts at 0.5
            nn.init.zeros_(self.context_gate_net[0].weight)
            nn.init.zeros_(self.context_gate_net[0].bias)
            nn.init.zeros_(self.context_gate_net[2].weight)
            nn.init.zeros_(self.context_gate_net[2].bias)

            self.context_scale_param = None  # No global alpha
        else:
            # Legacy: Global alpha (Baseline 1.5)
            p = min(max(context_init_scale / context_max_alpha, 0.01), 0.99)
            init_param = torch.log(torch.tensor([p / (1 - p)]))
            self.context_scale_param = nn.Parameter(init_param)
            self.context_gate_net = None

    def forward(self, x):
        # ...
        ctx = self.context_conv(x_spatial)

        if self.use_context_gate and self.context_gate_net is not None:
            # NEW: Patch-wise gate (per-patch decision)
            gate_input = torch.cat([x, ctx], dim=-1)  # (BHW, 2D)
            gate_logit = self.context_gate_net(gate_input)  # (BHW, 1)
            gate = torch.sigmoid(gate_logit)  # (BHW, 1)

            self._last_gate = gate.detach()  # For logging
            ctx = gate * ctx  # (BHW, D) * (BHW, 1) â†’ per-patch scaling
        else:
            # Legacy: Global alpha
            alpha = self.context_max_alpha * torch.sigmoid(self.context_scale_param)
            ctx = alpha * ctx

        s_input = torch.cat([x, ctx], dim=-1)
        # ...

    # NEW: Logging utilities
    def get_context_alpha(self) -> float:
        """Get global alpha value (legacy mode)."""
        if self.context_scale_param is not None:
            with torch.no_grad():
                return (self.context_max_alpha
                        * torch.sigmoid(self.context_scale_param)).item()
        return None

    def get_last_gate_stats(self) -> dict:
        """Get gate statistics (patch-wise mode)."""
        if hasattr(self, '_last_gate') and self._last_gate is not None:
            gate = self._last_gate
            return {
                'mean': gate.mean().item(),
                'std': gate.std().item(),
                'min': gate.min().item(),
                'max': gate.max().item()
            }
        return None
```

#### 2. AblationConfig (ablation.py)

**Added**:
```python
@dataclass
class AblationConfig:
    # ... existing fields ...

    # Scale-specific Context (Baseline 1.5)
    use_scale_context: bool = False
    scale_context_kernel: int = 3
    scale_context_init_scale: float = 0.1
    scale_context_max_alpha: float = 0.2

    # NEW: Patch-wise Context Gate (Baseline 2.0)
    use_context_gate: bool = False    # Use patch-wise gate instead of global alpha
    context_gate_hidden: int = 64     # Hidden dim for gate MLP
```

#### 3. MoLESpatialAwareNF (mole_nf.py)

**Before**:
```python
subnet = MoLEContextSubnet(
    dims_in, dims_out,
    rank=self.lora_rank,
    alpha=self.lora_alpha,
    use_lora=self.use_lora,
    use_task_bias=self.use_task_bias,
    context_kernel=self.scale_context_kernel,
    context_init_scale=self.scale_context_init_scale,
    context_max_alpha=self.scale_context_max_alpha
)
```

**After**:
```python
subnet = MoLEContextSubnet(
    dims_in, dims_out,
    rank=self.lora_rank,
    alpha=self.lora_alpha,
    use_lora=self.use_lora,
    use_task_bias=self.use_task_bias,
    context_kernel=self.scale_context_kernel,
    context_init_scale=self.scale_context_init_scale,
    context_max_alpha=self.scale_context_max_alpha,
    use_context_gate=self.use_context_gate,      # NEW
    context_gate_hidden=self.context_gate_hidden  # NEW
)
```

**Added get_context_info() method**:
```python
def get_context_info(self) -> dict:
    """Get context gate/alpha information for logging."""
    if not self.use_scale_context:
        return {}

    info = {}
    if self.use_context_gate:
        # Aggregate gate stats from all subnets
        gate_stats = []
        for subnet in self.subnets:
            if hasattr(subnet, 'get_last_gate_stats'):
                stats = subnet.get_last_gate_stats()
                if stats is not None:
                    gate_stats.append(stats)

        if gate_stats:
            info['gate_mean'] = sum(s['mean'] for s in gate_stats) / len(gate_stats)
            info['gate_std'] = sum(s['std'] for s in gate_stats) / len(gate_stats)
            info['gate_min'] = min(s['min'] for s in gate_stats)
            info['gate_max'] = max(s['max'] for s in gate_stats)
    else:
        # Collect alpha from all subnets
        alphas = [s.get_context_alpha() for s in self.subnets
                  if hasattr(s, 'get_context_alpha')]
        alphas = [a for a in alphas if a is not None]
        if alphas:
            info['alpha_mean'] = sum(alphas) / len(alphas)

    return info
```

#### 4. Trainer Logging (continual_trainer.py)

**Added context logging per epoch**:
```python
# In _train_base_task, _train_fast_stage, _train_slow_stage:
avg_epoch_loss = epoch_loss / max(num_batches, 1)
current_lr = optimizer.param_groups[0]['lr']

# NEW: Get context gate/alpha info for logging
extra_info = {"LR": current_lr}
context_info = self.nf_model.get_context_info()
if context_info:
    extra_info.update(context_info)

if self.logger:
    self.logger.log_epoch(task_id, epoch, num_epochs, avg_epoch_loss,
                          stage="FAST", extra_info=extra_info)
else:
    ctx_str = ""
    if 'gate_mean' in context_info:
        ctx_str = f" | Gate: {context_info['gate_mean']:.4f}Â±{context_info['gate_std']:.4f}"
    elif 'alpha_mean' in context_info:
        ctx_str = f" | Alpha: {context_info['alpha_mean']:.4f}"
    print(f"  ğŸ“Š [FAST] Epoch [...] Average Loss: {avg_epoch_loss:.4f}{ctx_str}")
```

### Command Line Usage

```bash
# Baseline 1.5: Global Alpha (ê¸°ì¡´)
python run_moleflow.py \
    --use_scale_context \
    --scale_context_kernel 3 \
    --scale_context_init_scale 0.1 \
    --scale_context_max_alpha 0.2

# Baseline 2.0: Patch-wise Gate (NEW)
python run_moleflow.py \
    --use_scale_context \
    --use_context_gate \
    --context_gate_hidden 64
```

### Expected Improvements
- íŒ¨ì¹˜ë³„ë¡œ context ì‚¬ìš© ì—¬ë¶€ ê²°ì • â†’ anomaly ê²½ê³„ì—ì„œ ë” ì •ë°€í•œ detection
- Gate networkê°€ normal/anomaly íŒ¨ì¹˜ íŠ¹ì„± í•™ìŠµ
- ë” interpretableí•œ anomaly map ìƒì„± ê°€ëŠ¥

### Baseline 1.5 â†’ 2.0
| File | Changes |
|------|---------|
| `moleflow/models/lora.py` | `MoLEContextSubnet` - context_gate_net ì¶”ê°€ |
| `moleflow/config/ablation.py` | `use_context_gate`, `context_gate_hidden` ì„¤ì • ì¶”ê°€ |
| `moleflow/models/mole_nf.py` | context gate íŒŒë¼ë¯¸í„° ì „ë‹¬, `get_context_info()` ë©”ì„œë“œ |
| `moleflow/trainer/continual_trainer.py` | Context gate/alpha ë¡œê¹… ì¶”ê°€ |

---

## Version 3 - No-Replay Continual Learning Solutions

### Motivation
Version 2ì—ì„œ continual learning ì‹œ ì„±ëŠ¥ ì €í•˜ ë¬¸ì œê°€ ì—¬ì „íˆ ì¡´ì¬:
- Task 0 â†’ Task 1 â†’ Task 2 í•™ìŠµ ì‹œ ì´ì „ task ì„±ëŠ¥ ê°ì†Œ (Catastrophic Forgetting)
- ê¸°ì¡´ ë°©ë²•: Replay buffer ì‚¬ìš© â†’ ë©”ëª¨ë¦¬ ë¹„ìš©, í”„ë¼ì´ë²„ì‹œ ë¬¸ì œ

**ëª©í‘œ**: Replay ì—†ì´ continual learning ì„±ëŠ¥ í–¥ìƒ

### V3 New Modules Overview

| Module | ëª©ì  | ìœ„ì¹˜ |
|--------|------|------|
| **WhiteningAdapter** | Task-agnostic feature normalization | Feature â†’ NF ì „ |
| **LightweightMSContext** | Multi-scale receptive field í™•ì¥ | NF ì…ë ¥ ì „ |
| **DeepInvertibleAdapter (DIA)** | Task-specific nonlinear manifold adaptation | NF ì¶œë ¥ í›„ |
| **OrthogonalGradientProjection (OGP)** | Gradient projection to null space | Training loop |
| **TwoStageHybridRouter** | Prototype + Likelihood routing | Inference |

---

## V3-1: WhiteningAdapter

### Core Idea
Task ê°„ feature distribution shift ë¬¸ì œ í•´ê²°:
```
Task 0 features: mean=Î¼â‚€, cov=Î£â‚€
Task 1 features: mean=Î¼â‚, cov=Î£â‚  (ë‹¤ë¥¸ ë¶„í¬)
```

**Solution**: Whitening â†’ Constrained De-whitening
```
x â†’ Whiten(x) â†’ z (zero mean, unit variance)
z â†’ ConstrainedDewhiten(z) â†’ x' (controlled distribution)
```

### Implementation
```python
# moleflow/models/whitening_adapter.py
class WhiteningAdapter(nn.Module):
    """
    Whitening + Constrained De-whitening for distribution alignment.

    Forward: x â†’ whiten â†’ constrained de-whiten â†’ x'
    - Whitening uses running statistics (updated during training)
    - De-whitening uses learnable but constrained parameters
    """
    def __init__(self, channels, constraint_scale=0.1):
        # Running statistics for whitening
        self.register_buffer('running_mean', torch.zeros(channels))
        self.register_buffer('running_var', torch.ones(channels))

        # Constrained de-whitening parameters
        # Î³ âˆˆ [1-Î´, 1+Î´], Î² âˆˆ [-Î´, Î´]
        self.dewhiten_gamma = nn.Parameter(torch.ones(channels))
        self.dewhiten_beta = nn.Parameter(torch.zeros(channels))
        self.constraint_scale = constraint_scale

    def forward(self, x):
        # Whitening: (x - Î¼) / Ïƒ
        x_whitened = (x - self.running_mean) / (self.running_var.sqrt() + 1e-5)

        # Constrained de-whitening
        gamma = 1.0 + self.constraint_scale * torch.tanh(self.dewhiten_gamma - 1.0)
        beta = self.constraint_scale * torch.tanh(self.dewhiten_beta)

        return gamma * x_whitened + beta
```

### Key Design
1. **Running Statistics**: Taskë³„ ì—…ë°ì´íŠ¸, í˜„ì¬ taskì˜ ë¶„í¬ ë°˜ì˜
2. **Constrained Parameters**: tanhë¡œ ë²”ìœ„ ì œí•œ â†’ ì•ˆì •ì  í•™ìŠµ
3. **Per-Task Adapter**: ê° taskë§ˆë‹¤ ë³„ë„ WhiteningAdapter

### Command Line
```bash
python run_moleflow.py --use_whitening_adapter
```

---

## V3-2: LightweightMSContext (Multi-Scale Context)

### Core Idea
ê¸°ì¡´ NFëŠ” patch ë‹¨ìœ„ ë…ë¦½ ì²˜ë¦¬ â†’ ì£¼ë³€ context ë¬´ì‹œ

**Solution**: Multi-scale dilated convolutionìœ¼ë¡œ receptive field í™•ì¥
```
x â†’ [Conv_d1, Conv_d2, Conv_d4] â†’ concat â†’ fusion â†’ x + context
```

### Implementation
```python
# moleflow/models/ms_context.py
class LightweightMSContext(nn.Module):
    """
    Multi-scale context via dilated depthwise convolutions.

    Uses multiple dilation rates to capture context at different scales
    without significantly increasing parameters.
    """
    def __init__(self, channels, dilations=[1, 2, 4], kernel_size=3):
        self.dilated_convs = nn.ModuleList([
            nn.Conv2d(channels, channels, kernel_size,
                      padding=d*(kernel_size//2), dilation=d, groups=channels)
            for d in dilations
        ])
        self.fusion = nn.Conv2d(channels * len(dilations), channels, 1)
        self.gate = nn.Parameter(torch.zeros(1))  # Starts at 0.5 after sigmoid

    def forward(self, x):
        # x: (B, H, W, D) â†’ (B, D, H, W) for conv
        x_conv = x.permute(0, 3, 1, 2)

        # Multi-scale features
        ms_features = [conv(x_conv) for conv in self.dilated_convs]
        ms_concat = torch.cat(ms_features, dim=1)

        # Fusion and gating
        context = self.fusion(ms_concat).permute(0, 2, 3, 1)
        gate = torch.sigmoid(self.gate)

        return x + gate * context
```

### Key Design
1. **Depthwise Separable**: íŒŒë¼ë¯¸í„° íš¨ìœ¨ì 
2. **Multiple Dilations**: d=1,2,4ë¡œ ë‹¤ì–‘í•œ scale í¬ì°©
3. **Learnable Gate**: í•™ìŠµ ì´ˆê¸° ì•ˆì •ì„±

### Command Line
```bash
python run_moleflow.py --use_ms_context
```

### âš ï¸ Warning: WhiteningAdapter + MS-Context ì¶©ëŒ

ë‘ ëª¨ë“ˆì„ ë™ì‹œ ì‚¬ìš© ì‹œ í•™ìŠµ ë¶ˆì•ˆì • ë°œìƒ:
- Lossê°€ ìŒìˆ˜ë¡œ ë°œì‚°
- Task 0 ì„±ëŠ¥ ê¸‰ê²©íˆ ì €í•˜

**ì›ì¸**: ë‘ ëª¨ë“ˆ ëª¨ë‘ NF ì…ë ¥ ì „ì— featureë¥¼ ë³€í™˜í•˜ì—¬ distribution ì¶©ëŒ

**ìë™ í•´ê²°**: `AblationConfig`ì—ì„œ ìë™ìœ¼ë¡œ MS-Context ë¹„í™œì„±í™”
```python
# ablation.py __post_init__()
if self.use_whitening_adapter and self.use_ms_context:
    print("âš ï¸  Warning: use_whitening_adapter + use_ms_context ì¡°í•©ì€ í•™ìŠµ ë¶ˆì•ˆì •")
    self.use_ms_context = False
```

---

## V3-3: DeepInvertibleAdapter (DIA)

### Core Idea
Base NF ì¶œë ¥ í›„ task-specific nonlinear adaptation:
```
x â†’ Base NF â†’ z_base â†’ DIA_task â†’ z_final
```

**Why DIA?**
- LoRA: Linear adaptation (í‘œí˜„ë ¥ ì œí•œ)
- DIA: Invertible nonlinear adaptation (ë” ê°•ë ¥í•œ manifold adaptation)

### Implementation
```python
# moleflow/models/dia.py
class DeepInvertibleAdapter(nn.Module):
    """
    Task-specific mini normalizing flow after base NF.

    Provides nonlinear manifold adaptation while maintaining invertibility.
    """
    def __init__(self, channels, n_blocks=2, hidden_ratio=0.5):
        self.blocks = nn.ModuleList([
            InvertibleBlock(channels, hidden_ratio) for _ in range(n_blocks)
        ])

    def forward(self, z, reverse=False):
        logdet = 0
        blocks = reversed(self.blocks) if reverse else self.blocks

        for block in blocks:
            z, ld = block(z, reverse=reverse)
            logdet = logdet + ld

        return z, logdet

class InvertibleBlock(nn.Module):
    """Affine coupling block for DIA."""
    def __init__(self, channels, hidden_ratio=0.5):
        hidden_dim = int(channels * hidden_ratio)
        self.net = nn.Sequential(
            nn.Linear(channels // 2, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, channels)  # s and t
        )

    def forward(self, x, reverse=False):
        x1, x2 = x.chunk(2, dim=-1)
        st = self.net(x1)
        s, t = st.chunk(2, dim=-1)
        s = torch.tanh(s) * 0.5  # Bounded scale

        if not reverse:
            y2 = x2 * torch.exp(s) + t
            logdet = s.sum(dim=-1)
        else:
            y2 = (x2 - t) * torch.exp(-s)
            logdet = -s.sum(dim=-1)

        return torch.cat([x1, y2], dim=-1), logdet
```

### Integration in mole_nf.py
```python
class MoLESpatialAwareNF(nn.Module):
    def __init__(self, ...):
        # ...
        self.dia_adapters = nn.ModuleDict()  # Per-task DIA

    def add_task_adapter(self, task_id):
        if self.use_dia:
            self.dia_adapters[str(task_id)] = DeepInvertibleAdapter(
                self.c_in, self.dia_n_blocks, self.dia_hidden_ratio
            )

    def forward(self, x, reverse=False):
        # Base NF forward
        z, logdet = self.inn(x)

        # DIA forward
        if self.use_dia and self.current_task_id is not None:
            task_key = str(self.current_task_id)
            if task_key in self.dia_adapters:
                z, dia_logdet = self.dia_adapters[task_key](z, reverse=reverse)
                logdet = logdet + dia_logdet

        return z, logdet
```

### Command Line
```bash
python run_moleflow.py \
    --use_dia \
    --dia_n_blocks 2 \
    --dia_hidden_ratio 0.5
```

---

## V3-4: OrthogonalGradientProjection (OGP)

### Core Idea
ì´ì „ taskì—ì„œ ì¤‘ìš”í•œ gradient ë°©í–¥ì„ ë³´ì¡´:
```
âˆ‡L_new â†’ Project to null space of previous tasks â†’ âˆ‡L_projected
```

**Gradient Projection**:
```
g' = g - Î£áµ¢ (g Â· váµ¢) váµ¢
```
where váµ¢ = important directions from previous tasks

### Implementation
```python
# moleflow/models/ogp.py
class OrthogonalGradientProjection:
    """
    Projects gradients to the null space of important subspaces
    from previous tasks to prevent catastrophic forgetting.
    """
    def __init__(self, threshold=0.99, max_rank_per_task=50, device='cuda'):
        self.threshold = threshold
        self.max_rank = max_rank_per_task
        self.device = device
        self.projection_matrices = {}  # Per-parameter projection

    def compute_basis(self, model, dataloader, task_id):
        """Compute important gradient directions for current task."""
        gradients = self._collect_gradients(model, dataloader)

        for name, grads in gradients.items():
            # SVD to find important directions
            G = torch.stack(grads)  # (N, D)
            U, S, V = torch.svd(G)

            # Select top-k directions (explain threshold% variance)
            cumsum = torch.cumsum(S**2, 0) / (S**2).sum()
            k = (cumsum < self.threshold).sum() + 1
            k = min(k, self.max_rank)

            # Store projection matrix: I - V_k @ V_k.T
            V_k = V[:, :k]
            if name not in self.projection_matrices:
                self.projection_matrices[name] = V_k
            else:
                # Merge with existing basis
                combined = torch.cat([self.projection_matrices[name], V_k], dim=1)
                U_c, S_c, V_c = torch.svd(combined)
                self.projection_matrices[name] = V_c[:, :self.max_rank]

    def project_gradient(self, model):
        """Project current gradients to null space of stored basis."""
        for name, param in model.named_parameters():
            if param.grad is None or name not in self.projection_matrices:
                continue

            V = self.projection_matrices[name]
            g = param.grad.view(-1)

            # g' = g - V @ V.T @ g
            g_proj = g - V @ (V.T @ g)
            param.grad = g_proj.view(param.grad.shape)
```

### Integration in Trainer
```python
class MoLEContinualTrainer:
    def __init__(self, ...):
        if self.use_ogp:
            self.ogp = OrthogonalGradientProjection(
                threshold=self.ogp_threshold,
                max_rank_per_task=self.ogp_max_rank
            )

    def _train_fast_stage(self, task_id, ...):
        for batch in dataloader:
            loss.backward()

            # OGP: Project gradients
            if self.use_ogp and self.ogp.is_initialized:
                self.ogp.project_gradient(self.nf_model)

            optimizer.step()

    def _after_task_training(self, task_id, dataloader):
        # Compute OGP basis after task training
        if self.use_ogp:
            self.ogp.compute_basis(self.nf_model, dataloader, task_id)
```

### Command Line
```bash
python run_moleflow.py \
    --use_ogp \
    --ogp_threshold 0.99 \
    --ogp_max_rank 50
```

---

## V3-5: TwoStageHybridRouter

### Core Idea
ê¸°ì¡´ RouterëŠ” Prototype matchingë§Œ ì‚¬ìš© â†’ ìœ ì‚¬í•œ task êµ¬ë¶„ ì–´ë ¤ì›€

**Solution**: Two-stage routing
1. **Stage 1 (Fast)**: Prototype filtering â†’ Top-K candidates
2. **Stage 2 (Accurate)**: NF likelihood comparison â†’ Final selection

### Implementation
```python
# moleflow/models/routing.py
class TwoStageHybridRouter(nn.Module):
    """
    Two-stage routing: Prototype filtering + Likelihood refinement.

    Stage 1: Mahalanobis distance to prototypes â†’ Top-K candidates
    Stage 2: NF log-likelihood for final selection
    """
    def __init__(self, nf_model, top_k=2):
        self.prototype_router = PrototypeRouter()
        self.nf_model = nf_model
        self.top_k = top_k

    def forward(self, features):
        # Stage 1: Prototype distances
        distances = self.prototype_router.compute_distances(features)
        top_k_tasks = distances.argsort()[:self.top_k]

        # Stage 2: NF likelihood
        likelihoods = []
        for task_id in top_k_tasks:
            self.nf_model.set_task(task_id)
            z, logdet = self.nf_model(features)
            log_prob = -0.5 * (z**2).sum() + logdet
            likelihoods.append(log_prob)

        # Select task with highest likelihood
        best_idx = torch.stack(likelihoods).argmax()
        return top_k_tasks[best_idx]
```

### Command Line
```bash
python run_moleflow.py \
    --use_hybrid_router \
    --router_top_k 2
```

---

## V3 Experiment Results

### Ablation Study (leather â†’ grid â†’ transistor)

| Configuration | Image AUC | Pixel AUC | Notes |
|---------------|-----------|-----------|-------|
| **Baseline (V2)** | 0.8168 | 0.9166 | - |
| DIA only | 0.8217 | 0.9277 | +0.5% Image, +1.1% Pixel |
| OGP only | 0.8180 | 0.9161 | Minimal change |
| **DIA + OGP** | **0.8226** | **0.9231** | **Best combination** |
| WhiteningAdapter only | (ì‹¤í—˜ ì¤‘) | (ì‹¤í—˜ ì¤‘) | - |
| MS-Context only | (ì‹¤í—˜ ì¤‘) | (ì‹¤í—˜ ì¤‘) | - |
| All V3 (conflict) | 0.4471 | 0.5527 | âŒ ì‹¤íŒ¨ (ì¶©ëŒ) |

### Key Findings
1. **DIA + OGP**: Best performance without replay
2. **WhiteningAdapter + MS-Context**: ì¡°í•© ì‹œ ì¶©ëŒ â†’ ìë™ ë¹„í™œì„±í™” ì²˜ë¦¬
3. **DIA > OGP**: DIAê°€ ë” í° ì„±ëŠ¥ í–¥ìƒ ê¸°ì—¬

---

## V3 File Changes Summary

| File | Changes |
|------|---------|
| `moleflow/models/whitening_adapter.py` | NEW: WhiteningAdapter module |
| `moleflow/models/ms_context.py` | NEW: LightweightMSContext module |
| `moleflow/models/dia.py` | NEW: DeepInvertibleAdapter module |
| `moleflow/models/ogp.py` | NEW: OrthogonalGradientProjection |
| `moleflow/models/routing.py` | TwoStageHybridRouter ì¶”ê°€ |
| `moleflow/models/mole_nf.py` | DIA integration, V3 options |
| `moleflow/config/ablation.py` | V3 options: use_dia, use_ogp, use_whitening_adapter, use_ms_context |
| `moleflow/trainer/continual_trainer.py` | OGP integration |
| `run_moleflow.py` | V3 CLI arguments, config saving |
| `run_v3_experiments.sh` | V3 ablation experiment script |

---

## V3 Command Line Reference

```bash
# Full V3 with recommended settings (DIA + OGP)
python run_moleflow.py \
    --use_dia \
    --dia_n_blocks 2 \
    --use_ogp \
    --ogp_threshold 0.99 \
    --ogp_max_rank 50 \
    --experiment_name Version3-DIA_OGP

# WhiteningAdapter only
python run_moleflow.py \
    --use_whitening_adapter \
    --experiment_name Version3-WhiteningAdapter

# MS-Context only (automatically disabled if WhiteningAdapter is on)
python run_moleflow.py \
    --use_ms_context \
    --experiment_name Version3-MSContext

# All options with diagnostics
python run_moleflow.py \
    --run_diagnostics \
    --use_dia \
    --use_ogp \
    --use_whitening_adapter \
    --experiment_name Version3-All
```

---
