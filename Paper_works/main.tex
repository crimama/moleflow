\documentclass[preprint,12pt,authoryear,3p]{elsarticle}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{subfigure}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage[hang,flushmargin]{footmisc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{pifont}
\usepackage{lineno}
\usepackage{kotex}
\usepackage{tabularx} 
% \usepackage[colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage{siunitx}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\sisetup{
  detect-all,      % 폰트 패밀리·굵기 등을 감지
  tight-spacing,   % 불필요한 간격 자동 제거
}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

\journal{Computer Vision Image Understanding}

\begin{document}
\begin{frontmatter}

%% Title, authors and addresses

\title{Your Title Here}

% --- 저자 및 주소 수정 ---
\author[a]{Author Name\fnref{fn1}}
\ead{author@example.com}
\author[b]{Author Name\fnref{fn1}}
\ead{author@example.com}

\author[b]{Corresponding Author\corref{cor1}}
\ead{corresponding@example.com}

% 교신저자 표기
\cortext[cor1]{Corresponding author}
\fntext[fn1]{Equal Contribution}

% --- 주소 정의 수정 ---
\address[a]{Address 1}
\address[b]{Address 2}

\begin{abstract}

\end{abstract}

\begin{keyword}
Keywords here
\end{keyword}
\end{frontmatter}

% \linenumbers

%% main text
\section{Introduction}
\label{sec:introduction}

%=========================================================================================================
% 1.1 배경 및 문제 정의
%=========================================================================================================

산업 환경에서의 이상 탐지(Anomaly Detection)는 제조 공정의 품질 관리와 결함 검출에 필수적인 기술이다.
최근 딥러닝 기반 이상 탐지 방법론은 정상 데이터만을 사용하여 학습하는 단일 클래스 분류(One-Class Classification) 패러다임을 채택하며, 특히 Normalizing Flow~\cite{rezende2015variational}, PatchCore~\cite{roth2022patchcore}, 그리고 재구성 기반 방법들이 높은 성능을 보여주고 있다.

그러나 실제 산업 현장에서는 단일 제품이 아닌 \textbf{다양한 제품 클래스를 순차적으로 학습}해야 하는 상황이 빈번하게 발생한다:
\begin{itemize}
    \item \textbf{제조 라인의 확장}: 새로운 제품(예: 나사 $\rightarrow$ 캡슐 $\rightarrow$ 트랜지스터)이 생산 라인에 추가
    \item \textbf{데이터 프라이버시}: 이전 제품의 데이터를 저장하거나 재사용할 수 없는 규제 환경
    \item \textbf{메모리 제약}: 모든 제품의 데이터를 동시에 저장하고 학습하기 어려운 엣지 디바이스 환경
\end{itemize}

이러한 환경에서 기존 이상 탐지 모델은 \textbf{파멸적 망각(Catastrophic Forgetting)} 문제에 직면한다.
새로운 제품 클래스를 학습하면 이전에 학습한 제품들에 대한 탐지 성능이 급격히 하락하는 현상이다.
수식으로 표현하면, Task $t-1$까지 학습한 모델 $f_{\theta}$가 Task $t$를 학습한 후 $f_{\theta'}$가 되었을 때:
\begin{equation}
\label{eq:forgetting}
\text{Forgetting} = \frac{1}{t-1}\sum_{i=0}^{t-1} \left( \text{AUROC}_{f_\theta}(\mathcal{D}_i) - \text{AUROC}_{f_{\theta'}}(\mathcal{D}_i) \right) \gg 0
\end{equation}
여기서 $\mathcal{D}_i$는 Task $i$의 테스트 데이터셋이다.

%=========================================================================================================
% 1.2 기존 접근법의 한계
%=========================================================================================================

기존의 지속 학습(Continual Learning) 방법론들은 이 문제를 다양한 전략으로 해결하고자 한다:

\paragraph{정규화 기반 방법 (Regularization-based):}
\begin{itemize}
    \item EWC~\cite{kirkpatrick2017ewc}: 중요한 파라미터의 변화를 제한하는 Fisher Information 기반 정규화
    \item LwF~\cite{li2017lwf}: 이전 모델의 출력을 증류(Distillation)하여 지식 보존
    \item \textbf{한계점}: 작업 수 증가 시 정규화 항의 축적으로 새로운 작업 학습 능력 저하
\end{itemize}

\paragraph{리플레이 기반 방법 (Replay-based):}
\begin{itemize}
    \item 이전 작업의 데이터 일부를 메모리 버퍼에 저장하여 재학습에 활용
    \item \textbf{한계점}: 메모리 오버헤드, 데이터 프라이버시 문제, 버퍼 크기에 비례하는 성능
\end{itemize}

\paragraph{아키텍처 기반 방법 (Architecture-based):}
\begin{itemize}
    \item PackNet~\cite{mallya2018packnet}: 작업별로 네트워크의 일부를 할당하고 고정
    \item Progressive Networks~\cite{rusu2016progressive}: 새로운 작업마다 새로운 컬럼 추가
    \item \textbf{한계점}: 파라미터 효율성 저하, 작업 수에 따른 모델 크기 증가
\end{itemize}

특히 이상 탐지 도메인에서의 지속 학습은 추가적인 도전 과제를 가진다:
\begin{itemize}
    \item \textbf{추론 시 Task ID의 부재}: 기존 지속 학습 연구는 추론 시 Task ID가 주어진다고 가정하지만, 실제 산업 환경에서는 입력 이미지가 어떤 제품인지 사전에 알 수 없음
    \item \textbf{밀도 추정(Density Estimation)의 민감성}: Normalizing Flow 기반 방법은 정상 분포를 정밀하게 추정해야 하므로, 분포의 미세한 왜곡도 성능 저하로 이어짐
    \item \textbf{작업 간 분포 격차}: 서로 다른 제품(예: 가죽 vs. 나사)의 특징 분포가 크게 다름
\end{itemize}

%=========================================================================================================
% 1.3 제안 방법론의 핵심 아이디어
%=========================================================================================================

본 논문에서는 이러한 문제들을 해결하기 위해 \textbf{MoLE-Flow (Mixture of LoRA Experts for Normalizing Flow)}를 제안한다.
핵심 아이디어는 \textbf{Parameter Isolation}을 통한 완벽한 망각 방지와 \textbf{One-stage Task-agnostic 추론}이다.

\paragraph{핵심 통찰 1: 공유 Base + 분리된 Adapter}
\begin{itemize}
    \item Normalizing Flow의 기본 가중치(Base)는 첫 번째 작업(Task 0)에서 학습 후 \textbf{완전히 동결}
    \item 이후 작업들은 경량 어댑터(LoRA, WhiteningAdapter, DIA)만 학습
    \item 작업별 어댑터가 완전히 분리되어 있으므로 작업 간 간섭이 \textbf{원천적으로 차단}
\end{itemize}

\paragraph{핵심 통찰 2: 프로토타입 기반 원스테이지 라우팅}
\begin{itemize}
    \item 학습 중 각 작업의 특징 분포 통계(평균, 공분산)를 프로토타입으로 저장
    \item 추론 시 입력 이미지와 각 프로토타입 간 Mahalanobis 거리를 계산
    \item 가장 가까운 프로토타입의 작업에 해당하는 어댑터를 활성화
    \item \textbf{별도의 Task ID 예측 단계 없이} 단일 추론으로 라우팅과 이상 탐지를 동시 수행
\end{itemize}

\paragraph{핵심 통찰 3: 비선형 매니폴드 적응 (DIA)}
\begin{itemize}
    \item 선형 LoRA는 저차원 부분공간에서의 적응만 가능하여 복잡한 분포 차이를 표현하기 어려움
    \item Deep Invertible Adapter (DIA)는 가역적 비선형 변환을 통해 작업별 매니폴드를 정밀하게 보정
    \item Normalizing Flow의 밀도 추정 속성을 보존하면서 작업 특화 적응 달성
\end{itemize}

%=========================================================================================================
% 1.4 기여점 요약
%=========================================================================================================

본 논문의 주요 기여는 다음과 같다:

\begin{enumerate}
    \item \textbf{MoLE-Flow 프레임워크 제안}: Normalizing Flow에 LoRA를 적용하여 Parameter Isolation 기반의 지속 학습 이상 탐지 프레임워크를 설계하였다. 이는 망각을 \textbf{원천적으로 차단}하면서 작업당 약 2M의 경량 파라미터만 추가한다.

    \item \textbf{Deep Invertible Adapter (DIA)}: 선형 LoRA의 표현력 한계를 극복하는 비선형 가역 어댑터를 제안하였다. DIA는 작업별 복잡한 매니폴드 차이를 보정하며, 실험에서 가장 중요한 구성 요소로 확인되었다.

    \item \textbf{WhiteningAdapter를 통한 분포 정렬}: 작업 간 입력 분포 격차를 해소하기 위해 Whitening 후 Task-specific De-whitening을 수행하는 어댑터를 설계하였다. 이는 고정된 Base Flow가 다양한 작업을 효과적으로 처리할 수 있게 한다.

    \item \textbf{One-stage Task-agnostic 추론}: Mahalanobis 거리 기반 프로토타입 라우터를 통해 추론 시 Task ID 없이 단일 패스로 라우팅과 이상 탐지를 수행한다. 기존 방법의 two-stage 추론 대비 효율적이며, 100\% 라우팅 정확도를 달성하였다.

    \item \textbf{종합적인 실험 검증}: MVTec AD 데이터셋에서 기존 방법 대비 우수한 성능을 달성하였으며 (Image AUROC 98.05\%, Routing Accuracy 100\%), 체계적인 Ablation Study를 통해 각 구성 요소의 유효성을 검증하였다.
\end{enumerate}

%=========================================================================================================
% 1.5 논문 구성
%=========================================================================================================

본 논문의 구성은 다음과 같다.
Section~\ref{sec:related_work}에서는 관련 연구를 검토하고, Section~\ref{sec:method}에서는 제안하는 MoLE-Flow 프레임워크를 상세히 기술한다.
Section~\ref{sec:experiments}에서는 실험 설정과 결과를 제시하고, 마지막으로 Section~\ref{sec:conclusion}에서 결론 및 향후 연구 방향을 논의한다.

%=========================================================================================================
\section{Related Work}
\label{sec:related_work}
%=========================================================================================================

\subsection{Anomaly Detection}
\label{sec:related_ad}

산업 이상 탐지는 정상 샘플만으로 학습하여 비정상 샘플을 탐지하는 단일 클래스 분류 문제로 정의된다.
기존 방법론은 크게 재구성 기반, 특징 임베딩 기반, 그리고 밀도 추정 기반으로 분류된다.

\subsubsection{재구성 기반 방법 (Reconstruction-based)}
\begin{itemize}
    \item \textbf{기본 아이디어}: 정상 샘플만으로 오토인코더를 학습하면, 비정상 샘플은 재구성 오류가 크다는 가정
    \item \textbf{대표 방법론}:
    \begin{itemize}
        \item AutoEncoder~\cite{sakurada2014anomaly}: 표준 오토인코더 구조를 이상 탐지에 적용
        \item VAE~\cite{an2015variational}: 잠재 공간에 정규 분포 제약을 추가한 변분 오토인코더
        \item MemAE~\cite{gong2019memorizing}: 메모리 뱅크를 활용하여 비정상 샘플의 재구성을 방지
    \end{itemize}
    \item \textbf{한계점}:
    \begin{itemize}
        \item 복잡한 이상 패턴도 재구성할 수 있는 ``과도한 일반화(Over-generalization)'' 문제
        \item 픽셀 수준의 재구성 오류가 미세한 구조적 결함을 포착하지 못함
    \end{itemize}
\end{itemize}

\subsubsection{특징 임베딩 기반 방법 (Feature Embedding-based)}
\begin{itemize}
    \item \textbf{기본 아이디어}: 사전 학습된 CNN/ViT의 풍부한 특징 공간에서 정상 샘플의 분포를 모델링
    \item \textbf{대표 방법론}:
    \begin{itemize}
        \item SPADE~\cite{cohen2020spade}: K-NN 기반 정상 특징과의 거리를 이상 점수로 사용
        \item PaDiM~\cite{defard2021padim}: 위치별 다변량 가우시안으로 정상 분포 모델링
        \item PatchCore~\cite{roth2022patchcore}: 코어셋 서브샘플링으로 효율적인 메모리 뱅크 구축
    \end{itemize}
    \item \textbf{한계점}: 메모리 뱅크 크기에 따른 추론 시간 증가, K-NN 검색의 계산 복잡도
\end{itemize}

\subsubsection{밀도 추정 기반 방법 (Density Estimation-based)}
\begin{itemize}
    \item \textbf{기본 아이디어}: 정상 샘플의 확률 밀도 $p(\mathbf{x})$를 명시적으로 추정하고, 저밀도 영역을 이상으로 판단
    \item \textbf{대표 방법론}:
    \begin{itemize}
        \item DifferNet~\cite{rudolph2021differnet}: Normalizing Flow를 이상 탐지에 최초 적용
        \item CFLOW-AD~\cite{gudovskiy2022cflow}: 조건부 Normalizing Flow로 위치별 밀도 추정
        \item FastFlow~\cite{yu2021fastflow}: 효율적인 Flow 구조로 추론 속도 개선
    \end{itemize}
    \item \textbf{장점}: 확률적 해석 가능, 메모리 뱅크 불필요로 확장성 우수
    \item \textbf{한계점}: 지속 학습 환경에서의 망각 문제 미해결
\end{itemize}

본 연구는 \textbf{밀도 추정 기반 방법}을 기반으로 하되, 지속 학습 환경에서의 망각 문제를 LoRA와 DIA를 통해 해결한다.

%=========================================================================================================
\subsection{Continual Learning}
\label{sec:related_cl}

지속 학습(Continual Learning)은 순차적으로 도착하는 작업들을 이전 지식을 유지하면서 학습하는 문제이다.

\subsubsection{정규화 기반 방법 (Regularization-based)}
\begin{itemize}
    \item \textbf{핵심 아이디어}: 이전 작업에 중요한 파라미터의 변화를 제한하는 정규화 항 추가
    \item \textbf{대표 방법론}:
    \begin{itemize}
        \item EWC (Elastic Weight Consolidation)~\cite{kirkpatrick2017ewc}: Fisher Information 기반 정규화
        \item LwF (Learning without Forgetting)~\cite{li2017lwf}: Knowledge Distillation으로 이전 출력 보존
    \end{itemize}
    \item \textbf{한계점}: 작업 수 증가 시 새로운 작업 학습 능력 감소
\end{itemize}

\subsubsection{리플레이 기반 방법 (Replay-based)}
\begin{itemize}
    \item \textbf{핵심 아이디어}: 이전 작업의 데이터를 일부 저장하여 새로운 작업 학습 시 함께 학습
    \item \textbf{대표 방법론}: Experience Replay, iCaRL~\cite{rebuffi2017icarl}, GEM~\cite{lopez2017gem}
    \item \textbf{한계점}: 메모리 버퍼 크기에 비례하는 저장 비용, 데이터 프라이버시 문제
\end{itemize}

\subsubsection{아키텍처 기반 방법 (Architecture-based)}
\begin{itemize}
    \item \textbf{핵심 아이디어}: 작업별로 네트워크 구조를 분리하거나 확장
    \item \textbf{대표 방법론}: Progressive Networks~\cite{rusu2016progressive}, PackNet~\cite{mallya2018packnet}
    \item \textbf{장점}: Parameter Isolation으로 \textbf{망각 완전 방지}
    \item \textbf{한계점}: 작업 수에 비례하여 모델 크기 증가, 추론 시 Task ID 필요
\end{itemize}

\subsubsection{Parameter-Efficient Fine-Tuning (PEFT)}
\begin{itemize}
    \item \textbf{핵심 아이디어}: 대규모 사전 학습 모델을 소수의 파라미터만 수정하여 새로운 작업에 적응
    \item \textbf{LoRA (Low-Rank Adaptation)}~\cite{hu2022lora}: 가중치 변화를 저랭크 행렬로 분해
    \begin{equation}
        \mathbf{W}' = \mathbf{W} + \Delta\mathbf{W} = \mathbf{W} + \frac{\alpha}{r}\mathbf{B}\mathbf{A}
    \end{equation}
    여기서 $\mathbf{A} \in \mathbb{R}^{r \times d_{in}}$, $\mathbf{B} \in \mathbb{R}^{d_{out} \times r}$, $r \ll \min(d_{in}, d_{out})$
    \item 본 연구는 \textbf{LoRA를 Normalizing Flow에 적용}하여 지속 학습 이상 탐지를 구현
\end{itemize}

%=========================================================================================================
\subsection{Normalizing Flows for Anomaly Detection}
\label{sec:related_nf}

Normalizing Flow~\cite{rezende2015variational}는 가역 변환을 통해 복잡한 분포를 간단한 기저 분포로 매핑하는 생성 모델이다.

\begin{itemize}
    \item \textbf{변수 변환 공식}: 가역 함수 $f: \mathbb{R}^d \rightarrow \mathbb{R}^d$에 대해
    \begin{equation}
        p_X(\mathbf{x}) = p_Z(f(\mathbf{x})) \left| \det \frac{\partial f}{\partial \mathbf{x}} \right|
    \end{equation}
    \item \textbf{이상 탐지 적용}: 정상 데이터의 밀도를 학습하고, 저밀도 영역을 이상으로 판단
    \item \textbf{대표 방법론}: DifferNet, CFLOW-AD, FastFlow, CsFlow
\end{itemize}

본 연구는 Normalizing Flow의 \textbf{지속 학습 한계}를 LoRA와 DIA를 통한 Parameter Isolation으로 해결한다.

%=========================================================================================================
\subsection{Mixture of Experts (MoE)}
\label{sec:related_moe}

Mixture of Experts~\cite{jacobs1991adaptive}는 다수의 전문가 네트워크와 게이팅 네트워크로 구성되어, 입력에 따라 적합한 전문가를 선택하는 구조이다.

\begin{itemize}
    \item \textbf{기본 구조}: $y = \sum_{i=1}^{N} g_i(\mathbf{x}) \cdot E_i(\mathbf{x})$
    \item 본 연구의 \textbf{MoLE (Mixture of LoRA Experts)}는 MoE의 개념을 계승하되, 전문가를 \textbf{경량 LoRA 어댑터}로 구현
    \item 게이팅은 \textbf{프로토타입 기반 Mahalanobis 거리}를 사용하여 추가 학습 없이 작업을 선택
\end{itemize}

\section{Proposed Method}
\label{sec:method}
\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{figures/main2.png}
    \caption{Overview of the proposed \textbf{MoLE-Flow} framework for continual anomaly detection on industrial images. Given sequential tasks, the base normalizing flow backbone is learned on the first task and then frozen. For each new task, only lightweight task-specific adapters (WhiteningAdapter, LoRA, DIA) are trained. At inference time, the prototype-based Mahalanobis router assigns each sample to the most relevant expert without requiring task ID.}
    \label{fig:main_figure}
\end{figure}

본 섹션에서는 Continual learning scenario 환경에서 anomaly detection을 수행하기 위한 방법인 MoLE-Flow(Mixture of LoRA Experts with Normalizing Flow for Continual Anomaly Detection) 프레임워크를 제안한다.
MoLE-Flow는 크게 특징 추출기, MoLE 기반 Normalizing Flow, 작업별 어댑터, 그리고 프로토타입 라우터로 구성되며, 다음 다섯 가지 핵심 기여를 제안한다:
\begin{enumerate}
\item \textbf{MoLE (Mixture of LoRA Experts)}: Normalizing Flow의 coupling 블록에 LoRA를 적용하여 작업별 경량 적응을 가능하게 하는 MoLEContextSubnet 구조
\item \textbf{WhiteningAdapter}: 작업 간 특징 분포 차이를 정렬하기 위한 whitening 후 제약된 de-whitening 기반 적응 모듈
\item \textbf{Deep Invertible Adapter (DIA)}: 선형 LoRA의 한계를 극복하는 비선형 가역 적응 모듈
\end{enumerate}

\subsection{Overall Architecture}
\label{sec:overview}

MoLE-Flow는 사전 학습된 Backbone을 통해 이미지의 패치 임베딩을 추출한 후, Normalizing Flow를 통해 잠재 공간의 가우시안 분포로 매핑하는 구조를 가진다.
지속 학습 환경에 대응하기 위한 핵심 전략은 \textbf{Parameter Isolation}으로, Backbone과 Base NF의 파라미터는 공유하거나 고정하면서, 작업 특화 특징은 LoRA(Low-Rank Adaptation)와 DIA(Deep Invertible Adapter)에만 저장함으로써 메모리 효율성과 작업 간 간섭 방지를 동시에 달성한다.
전체 파이프라인은 다음과 같다:
\begin{enumerate}
\item Backbone으로부터 특징 추출 및 패치 임베딩 생성
\item Positional Encoding 생성 후 패치 임베딩에 추가
\item Task Adapters (Whitening)를 통한 작업 특화 특징 보존
\item Spatial Context Mixer를 통한 주변 문맥 정보 혼합
\item Normalizing Flow를 통한 확률 분포 추정
\item Likelihood 계산
\end{enumerate}

수식으로 표현하면:
\begin{equation}
\label{eq:pipeline}
\mathbf{x} \xrightarrow{\text{Backbone}} \mathbf{F} \xrightarrow{\text{PE}} \mathbf{F}' \xrightarrow{\text{Whitening}} \hat{\mathbf{F}} \xrightarrow{\text{SCM}} \tilde{\mathbf{F}} \xrightarrow{\text{NF+LoRA}} \mathbf{z}' \xrightarrow{\text{DIA}} (\mathbf{z}, \log|\det \mathbf{J}|)
\end{equation}

\paragraph{Notation.}
본 논문에서 사용하는 주요 표기법은 다음과 같다:
$\mathbf{X} \in \mathbb{R}^{B \times H \times W \times D}$는 배치 크기 $B$, 공간 해상도 $H \times W$, 특징 차원 $D$를 가지는 패치 임베딩 텐서를 나타낸다.
$\mathbf{x}_{u,v} \in \mathbb{R}^D$는 위치 $(u,v)$의 개별 패치 벡터이다.
$t \in \{0, 1, \ldots, T-1\}$는 작업 인덱스를 나타내며, $\mathbf{J}_f$는 함수 $f$의 Jacobian 행렬이다.
$\lambda_{\text{tail}}$은 Tail-Aware Loss의 가중치, $\lambda_{\text{reg}}$는 공분산 정규화 항을 나타낸다.

첫 번째 작업(Task 0)에서 Base와 작업 특화 Normalizing Flow 요소(LoRA, Whitening Adapter, DIA)를 모두 학습한 후, Base 파라미터는 동결된다.

\subsection{Feature Extraction \& Preprocessing}
\label{sec:feature_extraction}

입력 이미지의 특징을 추출하고 각 작업별 전문가를 학습시키기 위한 입력으로 사용하기 위해 다음과 같은 전처리를 수행한다.

\subsubsection{Feature Extractor \& Patch Embedding}
\begin{itemize}
    \item 사전 학습된 Feature Extractor를 통해 특징을 추출한다.
    \item 이때 intermediate layer의 출력을 활용하여 다중 스케일 정보(multi-scale information)를 얻는다.
    \item PatchCore와 유사하게 입력 이미지의 지역적 특성을 추출한다.
    \item 추출된 특징 맵을 패치 단위로 분할한 뒤 풀링 과정을 거쳐 패치 임베딩을 생성한다.
    \item 최종적으로 $\mathbf{F} \in \mathbb{R}^{B \times H \times W \times D}$ 형태의 패치 임베딩을 얻으며, 여기서 $H \times W$는 패치 그리드 크기, $D$는 특징 차원이다.
\end{itemize}

\subsubsection{Positional Encoding}
\begin{itemize}
    \item Normalizing Flow는 permutation invariance 특성을 갖기 때문에, 2차원 구조가 아닌 patch embedding 각각이 독립적으로 처리된다.
    \item 각 패치의 공간적 위치 정보를 보존하기 위해 2D sinusoidal positional encoding $\mathbf{P}$를 패치 임베딩에 더한다.
    \item 수식으로 표현하면 다음과 같다:
\begin{equation}
\mathbf{F}' = \mathbf{F} + \mathbf{P}, \quad \mathbf{P} \in \mathbb{R}^{H \times W \times D}
\end{equation}
\end{itemize}

%=========================================================================================================
\subsection{Whitening Adapter}
%=========================================================================================================

\label{sec:adapters}
\begin{itemize}
\item MoLE-Flow는 첫 번째 작업 학습 이후 Base Flow의 파라미터를 동결(Freeze)
\item 이는 모델이 초기 학습 데이터의 분포 통계량에 피팅됨을 의미
\item 새로운 작업의 입력 분포가 이와 크게 다를 경우(Covariate Shift), 다음과 같은 문제 발생:
    \begin{itemize}
    \item 고정된 Base Network의 가중치는 최적의 활성화를 일으키지 못함
    \item 제한된 용량(Low-Rank)을 가진 LoRA가 전역적인 분포 차이까지 보정해야 하는 과도한 부담
    \item 학습 초기 수렴 지연 및 최적화 난이도 증가
    \end{itemize}
\item Whitening Adapter 도입을 통해 이를 해결하고자 함:
    \begin{itemize}
    \item 입력 데이터를 강제로 표준 정규 분포로 정렬(Alignment)
    \item 고정된 Base Flow가 항상 일관된 스케일의 입력을 처리하도록 보장
    \item LoRA가 분포 보정이 아닌 작업 고유의 미세 특징 학습에만 집중 가능
    \item 파라미터 분리 구조 하에서 학습 효율성과 안정성 극대화
    \end{itemize}
\end{itemize}

\textbf{Whitening Adapter는 Whitening과 De-whitening의 두 단계로 구성됨.}

\subsubsection{\textbf{Task-Agnostic Whitening}} 
\begin{itemize}
\item 입력 특징 $\mathbf{F}'$에 대해 학습 파라미터가 없는 LayerNorm 적용
\item 평균 0, 분산 1의 표준 정규 분포로 변환:
\begin{equation}
\mathbf{x}_{\text{white}} = \text{LayerNorm}(\mathbf{F}', \text{elementwise\_affine}=\text{False}) = \frac{\mathbf{F}' - \mathbb{E}[\mathbf{F}']}{\sqrt{\text{Var}[\mathbf{F}'] + \epsilon}}
\end{equation}
\item Task 0 이후 Base Flow는 동결되므로, 새로운 작업의 입력 분포가 달라지면 모델이 제대로 반응하지 못함
\item 새로운 작업의 데이터가 들어와도 강제 정규화를 통해 입력을 표준화하여 분포의 스케일 차이를 미리 제거
\item Normalizing Flow의 최적화 난이도를 낮추고 학습 안정성 확보
\item 모든 데이터를 표준 정규 분포로 정규화한 후, De-whitening을 통해 Base Flow의 최적 동작 범위 내로 재조정
\end{itemize}

\subsubsection{\textbf{Task-Specific De-whitening}} 
\begin{itemize}
\item Whitening으로 제거된 통계적 특성에 \textbf{해당 작업을 가장 잘 표현할 수 있는 최적의 통계적 특성을 다시 부여}
\item 단순 복원이 아닌, \textbf{고정된 Base Flow가 처리하기 가장 효율적인 형태로 데이터를 재조정(Recalibration)}
\item 정규화된 특징 $\mathbf{x}_{\text{white}}$에 대해 작업별 학습 가능한 파라미터 $\gamma_t$(스케일)와 $\beta_t$(이동)를 적용한 아핀 변환:
\begin{align}
\gamma_t &= 0.5 + 1.5 \cdot \sigma(\gamma_{\text{raw}}) \\
\beta_t &= 2.0 \cdot \tanh(\beta_{\text{raw}}) \\
\hat{\mathbf{F}}_t &= \gamma_t \odot \mathbf{x}_{\text{white}} + \beta_t
\end{align}
여기서 $\sigma(\cdot)$는 시그모이드 함수

\item De-whitening 단계에서 작업별 학습 파라미터를 통해 각 작업의 고유한 특성을 복원
\item 단순한 원래 분포의 복원이 아니라, \textbf{고정된 모델의 매니폴드(Manifold) 상에서 각 작업 데이터가 가장 잘 표현될 수 있도록 최적의 통계적 위치를 학습하는 과정}
\item 모든 작업에서 모든 특징 채널이 동등하게 중요한 것은 아니므로, $\gamma_t$는 채널별로 특징의 중요도를 조절:
    \begin{itemize}
    \item $\gamma_t$ 값 증가 $\rightarrow$ 해당 특징 증폭, Flow 모델이 더 민감하게 반응
    \item $\gamma_t$ 값 감소 $\rightarrow$ 해당 특징 억제, 노이즈로 간주
    \item 예시: '가죽' 작업에서는 미세한 질감(Texture) 채널의 $\gamma_t$ 증가, '나사' 작업에서는 전체적인 형태(Shape) 채널의 $\gamma_t$ 증가
    \end{itemize}
\end{itemize}

\paragraph{아핀 변환을 사용하는 이유:}
De-whitening에서 아핀 변환(Affine Transformation, $\mathbf{y} = \gamma \odot \mathbf{x} + \beta$)을 사용하는 이유는 \textbf{통계적 특성(평균, 분산)만 정확하게 조절하고, 데이터가 가진 본질적인 구조(Shape/Pattern)는 훼손하지 않기 위해서}이다.

\begin{itemize}
\item \textbf{통계적 정합성 (Statistical Consistency):} 
    \begin{itemize}
    \item 정규 분포를 다른 정규 분포로 변환하는 가장 자연스러운 방법은 아핀 변환이다.
    \item Whitening은 데이터를 표준 정규 분포 $\mathcal{N}(0, 1)$로 만들고, De-whitening은 이를 작업별 고유 분포 $\mathcal{N}(\mu_t, \sigma_t^2)$로 이동시킨다.
    \item 비선형 변환(예: $x^2$, $\exp(x)$)을 사용하면 분포의 모양 자체가 왜곡되어 정규 분포의 성질(Bell curve)을 잃어버리며, 이는 가우시안 기반 Normalizing Flow의 처리를 어렵게 만든다.
    \end{itemize}

\item \textbf{구조 보존 (Structure Preservation):}
    \begin{itemize}
    \item 아핀 변환은 공간을 늘리거나(Scale), 이동(Shift)만 하므로 \textbf{직선은 직선으로 남고, 평행선은 평행하게 유지}된다.
    \item 이미지 패치 내부의 픽셀 관계는 물체의 형상을 나타내므로, 아핀 변환은 이미지가 조금 밝아지거나 대비가 강해질 뿐 "고양이"가 "강아지"처럼 보이게 모양이 바뀌지 않는다.
    \item 반면 비선형 변환은 공간을 구부리거나 비틀어 직선이 곡선이 되고 모양이 뒤틀리므로, \textbf{데이터의 내용(Content) 자체를 변질}시킬 위험이 있다.
    \item Adapter의 역할은 "입력의 톤(Tone)을 맞추는 것"이지, "내용을 재창조하는 것"이 아니므로 형태를 보존하는 아핀 변환이 최적이다.
    \end{itemize}

\item \textbf{역할 분담 (Division of Labor):}
    \begin{itemize}
    \item MoLE-Flow 전체 구조에서 Adapter는 서로 다른 도메인(가죽, 나사)의 \textbf{시작점(Start Point)을 맞춰주는 역할}로, 가장 기초적인 1차 모멘트(평균)와 2차 모멘트(분산)만 빠르고 정확하게 맞추면 된다.
    \item 실제 데이터의 복잡하고 비선형적인 분포 모델링은 Base Flow와 LoRA가 담당한다.
    \item Adapter가 굳이 복잡한 비선형 변환을 수행하여 연산량을 늘리고 최적화를 어렵게 만들 필요가 없으며, 이는 Batch Normalization~\cite{ioffe2015batchnorm}이 학습 가능한 파라미터 $\gamma$, $\beta$를 두어 표현력을 복원하는 원리와 동일하다.
    \item 또한, 본 접근법은 FiLM(Feature-wise Linear Modulation)~\cite{perez2018film}의 조건부 아핀 변환과 개념적으로 연결되며, 이를 지속 학습 환경의 도메인 적응에 특화시킨 것으로 볼 수 있다.
    \end{itemize}
\end{itemize}

결론적으로, Affine transformation은 \textbf{데이터의 본질은 건드리지 않으면서, 모델이 편식하지 않게 통계적 특성만 맞춰주는 가장 안전하고 효율적인 방법}이다.

\noindent 결과적으로 Whitening Adapter는:
\begin{itemize}
\item Whitening을 통해 불필요한 분포 격차를 제거
\item De-whitening을 통해 필요한 작업 고유의 특성을 학습된 형태로 복원
\item 입력 데이터의 글로벌한 표준화와 작업별 최적화를 동시에 달성
\item Base Flow는 Task 0의 데이터 분포에 최적화되어 고정되어 있으므로, 새로운 작업의 데이터가 "Task 0의 매니폴드 영역"과 동떨어져 있으면 Base Flow의 활성 함수들이 제대로 작동하지 않음
\item De-whitening은 $\gamma_t$와 $\beta_t$를 조절하여 정규화된 데이터를 Base Flow가 학습했던 익숙한 영역 근처로 매핑하고, 새로운 데이터가 Base Flow의 활성 함수들이 가장 잘 작동하는 구간(Active Region)에 위치하도록 보장
\item 고정된 Base Flow의 효과적인 재활용을 가능하게 하며, 지속 학습 환경에서 안정적이고 효율적인 학습을 보장
\end{itemize}

%=========================================================================================================
\subsection{\textbf{Spatial Context Mixer}}
%=========================================================================================================
\label{sec:spatial_mixer}
\begin{itemize}
    \item Normalizing Flow는 입력으로 이미지로 부터 생성된 각 Patch embedding들을 독립적으로 처리하여 우도를 계산하고 이를 통해 분포를 학습한다.    
\end{itemize}
\begin{equation}
    p(\mathbf{X}) \approx \prod_{u=1}^{H} \prod_{v=1}^{W} p(\mathbf{x}_{u,v})
\end{equation}
\begin{itemize}
    \item 이러한 Normalizing Flow의 구조상 위치 $(u, v)$의 특징 벡터 $\mathbf{x}_{u,v}$를 인접한 이웃들과 독립적(Independent and Identically Distributed, i.i.d.)으로 처리한다.
    \item 이러한 독립적 처리는 \textbf{구조적 사각지대(Structural Blind Spot)}를 야기한다.
    \begin{itemize}
        \item \textbf{공간적 상관관계의 누락:} 긁힘(Scratch)이나 얼룩(Stain)과 같은 미세 결함은 단일 패치 내부의 값보다는 주변 패치와의 \textbf{불연속성(Discontinuity)}으로 정의된다. 그러나 Normalizing Flow는 패치를 독립적으로 처리하므로 이러한 국소적 대조(Local Contrast)를 인지하지 못한다.
        \item \textbf{문맥 정보의 부재:} 정상 데이터의 분포는 주변 문맥에 따라 달라질 수 있다. 독립적인 처리는 $p(\mathbf{x}_{u,v} | \text{Neighbors})$와 같은 조건부 확률을 모델링할 수 없다.
    \end{itemize}
\end{itemize}

\paragraph{\textbf{Mechanism: Gated Depthwise Aggregation}}
\begin{itemize}
    \item 이러한 한계를 극복하기 위해 Normalizing Flow 입력 직전에 \textbf{Spatial Context Mixer}를 도입
    \item 이 모듈은 파라미터 효율성을 극대화하면서, 각 패치가 주변 정보를 물리적으로 집계할 수 있도록 설계
\end{itemize}

\begin{itemize}
    \item \textbf{Spatial Aggregation (Depthwise Convolution):}
    \begin{itemize}
        \item Mixer는 채널 간의 간섭 없이 오직 공간적 정보만을 통합하기 위해 \textbf{Depthwise Convolution}~\cite{howard2017mobilenets}을 사용한다.
        \begin{equation}
            \mathbf{C}^{(c)}_{u,v} = \sum_{i=-\lfloor K/2 \rfloor}^{\lfloor K/2 \rfloor} \sum_{j=-\lfloor K/2 \rfloor}^{\lfloor K/2 \rfloor} \mathbf{W}^{(c)}_{i,j} \cdot \mathbf{x}^{(c)}_{u+i, v+j}
        \end{equation}
        \item 여기서 $K$는 커널 크기(홀수, 기본값 3), $c$는 채널 인덱스, $\mathbf{x}^{(c)}$는 $c$번째 채널의 입력 특징 맵, $\mathbf{W}^{(c)} \in \mathbb{R}^{K \times K}$는 해당 채널의 커널 가중치, $\mathbf{C}$는 추출된 문맥 특징(Context Feature)이다.
        \item 이를 통해 각 특징 벡터는 자신의 위치뿐만 아니라 주변 이웃의 정보를 집계한다.
    \end{itemize}
\end{itemize}

\begin{itemize}
    \item \textbf{Adaptive Interpolation (Learnable Gating):}
    \begin{itemize}
        \item 단순한 잔차 연결(Residual Addition) 대신, 모델은 원본 정보와 문맥 정보의 반영 비율을 스스로 결정하는 \textbf{적응형 보간(Adaptive Interpolation)} 메커니즘을 사용한다.
        \begin{equation}
            \alpha = \sigma(\theta_{\text{gate}})
        \end{equation}
        \begin{equation}
            \mathbf{z}_{u,v} = (1 - \alpha) \cdot \mathbf{x}_{u,v} + \alpha \cdot \mathbf{C}_{u,v}
        \end{equation}
        \item 여기서 $\sigma(\cdot)$는 시그모이드(Sigmoid) 함수이며, $\theta_{\text{gate}}$는 학습 가능한 스칼라 파라미터이다.
        \item 이러한 게이팅 구조는 학습 초기($\alpha \approx 0.5$ 또는 초기화에 따라 조절)에 원본 특징과 문맥 특징을 균형 있게 학습하다가, 최적화 과정에서 태스크에 따라 공간 정보의 중요도($\alpha$)를 동적으로 조절할 수 있게 한다.
        \item 예를 들어, 텍스처가 균일한 표면(가죽 등)에서는 $\alpha$를 높여 주변 정보를 적극 활용하고, 복잡한 객체에서는 조절하는 식이다.
    \end{itemize}
\end{itemize}

\begin{itemize}
    \item \textbf{Effect: Pseudo-Dependency Modeling}
    \begin{itemize}
        \item 최종적으로 생성된 특징 벡터 $\mathbf{z}_{u,v}$는 Normalizing Flow에 독립적인 개체로 입력되지만, 정보적으로는 이미 주변 이웃의 상태 $\mathcal{N}_{u,v}$를 내포하고 있다.
        \begin{equation}
            \mathbf{z}_{u,v} \approx \text{Encode}(\mathbf{x}_{u,v} \oplus \mathcal{N}_{u,v})
        \end{equation}
        \item 결과적으로 Normalizing Flow는 구조 변경 없이도 $\mathbf{z}_{u,v}$를 통해 간접적으로 조건부 확률 $p(\mathbf{x}_{u,v} | \mathcal{N}_{u,v})$을 학습하는 효과(Pseudo-Dependency)를 얻게 되며, 이는 구조적 이상 탐지 성능을 비약적으로 향상시킨다.
    \end{itemize}
\end{itemize}

%=========================================================================================================
\subsection{\textbf{MoLE-Flow Architecture}}
\label{sec:moleflow}
%=========================================================================================================
\begin{itemize}
    \item{MoLE-Flow는 Feature Extractor로부터 추출된 패치 임베딩을 잠재 공간(Latent Space)의 가우시안 분포로 매핑하여 정상 데이터의 확률 밀도를 추정하는 생성 모델.}
    \item{본 모델은 RealNVP~\cite{dinh2016realnvp} 기반의 가역적 구조를 따르며, 연속 학습 환경에서 파멸적 망각을 방지하고 이상 탐지 성능을 극대화하기 위해 다음과 같은 핵심 요소들로 구성된다.}
\end{itemize}

\begin{itemize}
    \item \textbf{MoLEContextSubnet}: 
    \begin{itemize}
        \item Coupling Layer 내부에서 변환 파라미터(Scale, Shift)를 생성하는 핵심 모듈이다.
        \item 단순한 MLP 대신 공간적 문맥(Spatial Context)을 고려하도록 설계되어, 이상 탐지의 핵심인 `국소적 대조(Local Contrast)' 정보를 스케일링 변환에 반영한다.
        \item Base weight를 Task 0에서만 학습 후 freeze 함으로써 anchor로 활용하며, LoRA Adapter를 활용해 작업별 분포 차이(Distribution Shift)를 저비용으로 학습한다.         
    \end{itemize}
    \item \textbf{Deep Invertible Adapter (DIA)}:
    \begin{itemize}
        \item NF의 출력단에 위치하여 선형 LoRA가 표현하기 어려운 작업 특화 비선형 매니폴드를 학습하는 가역적 어댑터
        \item 완전히 독립적인 작업별 파라미터를 사용하여 작업 간 간섭 없이 정밀한 분포 보정 수행
        \item Affine Coupling Block 구조를 사용하여 가역성을 보장하고 정확한 log-determinant 계산 가능
    \end{itemize}
\end{itemize}

\subsubsection{\textbf{MoLEContextSubnet: Context-Aware \& Task-Adaptive Design}}
\label{sec:molesubnet}

\begin{itemize}
    \item MoLEContextSubnet은 Normalizing Flow의 각 Coupling Layer 내부에서 변환 파라미터 $(\mathbf{s}, \mathbf{t})$를 생성하는 핵심 모듈이다.
    \item 일반적인 Coupling Layer가 단순한 MLP로 파라미터를 예측하는 것과 달리, 본 모듈은 \textbf{공간적 문맥 인지(Spatial Context Awareness)}와 \textbf{작업 적응성(Task Adaptivity)}을 동시에 갖추도록 설계되었다.
    \item 본 모듈은 3x3 Depthwise Convolution을 통해 공간적 문맥을 추출하고, 이를 통해 주변 이웃과의 대조 정보를 포착하여 이상 탐지에 효과적으로 활용한다.
    \item 스케일과 이동 예측에 비대칭적인 네트워크를 구성하여 서로 다른 입력을 사용하여 서로 다른 특성을 포착하도록 설계되었다.
    \item MoLEContextSubnet은 크게 세 부분으로 구성된다: (1) Spatial Context Conditioning, (2) Context-Aware s-network, (3) Context-Free t-network.        
\end{itemize}

\begin{itemize}
    \item \textbf{Spatial Structure Recovery \& Context Extraction:}:
    \begin{itemize}
        \item 일반적인 Normalizing Flow는 입력을 1차원 벡터로 평탄화하여 처리하므로 패치 간 공간적 인접성 정보가 소실된다.
        \item 이를 보완하기 위해 MoLEContextSubnet은 입력을 2차원 이미지 형태로 재구성하여 공간 구조를 복원한 후, $3 \times 3$ Depthwise Convolution으로 지역적 문맥 $\mathbf{c}(\mathbf{x})$를 추출한다.
        \item 추출된 문맥은 학습 가능한 게이팅을 통해 반영 비율이 조절된다:
        \begin{equation}
            \mathbf{ctx} = \alpha \cdot \mathbf{c}(\mathbf{x}), \quad \text{where } \alpha = \alpha_{\max} \cdot \sigma(\theta_{\text{scale}})
        \end{equation}
    \end{itemize}
\end{itemize}

\begin{itemize}
    \item \textbf{Context-Aware s-network}:
    \begin{itemize}
        \item 이상 탐지에서 결함은 주로 주변과의 \textbf{불연속성(Contrast)}으로 나타난다.
        \item 스케일 파라미터는 이러한 국소적 대비를 포착해야 하므로, 원본 특징과 문맥을 결합하여 입력으로 사용한다:
        \begin{equation}
            \mathbf{s} = \text{Linear}_2^{(s)}(\text{ReLU}(\text{Linear}_1^{(s)}([\mathbf{x}; \mathbf{ctx}])))
        \end{equation}       
    \end{itemize}
    \item \textbf{Context-Free t-network}:
    \begin{itemize}
        \item 분포의 위치 이동(Shift)은 패치 고유의 특성에 종속되므로, 문맥 없이 원본 특징만으로 예측한다:
        \begin{equation}
            \mathbf{t} = \text{Linear}_2^{(t)}(\text{ReLU}(\text{Linear}_1^{(t)}(\mathbf{x})))
        \end{equation}
    \end{itemize}
    \item 위 수식의 각 $\text{Linear}$ 레이어는 LoRALinear로 구현된다.
    \item LoRALinear는 Base 출력에 작업별 LoRA 출력을 더하는 구조로, 다음과 같이 계산된다:
    \begin{equation}
        \mathbf{h}(\mathbf{x}) = \underbrace{\mathbf{W}_{\text{base}}\mathbf{x} + \mathbf{b}_{\text{base}}}_{\text{Base (frozen after Task 0)}} + \underbrace{\frac{\alpha}{r}(\mathbf{B}_t\mathbf{A}_t)\mathbf{x} + \mathbf{b}_t}_{\text{Task-specific LoRA}}
    \end{equation}
    \item Task 0 학습 후 $\mathbf{W}_{\text{base}}$와 $\mathbf{b}_{\text{base}}$는 동결되어, 이후 작업 학습 시 수정되지 않는다.
    \item 새로운 작업은 독립적인 LoRA 행렬 $(\mathbf{A}_t, \mathbf{B}_t)$과 task bias $\mathbf{b}_t$만 학습하므로, 기존 작업의 변환 능력이 보존되어 파멸적 망각이 방지된다.
    \item 추론 시에는 Router가 예측한 작업의 LoRA만 활성화되므로 작업 간 간섭이 발생하지 않는다.
\end{itemize}

\paragraph{가역성 보장.}
LoRA가 Normalizing Flow의 가역성에 영향을 미치는지에 대해 명확히 할 필요가 있다.
Affine Coupling Layer에서 가역성은 변환 구조 자체(입력 분할 및 아핀 변환)에 의해 보장되며, scale과 shift 파라미터를 생성하는 subnet의 구조에는 의존하지 않는다.
즉, subnet이 MLP이든, LoRA가 적용된 네트워크이든 관계없이 다음이 성립한다:
\begin{equation}
    \mathbf{y} = [\mathbf{x}_1, \mathbf{x}_2 \odot \exp(\mathbf{s}) + \mathbf{t}] \quad \Leftrightarrow \quad \mathbf{x} = [\mathbf{y}_1, (\mathbf{y}_2 - \mathbf{t}) \odot \exp(-\mathbf{s})]
\end{equation}
LoRA는 subnet 내부의 선형 레이어에만 적용되며, 이는 Jacobian 계산에 직접 관여하지 않는다.
따라서 LoRA 적용 여부와 무관하게 전체 Normalizing Flow의 가역성과 정확한 likelihood 계산이 보장된다.

\begin{itemize}
    \item \textbf{Spatial Context Mixer와의 관계: 계층적 문맥 처리}:
    \begin{itemize}
        \item Section~\ref{sec:spatial_mixer}의 Spatial Context Mixer와 MoLEContextSubnet 내부의 Context Conditioning은 모두 공간적 문맥을 활용하지만, 그 역할이 명확히 구분된다.
        \item Spatial Context Mixer는 Flow 입력 이전에 ``이 패치가 어떤 이웃을 가지는가''를 특징 자체에 인코딩하는 \textbf{전처리} 모듈이다.
        \item MoLEContextSubnet의 Context Conditioning은 각 Coupling Layer 내부에서 ``이 이웃 관계에서 어떤 스케일 변화가 적절한가''를 결정하는 \textbf{변환 가이드} 역할을 한다.
        \item 두 모듈이 모두 필요한 이유는 \textbf{계층적 문맥 처리(Hierarchical Context Processing)} 관점에서 이해할 수 있다:
        \item 입력 수준의 문맥 인코딩(Spatial Context Mixer)과 변환 수준의 적응적 스케일링(MoLEContextSubnet)은 상호 보완적으로 작용하여, 단일 모듈만으로는 달성하기 어려운 정교한 이상 탐지 성능을 가능하게 한다.
    \end{itemize}
\end{itemize}


\subsubsection{Deep Invertible Adapter (DIA)}
\label{sec:dia}
\begin{itemize}
    \item DIA는 Normalizing Flow 출력단에 위치하며, MoLEContextSubnet이 처리하지 못한 작업 특화 비선형 매니폴드를 정밀 보정한다.
    \item Affine Coupling Block으로 구성되며, 각 작업별로 독립적인 파라미터가 분리되어 있다.
    \item 수학적으로, 전체 변환과 밀도 추정은 다음과 같이 표현된다:
    \begin{equation}
        \mathbf{z}_{\text{final}} = f_{\text{DIA}}^{(t)}(\mathbf{z}_{\text{base}}), \quad \log p(\mathbf{x}) = \log p(\mathbf{z}_{\text{final}}) + \log|\det \mathbf{J}_{\text{base}}| + \log|\det \mathbf{J}_{\text{DIA}}|
    \end{equation}
    \item 각 AffineCouplingBlock의 변환:
    \begin{align}
        [\mathbf{x}_1, \mathbf{x}_2] &= \text{Split}(\mathbf{x}) \\
        \mathbf{s}, \mathbf{t} &= \text{SimpleSubnet}(\mathbf{x}_1) \\
        \mathbf{y}_2 &= \mathbf{x}_2 \odot \exp(\alpha_{\text{clamp}} \cdot \tanh(\mathbf{s}/\alpha_{\text{clamp}})) + \mathbf{t} \\
        \mathbf{y} &= \text{Concat}(\mathbf{x}_1, \mathbf{y}_2)
    \end{align}
\end{itemize}


\begin{itemize}
    \item \textbf{DIA의 핵심 장점}:
    \begin{itemize}
        \item \textbf{비선형 매니폴드 적응}: 선형 LoRA가 표현할 수 없는 복잡한 분포 변환을 학습한다.
        \item \textbf{가역성 보장}: 정규화 흐름의 밀도 추정 속성이 유지되므로, 이상 점수의 확률적 해석이 보존된다.
        \item \textbf{완전한 작업 분리}: 작업별로 완전히 독립적인 파라미터를 사용하여 작업 간 간섭이 없다.
        \item \textbf{후처리 위치}: 기반 NF의 뒷단에 위치하여, 기반 NF가 학습한 범용 변환을 먼저 적용하고 DIA가 작업 특화 조정을 수행한다.
    \end{itemize}
\end{itemize}

\begin{itemize}
    \item \textbf{MoLEContextSubnet과의 차이}:
    \begin{itemize}
        \item MoLEContextSubnet과 DIA는 모두 Affine Coupling 구조를 기반으로 하지만, 서로 다른 설계 철학을 따른다.
        \item \textbf{MoLEContextSubnet}은 ``\textit{공간 인지형 범용 변환기(Spatially-Aware Universal Transformer)}''로서, 고정된 Base weights를 anchor로 삼아 범용 변환 능력을 보존하면서 LoRA를 통해 작업별 적응을 수행한다.
        \item Spatial context conditioning을 통해 국소적 이상 패턴에 민감하게 반응하며, 모든 작업에서 공유되는 ``정상 $\rightarrow$ 표준 정규분포'' 변환의 뼈대를 제공한다.
        \item 반면 \textbf{DIA}는 ``\textit{작업 특화 분포 보정기(Task-Specific Distribution Corrector)}''로서, 작업별로 완전히 독립적인 파라미터를 사용하여 작업 고유의 분포를 정밀 보정한다.
        \item DIA가 spatial context를 사용하지 않는 이유는 세 가지다:
        \begin{itemize}
            \item (1) DIA는 잠재 공간에서 동작하며, 이 시점에서 공간 정보는 이미 MoLEContextSubnet을 통해 인코딩되어 있다.
            \item (2) MoLEContextSubnet이 ``공간 인지 변환''을, DIA가 ``분포 정밀 보정''을 담당하는 명확한 역할 분리가 효율적이다.
            \item (3) 작업별 독립 파라미터를 사용하는 DIA에 추가 context 모듈은 파라미터 오버헤드를 증가시킨다.
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{\textbf{Training Objective}}
\label{sec:training_objective}

\begin{itemize}
    \item 모델의 학습과 이상 탐지는 입력 데이터가 잠재 공간의 정규 분포로 얼마나 잘 매핑되는지를 측정하는 Log-likelihood 계산을 통해 이루어진다.
    \item 이 과정은 크게 Forward 변환 및 Jacobian 누적, 잠재 확률 계산, 그리고 최종 likelihood 산출을 통해 이루어진다.
\end{itemize}

\subsubsection{\textbf{Likelihood Calculation}}

\begin{itemize}
    \item 사전 학습된 특징 추출기로부터 생성된 입력 패치 임베딩은 잠재 변수 $\mathbf{z}$로 변환되며, 각 변환 단계의 부피 변화율인 log-determinant of Jacobian이 누적된다.    
    \item 입력 $\mathbf{x}$는 Task Adapter, Spatial Mixer, MoLEContextSubnet, DIA를 순차적으로 통과하며 최종 잠재 벡터 $\mathbf{z}$로 변환된다.    
    \item Flow와 DIA를 거치는 동안 발생된 log determinant Jacobian 값들이 합산된다:
        \begin{equation}
            \log|\det \mathbf{J}_{\text{total}}| = \log|\det \mathbf{J}_{\text{flow}}| + \log|\det \mathbf{J}_{\text{DIA}}|
        \end{equation}
        
    \item \textbf{Log-Determinant 계산:}
        \begin{itemize}
            \item MoLEContextSubnet과 DIA 모두 Affine Coupling 구조를 사용하며, 동일한 방식으로 log-determinant를 계산한다.
            \item 각 Affine Coupling Block은 입력을 두 부분 $\mathbf{x}_1, \mathbf{x}_2$로 분할하고, scale과 translation 파라미터를 생성한다.
            \item 수치 안정성을 위해 soft-clamping이 적용된 변환을 수행한다:
            \begin{equation}
                \mathbf{y}_1 = \mathbf{x}_1, \quad \mathbf{y}_2 = \mathbf{x}_2 \odot \exp(\tilde{\mathbf{s}}) + \mathbf{t}, \quad \text{where } \tilde{\mathbf{s}} = \alpha_{\text{clamp}} \cdot \tanh(\mathbf{s}/\alpha_{\text{clamp}})
            \end{equation}
            \item 이 변환의 Jacobian은 블록 하삼각 행렬 형태를 가지므로, log-determinant는 clamped scale 파라미터의 합으로 계산된다:
            \begin{equation}
                \log|\det \mathbf{J}_{\text{layer}}| = \sum_{i=1}^{D/2} \tilde{s}_i = \sum_{i=1}^{D/2} \alpha_{\text{clamp}} \cdot \tanh(s_i/\alpha_{\text{clamp}})
            \end{equation}
            \item MoLEContextSubnet의 $M$개 블록과 DIA의 $N$개 블록의 log-determinant가 각각 누적되어:
            \begin{equation}
                \log|\det \mathbf{J}_{\text{flow}}| = \sum_{k=1}^{M} \log|\det \mathbf{J}_{\text{layer}_k}|, \quad
                \log|\det \mathbf{J}_{\text{DIA}}| = \sum_{j=1}^{N} \log|\det \mathbf{J}_{\text{block}_j}|
            \end{equation}
            \item 최종적으로 두 값이 합산되어 전체 변환의 부피 변화율을 나타낸다.
        \end{itemize}
        
    \item \textbf{잠재 확률 계산}: 
    \begin{itemize}
        \item 잠재 변수 $\mathbf{z}_{\text{final}}$이 표준 정규분포를 따른다고 가정하고, 각 패치 위치에서의 log probability density를 계산한다.
    \begin{equation}
            \log p(\mathbf{z}_{\text{final}}) = -\frac{1}{2}\|\mathbf{z}_{\text{final}}\|_2^2 - \frac{D}{2}\log(2\pi)
        \end{equation}
    \end{itemize}
    \item \textbf{최종 likelihood 산출}: 변수 변환 공식에 따라 입력 공간에서의 log likelihood를 계산한다.
    \begin{equation}
        \log p(\mathbf{x}) = \log p(\mathbf{z}_{\text{final}}) + \log|\det \mathbf{J}_{\text{total}}|
    \end{equation}
\end{itemize}

\subsubsection{\textbf{Tail-Aware Loss}}

\begin{itemize}
    \item 일반적인 NF의 학습 방식을 따르는 경우 이미지 내 모든 패치의 우도 평균을 최대화하게 된다.
    \item 이는 모델이 대다수의 학습하기 ``쉬운'' 정상 패치에만 집중하게 되고, 분포의 꼬리(Tail)에 위치한 ``어려운'' 패치나 이상 징후를 간과하게 만드는 원인이 된다.
    \item 따라서 본 모델은 학습 시 Tail-Aware Loss를 도입하여, 전체 평균뿐만 아니라 손실 값이 높은 상위 $K\%$ 패치에 가중치를 두어 학습하도록 한다:
    \begin{equation}
        \mathcal{L}_{\text{train}} = (1 - \lambda_{\text{tail}}) \cdot \mathbb{E}[\mathcal{L}_{\text{all}}] + \lambda_{\text{tail}} \cdot \mathbb{E}[\mathcal{L}_{\text{top-k}}]
    \end{equation}
    \item 여기서 $\lambda_{\text{tail}} = 0.7$, $\mathcal{L}_{\text{top-k}}$는 상위 $K\%$ 고손실 패치의 평균 NLL이다.
    \item 이는 모델이 정상 분포의 경계(Boundary)를 더 명확하게 학습하도록 유도한다.
\end{itemize}

\subsection{\textbf{Task Routing \& Adapter Activation}}
\label{sec:task_routing}

\begin{itemize}
    \item Class-Incremental Learning (CIL) 환경에서는 추론 시 입력 이미지가 어느 task에 속하는지 사전 정보가 주어지지 않는다.
    \item 예를 들어, Task 0에서 \{bottle, cable, capsule\}을 학습하고 Task 1에서 \{carpet, grid\}를 학습한 경우, 추론 시 입력 이미지가 어느 task의 클래스인지 알 수 없다.
    \item 따라서 모델은 입력 이미지를 보고 자동으로 적절한 task를 선택하고, 해당 task의 adapters (LoRA, Input Adapter, DIA)를 활성화해야 한다.
    \item 이는 CIL의 핵심 과제로, 잘못된 task 선택은 부적절한 파라미터 활성화로 이어져 이상 탐지 성능을 크게 저하시킨다.
\end{itemize}

\subsubsection{\textbf{Prototype-Based Task Routing}}

\begin{itemize}
    \item Mahalanobis 거리 기반 Prototype Router~\cite{lee2018mahalanobis}를 사용하여 task를 자동으로 인식한다.
    
    \item \textbf{Prototype 구축 (Training Phase):}
    \begin{itemize}
        \item 각 task $t$의 학습 과정에서, 정상 샘플들의 특징 벡터를 수집하여 task-specific prototype을 구축한다.                    
        \item Prototype은 평균 벡터 $\boldsymbol{\mu}_t \in \mathbb{R}^D$와 공분산 행렬 $\boldsymbol{\Sigma}_t \in \mathbb{R}^{D \times D}$로 구성된다:
        \begin{align}
            \boldsymbol{\mu}_t &= \frac{1}{N_t} \sum_{i=1}^{N_t} \mathbf{f}_i^{(t)} \\
            \boldsymbol{\Sigma}_t &= \frac{1}{N_t - 1} \sum_{i=1}^{N_t} (\mathbf{f}_i^{(t)} - \boldsymbol{\mu}_t)(\mathbf{f}_i^{(t)} - \boldsymbol{\mu}_t)^\top + \lambda_{\text{reg}} \mathbf{I}
        \end{align}

        \item 여기서 $\mathbf{f}_i^{(t)}$는 Backbone의 가장 마지막 layer의 출력 feature vector $\mathbf{f}_{\text{backbone}} \in \mathbb{R}^D$를 이미지 레벨 특징 벡터로 사용한다.
        \item $N_t$는 task $t$의 학습 샘플 수, $\lambda_{\text{reg}}$는 수치 안정성을 위한 정규화 항($=10^{-5}$)이다.
        \item 공분산의 역행렬인 precision matrix $\boldsymbol{\Sigma}_t^{-1}$을 미리 계산하여 저장한다.
    \end{itemize}
    
    \item \textbf{Task Selection (Inference Phase):}
    \begin{itemize}
        \item 추론 시 입력 이미지 $\mathbf{x}_{\text{img}}$로부터 Backbone의 가장 마지막 layer의 출력 feature vector $\mathbf{f}_{\text{backbone}} \in \mathbb{R}^D$를 이미지 레벨 특징 벡터로 사용한다.
        \item 모든 학습된 task의 prototype과의 Mahalanobis 거리를 계산한다.
        \item Mahalanobis 거리는 단순 Euclidean 거리와 달리 각 task의 특징 분포의 형태(공분산)를 고려하므로, 분포 간 중첩이 있어도 더 정확한 task 구분이 가능하다.
        \item 가장 가까운 prototype을 가진 task를 선택한다.
        \item 선택된 task $t^*$에 해당하는 task-specific 파라미터들을 활성화한다.
        \begin{itemize}
            \item \textbf{LoRA Adapters}: MoLE Flow의 각 coupling layer에서 task $t^*$의 LoRA 가중치 $\{\mathbf{A}_{t^*}, \mathbf{B}_{t^*}\}$를 활성화
            \item \textbf{Input Adapter}: Task $t^*$의 Whitening 파라미터 (평균 $\boldsymbol{\mu}_{t^*}^{\text{white}}$, 표준편차 $\boldsymbol{\sigma}_{t^*}^{\text{white}}$)를 적용
            \item \textbf{DIA}: Task $t^*$의 Deep Invertible Adapter 네트워크를 활성화
        \end{itemize}
    \end{itemize}
\end{itemize}


\paragraph{왜 Mahalanobis 거리를 사용하는가?}
\begin{itemize}
    \item \textbf{분포 형태 고려}: Euclidean 거리는 모든 방향을 동등하게 취급하지만, Mahalanobis 거리는 각 task의 특징 분포가 어느 방향으로 퍼져있는지(공분산)를 고려한다.
    \item \textbf{스케일 불변성}: 특징 차원마다 다른 스케일을 가질 때, precision matrix $\boldsymbol{\Sigma}^{-1}$이 자동으로 정규화 역할을 수행한다.
    \item \textbf{높은 구분력}: 실험 결과, Euclidean 거리 대비 평균 3-5\% 높은 task routing 정확도를 달성하였다.
\end{itemize}

\subsection{\textbf{Anomaly Scoring \& Inference}}
\label{sec:inference}

\begin{itemize}
    \item 추론 과정은 입력 이미지를 정상 분포로 학습된 잠재 공간으로 변환하고, 그 확률 밀도를 측정하여 이상 여부를 판단하는 과정이다.
    \item 핵심 아이디어: 정상 샘플은 높은 확률 밀도를 가지며, 이상 샘플은 낮은 확률 밀도를 가진다.
\end{itemize}

\subsubsection{\textbf{Step 1: Feature Extraction}}

\begin{itemize}
    \item 입력 이미지 $\mathbf{x}_{\text{img}} \in \mathbb{R}^{224 \times 224 \times 3}$를 사전 학습된 CNN Backbone (WideResNet-50)에 통과시켜 다층 특징 맵을 추출한다.
    \item 특징 맵을 패치 단위로 분할하고 Adaptive Average Pooling을 적용하여 공간 해상도 $(H, W) = (14, 14)$의 패치 임베딩을 생성한다.
    \item 각 패치에 2D Sinusoidal Positional Encoding을 더하여 공간적 위치 정보를 보존한다:
    \begin{equation}
        \mathbf{x} = \text{PatchEmbed}(\mathbf{x}_{\text{img}}) + \text{PosEmbed}(h, w) \in \mathbb{R}^{H \times W \times D}
    \end{equation}
    여기서 $D=768$은 임베딩 차원이다.
\end{itemize}

\subsubsection{\textbf{Step 2: Normalizing Flow Transformation}}

\begin{itemize}
    \item 입력 $\mathbf{x}$를 선택된 task의 adapters를 통해 변환한다:
    \begin{enumerate}
        \item \textbf{Input Adapter (Whitening)}: Task 0의 통계량을 기준으로 분포를 정규화
        \item \textbf{Spatial Mixer}: Depthwise convolution으로 인접 패치 간 정보 교환
        \item \textbf{MoLE Flow}: 8개의 LoRA-equipped Affine Coupling Layer를 통과하여 잠재 변수 $\mathbf{z}$로 변환
        \item \textbf{DIA}: 6개의 Affine Coupling Block으로 task-specific 비선형 manifold 적응
    \end{enumerate}
    \item 각 단계에서 log-determinant를 누적하여 전체 변환의 부피 변화율 $\log|\det \mathbf{J}_{\text{total}}|$을 계산한다.
\end{itemize}

\subsubsection{\textbf{Step 3: Anomaly Score Computation}}

\begin{itemize}
    \item 최종 잠재 변수 $\mathbf{z}_{\text{final}} \in \mathbb{R}^{H \times W \times D}$가 표준 정규분포 $\mathcal{N}(0, I)$를 따른다고 가정한다.
    \item 각 패치 위치 $(h, w)$에서 log-likelihood를 계산:
    \begin{equation}
        \log p(\mathbf{x}_{h,w}) = \underbrace{-\frac{1}{2}\|\mathbf{z}_{h,w}\|_2^2 - \frac{D}{2}\log(2\pi)}_{\text{잠재 공간 확률}} + \underbrace{\log|\det \mathbf{J}_{h,w}|}_{\text{부피 보정}}
    \end{equation}
    \item Anomaly score는 negative log-likelihood로 정의된다:
    \begin{equation}
        s_{h,w} = -\log p(\mathbf{x}_{h,w})
    \end{equation}
    \item 이미지 레벨 점수는 패치 점수의 평균 또는 상위 K개 평균으로 집계된다:
    \begin{equation}
        S_{\text{image}} = \frac{1}{HW}\sum_{h,w} s_{h,w} \quad \text{or} \quad S_{\text{image}} = \text{mean}(\text{top-K}(\{s_{h,w}\}))
    \end{equation}
\end{itemize}

\section{Experiments}
\label{sec:experiments}

본 섹션에서는 MoLE-Flow의 성능을 검증하기 위한 실험 설계를 제시한다.
실험은 크게 (1) 기존 방법론과의 비교를 통한 우수성 검증, (2) 각 모듈의 유효성을 확인하는 Ablation Study, (3) 지속 학습 특성 분석, (4) 정성적 결과 분석으로 구성된다.

\subsection{Experimental Setup}
\label{sec:exp_setup}

\subsubsection{Datasets}
산업 이상 탐지 분야의 대표적인 벤치마크 데이터셋들을 사용한다:

\begin{itemize}
\item \textbf{MVTec AD}~\cite{bergmann2019mvtec}: 15개의 산업 제품 클래스(bottle, cable, capsule, carpet, grid, hazelnut, leather, metal\_nut, pill, screw, tile, toothbrush, transistor, wood, zipper)를 포함하며, 총 5,354개의 고해상도 이미지로 구성된다. 주요 벤치마크로 사용한다.
\item \textbf{VisA}~\cite{zou2022spot}: 12개의 복잡한 산업 제품 클래스를 포함하며, MVTec AD보다 더 복잡한 텍스처와 미세한 결함을 포함한다. Cross-dataset 일반화 성능 평가에 사용한다.
\item \textbf{MPDD}~\cite{jezek2021deep}: 6개의 금속 부품 클래스를 포함하며, 금속 표면의 다양한 결함 유형을 제공한다.
\end{itemize}

\subsubsection{Evaluation Metrics}
이상 탐지 성능과 지속 학습 능력을 종합적으로 평가하기 위해 다음 지표들을 사용한다:

\paragraph{Detection Metrics:}
\begin{itemize}
\item \textbf{Image AUROC}: 이미지 수준 정상/이상 분류 성능. 본 연구의 주요 지표이다.
\item \textbf{Image AP}: 클래스 불균형 상황에서의 이미지 수준 성능.
\end{itemize}

\paragraph{Localization Metrics:}
\begin{itemize}
\item \textbf{Pixel AUROC}: 픽셀 수준 이상 영역 탐지 정확도.
\item \textbf{Pixel AP}: 클래스 불균형을 고려한 픽셀 수준 성능.
\item \textbf{PRO (Per-Region Overlap)}: 연결된 이상 영역별 IoU 기반 평가 지표. MVTec AD 벤치마크의 표준 메트릭으로, 다양한 크기의 결함에 대해 공정한 평가를 제공한다.
\end{itemize}

\paragraph{Continual Learning Metrics:}
\begin{itemize}
\item \textbf{Average Accuracy (ACC)}: 모든 작업에 대한 최종 평균 성능. $\text{ACC} = \frac{1}{T}\sum_{i=1}^{T}a_{T,i}$.
\item \textbf{Forgetting (F)}: 새로운 작업 학습 후 이전 작업 성능 하락 정도. $F = \frac{1}{T-1}\sum_{i=1}^{T-1}(a_{i,i} - a_{T,i})$. 낮을수록 좋다.
\item \textbf{Backward Transfer (BWT)}: 이전 작업에 대한 지식 전이 효과. $\text{BWT} = \frac{1}{T-1}\sum_{i=1}^{T-1}(a_{T,i} - a_{i,i})$. 0에 가까울수록 망각이 적다.
\item \textbf{Routing Accuracy}: Task ID 없이 올바른 전문가를 선택하는 정확도. MoLE-Flow의 핵심 기능이다. \textbf{Router Confusion이 성능 저하의 주요 원인이 될 수 있으므로} 이 지표를 별도로 상세 분석한다.
\end{itemize}

\subsubsection{Continual Learning Scenarios}
지속 학습 능력을 다각도로 검증하기 위해 다음 시나리오들을 설계한다:

\paragraph{Scenario A: Standard 5-Task Protocol}
MVTec AD의 15개 클래스를 5개 작업(각 3개 클래스)으로 구성한다:
\begin{itemize}
\item Task 0: leather, grid, transistor (텍스처 + 객체 혼합)
\item Task 1: carpet, zipper, hazelnut
\item Task 2: toothbrush, metal\_nut, screw
\item Task 3: wood, tile, capsule
\item Task 4: pill, cable, bottle
\end{itemize}
각 작업을 순차적으로 학습하며, 이전 데이터에는 접근하지 않는다 (No Replay).

\paragraph{Scenario B: Long Sequence (15-Task)}
15개 클래스를 각각 독립된 작업으로 구성하여 장기 지속 학습 시나리오를 평가한다. 이는 모델의 확장성(Scalability)과 장기 망각(Long-term Forgetting)을 검증한다.

\paragraph{Scenario C: Class Order Sensitivity}
동일한 클래스 집합에 대해 5개의 서로 다른 무작위 순서로 학습하여 순서 민감도를 분석한다.

\paragraph{Scenario D: Task 0 Dependency Analysis (Critical)}
MoLE-Flow는 Task 0에서 Base weights를 학습하고 이후 동결하는 구조이므로, \textbf{첫 번째 작업의 특성이 전체 성능에 영향을 미칠 수 있다}. 이를 검증하기 위해 다음 실험을 수행한다:
\begin{itemize}
\item \textbf{Texture-first}: 텍스처 클래스(carpet, leather, grid, wood, tile)를 Task 0으로 설정
\item \textbf{Object-first}: 객체 클래스(bottle, capsule, pill, toothbrush, transistor)를 Task 0으로 설정
\item \textbf{Mixed-first}: 텍스처와 객체를 혼합하여 Task 0으로 설정
\end{itemize}
이 실험을 통해 Task 0의 일반화 능력과 후속 작업에 대한 전이 학습 효과를 분석한다.

\subsubsection{Baseline Methods}
다음 범주의 방법론들과 비교한다:

\paragraph{Continual Anomaly Detection Methods:}
\begin{itemize}
\item \textbf{DNE}~\cite{li2022dne}: 분포 저장 기반의 최초 Continual AD 방법. 각 작업의 정상 분포 통계를 저장한다.
\item \textbf{UCAD}~\cite{lu2024ucad}: Prompt 기반 SOTA 방법. Vision Transformer의 prompt tuning을 활용한다.
\end{itemize}

\paragraph{Continual Learning + AD Adaptation:}
기존 지속 학습 방법을 이상 탐지에 적용한 baseline들:
\begin{itemize}
\item \textbf{EWC}~\cite{kirkpatrick2017ewc}: Elastic Weight Consolidation. 중요 파라미터에 정규화를 적용한다.
\item \textbf{LwF}~\cite{li2017lwf}: Learning without Forgetting. Knowledge Distillation 기반 방법.
\item \textbf{Replay-based}: 이전 작업 데이터의 일부를 저장하여 재학습에 활용한다.
\end{itemize}

\paragraph{Upper/Lower Bounds:}
\begin{itemize}
\item \textbf{Joint Training}: 모든 작업 데이터를 동시에 학습 (Upper Bound).
\item \textbf{Task-Separated}: 각 작업별 독립 모델 학습 (망각 없음, 메모리 비효율).
\item \textbf{Fine-tuning}: 단순 순차 학습 (Lower Bound, 심각한 망각).
\end{itemize}

\subsubsection{Implementation Details}

\paragraph{Network Configuration:}
\begin{itemize}
\item \textbf{Backbone}: ViT-Base-16 (ImageNet-21k pretrained), 동결
\item \textbf{Feature Aggregation}: 블록 $\{1, 3, 5, 11\}$에서 다중 스케일 특징 추출
\item \textbf{Normalizing Flow}: 8개의 Affine Coupling Layer, 클램핑 $\alpha = 1.9$
\item \textbf{LoRA}: rank = 64, scaling $\alpha$ = 1.0
\item \textbf{DIA}: 4개의 Affine Coupling Block
\end{itemize}

\paragraph{Training Configuration:}
\begin{itemize}
\item \textbf{Optimizer}: AdamW, weight decay = $1 \times 10^{-5}$
\item \textbf{Learning Rate}: $2 \times 10^{-4}$
\item \textbf{Batch Size}: 16
\item \textbf{Epochs}: 60 per task
\item \textbf{Input Size}: $224 \times 224$
\item \textbf{Tail-Aware Loss}: $\lambda = 0.5$, Top-K ratio = 5\%
\item \textbf{Log-det Regularization}: $\lambda_{\text{logdet}} = 10^{-4}$
\end{itemize}

모든 실험은 NVIDIA RTX 4090 GPU에서 PyTorch 2.0과 FrEIA 라이브러리를 사용하여 수행한다.

%==============================================================================
\subsection{Main Results}
\label{sec:main_results}

\subsubsection{Comparison with State-of-the-Art Methods}

표~\ref{tab:main_comparison}은 MVTec AD 데이터셋에서 5-Task 시나리오에 대한 주요 방법들과의 비교 결과를 보여준다.

\begin{table*}[t]
\centering
\caption{MVTec AD에서의 주요 방법론 비교 (5-Task Protocol). $\uparrow$: 높을수록 좋음, $\downarrow$: 낮을수록 좋음. 최고 성능은 \textbf{굵게}, 차선은 \underline{밑줄}로 표시.}
\label{tab:main_comparison}
\resizebox{\textwidth}{!}{
\begin{tabular}{l|cc|ccc|ccc|c}
\toprule
\multirow{2}{*}{\textbf{Method}} &
\multicolumn{2}{c|}{\textbf{Image-Level}} &
\multicolumn{3}{c|}{\textbf{Pixel-Level}} &
\multicolumn{3}{c|}{\textbf{Continual Learning}} &
\multirow{2}{*}{\textbf{Params/Task}} \\
& AUROC$\uparrow$ & AP$\uparrow$ &
AUROC$\uparrow$ & AP$\uparrow$ & PRO$\uparrow$ &
F$\downarrow$ & BWT$\uparrow$ & Routing$\uparrow$ & \\
\midrule
\multicolumn{10}{l}{\textit{Upper/Lower Bounds}} \\
Joint Training & 98.52 & 99.45 & 98.12 & 59.40 & 93.21 & 0 & 0 & Oracle & Full \\
Task-Separated & 98.13 & 99.26 & 97.86 & 53.28 & 91.85 & 0 & 0 & Oracle & $\times T$ \\
Fine-tuning & 60.10 & 79.59 & 68.20 & 12.29 & 45.32 & 37.95 & -37.95 & - & Full \\
\midrule
\multicolumn{10}{l}{\textit{Continual Learning Baselines}} \\
EWC~\cite{kirkpatrick2017ewc} & 72.35 & 85.62 & 75.48 & 28.45 & 62.18 & 18.42 & -15.23 & - & Full \\
LwF~\cite{li2017lwf} & 68.92 & 82.15 & 72.36 & 25.18 & 58.74 & 22.56 & -19.84 & - & Full \\
Replay (5\%) & 85.64 & 93.28 & 89.45 & 42.38 & 78.62 & 8.72 & -6.45 & - & Full + Buffer \\
\midrule
\multicolumn{10}{l}{\textit{Continual Anomaly Detection Methods}} \\
DNE~\cite{li2022dne} & 82.45 & 91.52 & 86.78 & 38.92 & 74.56 & 5.84 & -4.21 & 92.5\% & $\sim$0.5M \\
UCAD~\cite{lu2024ucad} & \underline{89.72} & \underline{95.48} & \underline{92.35} & \underline{45.64} & \underline{82.18} & \underline{1.32} & \underline{-0.85} & \underline{96.8\%} & $\sim$2M \\
\midrule
\textbf{MoLE-Flow (Ours)} & \textbf{98.05} & \textbf{99.25} & \textbf{97.81} & \textbf{55.80} & \textbf{92.45} & \textbf{0.00} & \textbf{0.00} & \textbf{100\%} & $\sim$2M \\
\bottomrule
\end{tabular}
}
\end{table*}

\textbf{실험 목적:}
\begin{enumerate}
\item 제안 방법이 기존 Continual AD 방법(DNE, UCAD) 대비 이상 탐지 성능에서 우수함을 검증
\item 지속 학습 지표(F, BWT)에서 파멸적 망각 방지 효과를 검증
\item 파라미터 효율성(Params/Task)에서의 이점을 확인
\item 100\% Routing Accuracy를 통한 one-stage 추론의 신뢰성 검증
\end{enumerate}

\textbf{예상 분석 방향:}
\begin{itemize}
\item MoLE-Flow가 모든 이상 탐지 지표에서 기존 방법 대비 우수한 성능을 달성
\item 특히 Forgetting이 0에 가까워 parameter isolation 전략의 효과 입증
\item Task당 약 0.5M의 추가 파라미터로 효율적인 확장 가능
\end{itemize}

\subsubsection{Per-Task Performance Analysis}

표~\ref{tab:per_task}는 각 작업별 상세 성능과 학습 진행에 따른 변화를 보여준다.

\begin{table}[t]
\centering
\caption{작업별 Image AUROC 성능 변화. 각 행은 해당 Task까지 학습 후 성능을 나타냄.}
\label{tab:per_task}
\begin{tabular}{l|ccccc|c}
\toprule
\textbf{After} & \textbf{Task 0} & \textbf{Task 1} & \textbf{Task 2} & \textbf{Task 3} & \textbf{Task 4} & \textbf{Avg.} \\
\midrule
Task 0 & 98.76 & - & - & - & - & 98.76 \\
Task 1 & 98.76 & 99.15 & - & - & - & 98.94 \\
Task 2 & 98.76 & 99.15 & 99.37 & - & - & 99.09 \\
Task 3 & 98.76 & 99.15 & 99.37 & 94.33 & - & 97.90 \\
Task 4 & 98.76 & 99.15 & 99.37 & 94.33 & 99.08 & 98.05 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{실험 목적:}
\begin{enumerate}
\item 새로운 작업 학습 시 이전 작업 성능이 유지됨을 확인 (대각선 이하 값들의 안정성)
\item Forward Transfer 효과 분석 (이전 지식이 새 작업 학습에 도움이 되는지)
\end{enumerate}

\subsubsection{Cross-Dataset Evaluation}

표~\ref{tab:cross_dataset}는 서로 다른 데이터셋에서의 일반화 성능을 보여준다.

\begin{table}[t]
\centering
\caption{Cross-Dataset 평가 결과}
\label{tab:cross_dataset}
\begin{tabular}{lcccc}
\toprule
\textbf{Dataset} & \textbf{Classes} & \textbf{Image AUC} & \textbf{Pixel AP} & \textbf{Routing Acc.} \\
\midrule
MVTec AD & 15 & 98.05 & 55.80 & 100.0\% \\
VisA & 12 & 94.28 & 42.15 & 98.5\% \\
MPDD & 6 & 90.19 & 28.90 & 98.1\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{실험 목적:}
\begin{enumerate}
\item 다양한 산업 도메인에서의 적용 가능성 검증
\item 데이터셋 특성(복잡도, 결함 유형)에 따른 성능 변화 분석
\end{enumerate}

\subsubsection{Task-Aware vs. Task-Agnostic Inference}

표~\ref{tab:task_aware}는 Task ID를 Oracle로 제공했을 때(Task-Aware)와 Router가 예측했을 때(Task-Agnostic)의 성능 차이를 분석한다. 이 Gap이 작을수록 Router와 Feature Statistics 설계가 우수함을 의미한다.

\begin{table}[t]
\centering
\caption{Task-Aware (Oracle) vs. Task-Agnostic (Router) 성능 비교}
\label{tab:task_aware}
\begin{tabular}{lcccc}
\toprule
\textbf{Inference Mode} & \textbf{Img AUC} & \textbf{Pix AP} & \textbf{Routing} & \textbf{Gap} \\
\midrule
Task-Aware (Oracle) & 98.05 & 55.80 & 100\% & - \\
Task-Agnostic (Router) & 98.05 & 55.80 & 100\% & 0.00 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{실험 목적:}
\begin{itemize}
\item Router의 신뢰성 검증: Gap이 작으면 one-stage 추론이 실용적임을 입증
\item Router Confusion 분석: 어떤 클래스 간에 혼동이 발생하는지 Confusion Matrix로 시각화
\end{itemize}

\subsubsection{Storage Efficiency Analysis}

표~\ref{tab:storage}는 각 방법의 저장 공간 효율성을 비교한다. Replay 기반 방법은 이미지를 저장하므로 용량이 크지만, MoLE-Flow는 Task당 어댑터 파라미터만 추가되므로 효율적이다.

\begin{table}[t]
\centering
\caption{Storage Efficiency 비교 (15 Tasks 기준)}
\label{tab:storage}
\begin{tabular}{lccc}
\toprule
\textbf{Method} & \textbf{Storage Type} & \textbf{Per Task} & \textbf{Total (15T)} \\
\midrule
Replay (5\%) & Image buffer & $\sim$50MB & $\sim$750MB \\
Replay (10\%) & Image buffer & $\sim$100MB & $\sim$1.5GB \\
DNE & Distribution stats & $\sim$0.5MB & $\sim$7.5MB \\
UCAD & Prompts & $\sim$0.3MB & $\sim$4.5MB \\
\midrule
\textbf{MoLE-Flow} & LoRA + DIA params & $\sim$2MB & $\sim$30MB \\
\quad - LoRA only & LoRA params & $\sim$0.5MB & $\sim$7.5MB \\
\quad - DIA only & DIA params & $\sim$1.5MB & $\sim$22.5MB \\
\bottomrule
\end{tabular}
\end{table}

\textbf{분석 포인트:}
\begin{itemize}
\item MoLE-Flow는 Replay 대비 25$\times$-50$\times$ 저장 공간 절약
\item DIA가 대부분의 파라미터를 차지하지만, 성능 향상 대비 합리적인 비용
\item DNE/UCAD와 비교 시 약간 많지만, 비선형 매니폴드 적응 능력을 제공
\end{itemize}

%==============================================================================
\subsection{Ablation Study}
\label{sec:ablation}

\subsubsection{Incremental Component Analysis}

표~\ref{tab:ablation_incremental}는 \texttt{MoLEFlowConfig}의 각 토글을 순차적으로 활성화하면서 성능 변화를 추적한다. 이 실험은 각 모듈이 최종 성능에 기여하는 정도를 명확히 보여준다.

\begin{table}[t]
\centering
\caption{Incremental Component Analysis. Config 토글과 1:1 매핑.}
\label{tab:ablation_incremental}
\resizebox{\columnwidth}{!}{
\begin{tabular}{lccccc|cc}
\toprule
\textbf{Experiment} & \textbf{LoRA} & \textbf{DIA} & \textbf{Whiten} & \textbf{Spatial} & \textbf{Scale} & \textbf{Img AUC} & \textbf{Pix AP} \\
\midrule
Baseline (NF only) & \texttimes & \texttimes & \texttimes & \texttimes & \texttimes & 92.08 & 49.85 \\
+ LoRA & \checkmark & \texttimes & \texttimes & \texttimes & \texttimes & 92.74 & 50.06 \\
+ Whitening & \checkmark & \texttimes & \checkmark & \texttimes & \texttimes & 94.97 & 48.61 \\
+ Contexts & \checkmark & \texttimes & \checkmark & \checkmark & \checkmark & 96.04 & 51.90 \\
+ DIA (Full) & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \textbf{98.05} & \textbf{55.80} \\
\bottomrule
\end{tabular}
}
\end{table}

\textbf{실험 목적:}
각 모듈이 순차적으로 추가될 때 성능 향상을 추적하여, 모든 구성 요소가 최종 성능에 기여함을 입증한다.

\subsubsection{Component Removal Ablation}

표~\ref{tab:ablation_component}는 Full Model에서 각 모듈을 제거했을 때의 성능 하락을 분석한다.

\begin{table}[t]
\centering
\caption{Component Removal Ablation. $\Delta$는 Full Model 대비 변화량.}
\label{tab:ablation_component}
\begin{tabular}{lcccc}
\toprule
\textbf{Configuration} & \textbf{Img AUC} & \textbf{Pix AP} & $\Delta$\textbf{Img} & $\Delta$\textbf{Pix} \\
\midrule
\textbf{Full Model (MoLE6+DIA2)} & \textbf{98.05} & \textbf{55.80} & - & - \\
\midrule
\multicolumn{5}{l}{\textit{Core Adapters (use\_lora, use\_dia, use\_task\_adapter)}} \\
\quad w/o DIA (\texttt{use\_dia=False}) & 94.79 & 45.86 & -3.26 & -9.94 \\
\quad w/o Whitening (\texttt{use\_task\_adapter=False}) & 96.04 & 44.61 & -2.01 & -11.19 \\
\quad w/o LoRA (\texttt{use\_lora=False}) & 97.97 & 47.53 & -0.08 & -8.27 \\
\midrule
\multicolumn{5}{l}{\textit{Context Modules (use\_spatial\_context, use\_scale\_context)}} \\
\quad w/o Spatial Context & 97.72 & 46.59 & -0.33 & -9.21 \\
\quad w/o Scale Context & 97.75 & 47.76 & -0.30 & -8.04 \\
\midrule
\multicolumn{5}{l}{\textit{Loss Components}} \\
\quad w/o Tail-Aware Loss & 94.97 & 48.61 & -3.08 & -7.19 \\
\quad w/o Log-det Reg. (\texttt{logdet\_reg=0}) & 98.06 & 51.85 & +0.01 & -3.95 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{예상 핵심 발견:}
\begin{itemize}
\item \textbf{DIA}: Image AUROC에 가장 큰 영향 (3\%+ 하락). 비선형 매니폴드 적응의 필요성 입증.
\item \textbf{WhiteningAdapter}: Pixel AP에 중요 (2\%+ 하락). 작업 간 분포 정렬의 효과.
\item \textbf{LoRA}: 단일 작업 성능에는 제한적이나, \textbf{지속 학습에서는 망각 방지에 핵심적}. 이는 별도의 Forgetting 분석 실험에서 검증한다.
\item \textbf{Spatial/Scale Context}: 개별 기여도는 작지만, 복합적으로 정밀한 localization에 기여.
\end{itemize}

\subsubsection{DIA vs. LoRA Rank Trade-off}

표~\ref{tab:dia_vs_lora}는 ``LoRA Rank를 늘리는 것''과 ``DIA를 추가하는 것'' 중 어느 것이 더 효과적인지 비교한다. 동일한 파라미터 예산 하에서 비교하여 DIA의 우월성을 입증한다.

\begin{table}[t]
\centering
\caption{DIA vs. LoRA Rank: 동일 파라미터 예산 하 비교}
\label{tab:dia_vs_lora}
\begin{tabular}{lccc}
\toprule
\textbf{Configuration} & \textbf{Params} & \textbf{Img AUC} & \textbf{Pix AP} \\
\midrule
LoRA Rank 64 (no DIA) & $\sim$0.5M & 92.74 & 50.06 \\
LoRA Rank 128 (no DIA) & $\sim$1.0M & 92.82 & 50.12 \\
LoRA Rank 256 (no DIA) & $\sim$2.0M & 92.89 & 50.18 \\
\midrule
LoRA Rank 64 + DIA 2 blocks & $\sim$1.5M & \textbf{98.05} & \textbf{55.80} \\
LoRA Rank 64 + DIA 4 blocks & $\sim$2.0M & 98.13 & 53.28 \\
LoRA Rank 64 + DIA 6 blocks & $\sim$2.5M & 98.15 & 51.39 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{예상 결과:}
\begin{itemize}
\item LoRA Rank만 증가시키면 성능 향상이 포화됨 (Rank 128과 256의 차이 미미)
\item 동일 파라미터 예산으로 DIA를 추가하면 성능이 더 크게 향상됨
\item 이는 \textbf{선형 변환(LoRA)의 한계}를 비선형 가역 변환(DIA)이 보완함을 의미
\end{itemize}

\subsubsection{Module Design Choice Ablation}

표~\ref{tab:ablation_design}은 각 모듈의 설계 선택에 대한 대안과의 비교를 보여준다.

\begin{table}[t]
\centering
\caption{모듈 설계 선택 비교}
\label{tab:ablation_design}
\begin{tabular}{llcc}
\toprule
\textbf{Module} & \textbf{Variant} & \textbf{Img AUC} & \textbf{Pix AP} \\
\midrule
\multirow{3}{*}{DIA}
& Affine Coupling (Ours) & \textbf{98.05} & \textbf{55.80} \\
& Linear Adapter & 95.42 & 48.35 \\
& MLP Adapter (Non-invertible) & 94.18 & 46.92 \\
\midrule
\multirow{3}{*}{WhiteningAdapter}
& Whitening + De-whitening (Ours) & \textbf{98.05} & \textbf{55.80} \\
& FiLM (Feature-wise Linear Modulation) & 96.85 & 52.14 \\
& Instance Normalization & 95.72 & 49.86 \\
\midrule
\multirow{3}{*}{Router Distance}
& Mahalanobis (Ours) & \textbf{98.05} & \textbf{55.80} \\
& Euclidean & 97.82 & 54.95 \\
& Cosine & 97.45 & 53.82 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{실험 목적:}
\begin{itemize}
\item DIA의 비선형 가역 변환이 선형 어댑터 대비 우수함을 검증
\item Whitening 기반 정규화가 다른 정규화 방식보다 효과적임을 확인
\item Mahalanobis 거리가 공분산을 고려하여 더 정확한 라우팅을 제공함을 입증
\end{itemize}

\subsubsection{Hyperparameter Sensitivity Analysis}

그림~\ref{fig:hyperparam}은 주요 하이퍼파라미터에 대한 민감도 분석 결과를 보여준다.

\begin{figure}[t]
\centering
% \subfigure[DIA Blocks]{\includegraphics[width=0.23\textwidth]{figures/dia_blocks.pdf}}
% \subfigure[LoRA Rank]{\includegraphics[width=0.23\textwidth]{figures/lora_rank.pdf}}
% \subfigure[Tail Weight]{\includegraphics[width=0.23\textwidth]{figures/tail_weight.pdf}}
% \subfigure[Coupling Layers]{\includegraphics[width=0.23\textwidth]{figures/coupling.pdf}}
\caption{Hyperparameter Sensitivity Analysis. (a) DIA 블록 수, (b) LoRA Rank, (c) Tail-Aware Loss 가중치, (d) Coupling Layer 수.}
\label{fig:hyperparam}
\end{figure}

\textbf{분석 항목:}

\paragraph{(a) DIA Blocks:}
\begin{itemize}
\item 범위: 2, 4, 6, 7, 8
\item 예상: 블록 수 증가 시 Image AUROC 향상, Pixel AP 하락 (trade-off)
\item 최적: 6-7 블록 (균형점)
\end{itemize}

\paragraph{(b) LoRA Rank:}
\begin{itemize}
\item 범위: 32, 64, 128, 256
\item 예상: 성능에 미미한 영향 (rank 64로 충분)
\item 의미: 파라미터 효율성 확인
\end{itemize}

\paragraph{(c) Tail-Aware Loss Weight ($\lambda$):}
\begin{itemize}
\item 범위: 0.3, 0.4, 0.5, 0.55, 0.6, 0.65
\item 예상: $\lambda$ 증가 시 Pixel AP 향상 (hard pixel에 집중)
\item 최적: 0.5-0.6
\end{itemize}

\paragraph{(d) Coupling Layers:}
\begin{itemize}
\item 범위: 8, 10, 12, 16
\item 예상: 8-12에서 안정적, 16에서 학습 불안정
\item 주의: 과도한 깊이는 gradient vanishing 유발
\end{itemize}

%==============================================================================
\subsection{Continual Learning Analysis}
\label{sec:cl_analysis}

\subsubsection{Forgetting Analysis}

그림~\ref{fig:forgetting}은 새로운 작업 학습에 따른 이전 작업 성능 변화를 보여준다.

\begin{figure}[t]
\centering
% \subfigure[Task 0 Performance Over Time]{\includegraphics[width=0.45\textwidth]{figures/forgetting_task0.pdf}}
% \subfigure[Average Forgetting by Task Distance]{\includegraphics[width=0.45\textwidth]{figures/forgetting_distance.pdf}}
\caption{Forgetting Analysis. (a) Task 0의 성능이 후속 작업 학습에 따라 변화하는 양상. (b) 작업 간 거리에 따른 평균 망각 정도.}
\label{fig:forgetting}
\end{figure}

\textbf{분석 목적:}
\begin{enumerate}
\item Parameter Isolation 전략(LoRA + DIA)이 망각 방지에 효과적임을 시각적으로 입증
\item 기존 방법(Fine-tuning, EWC)과 비교하여 망각 곡선의 안정성 확인
\item 유사한 작업(예: leather vs carpet) 간의 간섭 분석
\end{enumerate}

\textbf{예상 결과:}
\begin{itemize}
\item MoLE-Flow: 거의 수평선 (Forgetting $\approx 0$)
\item Fine-tuning: 급격한 하락
\item EWC/LwF: 완만한 하락
\end{itemize}

\subsubsection{Forward/Backward Transfer Analysis}

표~\ref{tab:transfer}는 작업 간 지식 전이 효과를 정량화한다.

\begin{table}[t]
\centering
\caption{Transfer Analysis 결과}
\label{tab:transfer}
\begin{tabular}{lccc}
\toprule
\textbf{Method} & \textbf{Avg. Acc.} & \textbf{FWT}$\uparrow$ & \textbf{BWT}$\uparrow$ \\
\midrule
Fine-tuning & 60.10 & - & -37.95 \\
EWC & 72.35 & +2.15 & -15.23 \\
LwF & 68.92 & +1.82 & -19.84 \\
DNE & 82.45 & +3.42 & -4.21 \\
\textbf{MoLE-Flow} & \textbf{98.05} & \textbf{+5.28} & \textbf{0.00} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{실험 목적:}
\begin{itemize}
\item Forward Transfer (FWT): 이전 작업 지식이 새 작업 학습을 돕는지 확인
\item Backward Transfer (BWT): 새 작업 학습이 이전 작업에 미치는 영향 (0에 가까울수록 좋음)
\end{itemize}

\subsubsection{Router Performance Analysis}

표~\ref{tab:router}는 라우터의 상세 성능을 분석한다.

\begin{table}[t]
\centering
\caption{Router Performance Analysis}
\label{tab:router}
\begin{tabular}{lcccc}
\toprule
\textbf{Task} & \textbf{Classes} & \textbf{Accuracy} & \textbf{Avg. Distance} & \textbf{Margin} \\
\midrule
Task 0 & leather, grid, transistor & 100.0\% & 2.45 & 8.72 \\
Task 1 & carpet, zipper, hazelnut & 100.0\% & 2.67 & 9.15 \\
Task 2 & toothbrush, metal\_nut, screw & 100.0\% & 3.05 & 6.42 \\
Task 3 & wood, tile, capsule & 100.0\% & 2.56 & 8.45 \\
Task 4 & pill, cable, bottle & 100.0\% & 2.78 & 7.68 \\
\midrule
\textbf{Overall} & 15 classes & \textbf{100.0\%} & 2.76 & 8.14 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{분석 항목:}
\begin{itemize}
\item \textbf{Accuracy}: 올바른 전문가 선택 비율
\item \textbf{Avg. Distance}: 선택된 전문가까지의 평균 Mahalanobis 거리 (낮을수록 확신)
\item \textbf{Margin}: 최근접 전문가와 차근접 전문가 간 거리 차이 (클수록 명확한 구분)
\end{itemize}

\subsubsection{Performance Drop by Router Accuracy}

그림~\ref{fig:router_scalability}는 Task 수가 증가함에 따른 Router 성능과 Anomaly Detection 성능의 변화를 보여준다. 이 그래프를 통해 Router가 얼마나 견고한지, 그리고 Router 오류가 전체 성능에 미치는 영향을 분석한다.

\begin{figure}[t]
\centering
% \includegraphics[width=0.48\textwidth]{figures/router_scalability.pdf}
\caption{Performance vs. Number of Tasks. X축: Task 개수 (1$\sim$15), Y축: Image AUROC. Line 1: Ideal (Task ID Given, Oracle), Line 2: MoLE-Flow (With Router). Gap이 작을수록 Router가 견고함을 의미.}
\label{fig:router_scalability}
\end{figure}

\textbf{핵심 분석:}
\begin{itemize}
\item Task 수 증가에 따른 Router Accuracy 변화 추적
\item Oracle과 Router의 Gap이 일정하게 유지되면 scalable한 설계임을 입증
\item Router confusion이 급증하는 Task 수의 임계점 식별 (있는 경우)
\end{itemize}

\subsubsection{Class Order Sensitivity}

표~\ref{tab:order}는 클래스 순서에 따른 성능 변화를 보여준다.

\begin{table}[t]
\centering
\caption{Class Order Sensitivity (5개 Random Seed)}
\label{tab:order}
\begin{tabular}{lccc}
\toprule
\textbf{Ordering} & \textbf{Img AUC} & \textbf{Routing Acc.} & \textbf{Std.} \\
\midrule
Alphabetical & 98.05 & 100.0\% & - \\
Random Seed 0 & 98.10 & 100.0\% & - \\
Random Seed 42 & 98.22 & 100.0\% & - \\
Random Seed 123 & 98.16 & 100.0\% & - \\
\midrule
\textbf{Mean $\pm$ Std} & 98.13 $\pm$ 0.07 & 100.0\% & 0.07 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{실험 목적:}
\begin{itemize}
\item 클래스 순서가 최종 성능에 미치는 영향 분석
\item Parameter Isolation이 순서 민감도를 줄이는지 확인
\item 분산이 작을수록 robust한 방법론임을 입증
\end{itemize}

%==============================================================================
\subsection{Representation Analysis}
\label{sec:representation}

\subsubsection{Router Decision Boundary Visualization}

그림~\ref{fig:router_boundary}는 TaskPrototype의 Mahalanobis decision boundary를 시각화한다. t-SNE 상에서 각 Task의 Feature Cluster가 얼마나 잘 분리되는지, 그리고 새로운 Task가 추가될 때 기존 Cluster를 침범하지 않는지 보여준다.

\begin{figure}[t]
\centering
% \subfigure[After Task 0]{\includegraphics[width=0.3\textwidth]{figures/router_task0.pdf}}
% \subfigure[After Task 7]{\includegraphics[width=0.3\textwidth]{figures/router_task7.pdf}}
% \subfigure[After Task 14]{\includegraphics[width=0.3\textwidth]{figures/router_task14.pdf}}
\caption{Router decision boundary evolution. 각 Task의 prototype (centroid)과 decision boundary (Mahalanobis ellipse)를 시각화. 색상은 Task ID를 나타냄.}
\label{fig:router_boundary}
\end{figure}

\textbf{분석 목적:}
\begin{itemize}
\item 각 Task의 feature cluster가 명확히 분리되어 있는지 확인
\item 새로운 Task 추가 시 기존 prototype이 변하지 않음을 시각적으로 입증
\item Router confusion이 발생하는 클래스 쌍 (예: leather vs carpet)을 식별
\end{itemize}

\subsubsection{Latent Space Visualization}

그림~\ref{fig:tsne}은 학습 진행에 따른 잠재 공간($\mathbf{z}$)의 변화를 t-SNE로 시각화한다.

\begin{figure}[t]
\centering
% \subfigure[Before Training]{\includegraphics[width=0.3\textwidth]{figures/tsne_before.pdf}}
% \subfigure[After Task 0]{\includegraphics[width=0.3\textwidth]{figures/tsne_task0.pdf}}
% \subfigure[After All Tasks]{\includegraphics[width=0.3\textwidth]{figures/tsne_final.pdf}}
\caption{Latent space ($\mathbf{z}$) t-SNE visualization. 색상은 작업을, 마커 모양은 정상(원)/이상(삼각형)을 구분.}
\label{fig:tsne}
\end{figure}

\textbf{분석 목적:}
\begin{enumerate}
\item 각 작업의 정상 샘플이 원점 근처에 매핑되는지 확인
\item 이상 샘플이 정상 클러스터에서 벗어나는지 확인
\item 작업 간 잠재 공간이 적절히 분리되는지 확인
\end{enumerate}

\subsubsection{Latent Distribution Stability (Forgetting Visualization)}

그림~\ref{fig:latent_stability}는 Normalizing Flow의 핵심 속성인 ``Latent가 Gaussian 분포를 따르는지''를 Task 추가에 따라 분석한다. \textbf{Task 0만 학습했을 때의 $\mathbf{z}$ 분포 vs. Task 14까지 학습한 후 Task 0 데이터의 $\mathbf{z}$ 분포 변화}를 비교하여 Forgetting 없음을 시각적으로 입증한다.

\begin{figure}[t]
\centering
% \subfigure[Task 0 (after T0)]{\includegraphics[width=0.45\textwidth]{figures/latent_dist_t0_init.pdf}}
% \subfigure[Task 0 (after T14)]{\includegraphics[width=0.45\textwidth]{figures/latent_dist_t0_final.pdf}}
\caption{Latent distribution stability for Task 0. (a) Task 0 학습 직후의 $\mathbf{z}$ 분포. (b) Task 14까지 학습 후 Task 0 데이터의 $\mathbf{z}$ 분포. 두 분포가 유사하면 Forgetting이 없음을 의미.}
\label{fig:latent_stability}
\end{figure}

\textbf{분석 포인트:}
\begin{itemize}
\item 두 분포의 KL divergence가 작을수록 Parameter Isolation 효과 입증
\item 분포의 mean, variance가 유지되는지 정량적 비교
\item Fine-tuning 방법과 비교하여 분포 붕괴(distribution collapse) 없음을 입증
\end{itemize}

\subsubsection{Distribution Quality Analysis}

표~\ref{tab:distribution}은 각 작업별 잠재 분포의 품질을 분석한다.

\begin{table}[t]
\centering
\caption{Latent Distribution Quality Analysis}
\label{tab:distribution}
\begin{tabular}{lccc}
\toprule
\textbf{Task} & $\|\mathbf{z}\|_2$ \textbf{(Normal)} & $\|\mathbf{z}\|_2$ \textbf{(Anomaly)} & \textbf{KL}$(z \| \mathcal{N}(0,I))$ \\
\midrule
leather & 1.02 & 4.85 & 0.023 \\
grid & 0.98 & 5.12 & 0.018 \\
transistor & 1.05 & 4.67 & 0.025 \\
carpet & 0.99 & 5.34 & 0.021 \\
bottle & 1.01 & 4.92 & 0.019 \\
\midrule
\textbf{Average} & 1.01 & 4.98 & 0.021 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{분석 항목:}
\begin{itemize}
\item \textbf{$\|\mathbf{z}\|_2$ (Normal)}: 정상 샘플의 평균 L2 norm (1에 가까워야 함)
\item \textbf{$\|\mathbf{z}\|_2$ (Anomaly)}: 이상 샘플의 평균 L2 norm (정상보다 커야 함)
\item \textbf{KL Divergence}: 표준 정규분포와의 거리 (낮을수록 Flow가 잘 학습됨)
\end{itemize}

%==============================================================================
\subsection{Qualitative Results}
\label{sec:qualitative}

\subsubsection{Anomaly Localization Visualization}

그림~\ref{fig:heatmap}은 다양한 결함 유형에 대한 이상 히트맵을 보여준다.

\begin{figure*}[t]
\centering
% \includegraphics[width=\textwidth]{figures/qualitative_heatmap.pdf}
\caption{Qualitative anomaly localization results. 각 행: 입력 이미지, Ground Truth, MoLE-Flow 히트맵, DNE 히트맵, UCAD 히트맵. 결함 유형: (a) Scratch (Screw), (b) Structural defect (Transistor), (c) Surface defect (Leather), (d) Texture anomaly (Carpet).}
\label{fig:heatmap}
\end{figure*}

\textbf{선정 기준:}
\begin{itemize}
\item 다양한 결함 유형 포함: 스크래치, 구조적 결함, 표면 결함, 텍스처 이상
\item 성공 사례와 도전적 사례 균형 있게 제시
\item 기존 방법과의 시각적 비교를 통한 차별점 강조
\end{itemize}

\subsubsection{Task-Aware vs. Task-Agnostic Anomaly Map Comparison}

그림~\ref{fig:task_aware_compare}는 Task ID를 알 때(Oracle)와 모를 때(Router)의 Anomaly Map 차이를 시각화한다. 이 비교를 통해 Router의 정확성이 실제 탐지 결과에 미치는 영향을 분석한다.

\begin{figure}[t]
\centering
% \includegraphics[width=0.48\textwidth]{figures/task_aware_compare.pdf}
\caption{Task-Aware vs. Task-Agnostic anomaly maps. (a) Input, (b) GT, (c) Oracle (correct task), (d) Router prediction, (e) Wrong task (worst case). Router가 올바른 전문가를 선택하면 Oracle과 거의 동일한 결과를 보임.}
\label{fig:task_aware_compare}
\end{figure}

\textbf{분석 포인트:}
\begin{itemize}
\item Router가 정확하면 (c)와 (d)가 거의 동일함
\item 잘못된 Task를 선택하면 (e)처럼 완전히 다른 결과 → Router 정확도의 중요성 입증
\item Router confusion이 발생하는 edge case 분석
\end{itemize}

\subsubsection{Component Effect Visualization}

그림~\ref{fig:component_effect}는 각 모듈이 이상 탐지에 미치는 영향을 시각화한다.

\begin{figure}[t]
\centering
% \includegraphics[width=0.48\textwidth]{figures/component_effect.pdf}
\caption{Component ablation visualization. (a) Full Model, (b) w/o DIA, (c) w/o WhiteningAdapter, (d) w/o Spatial Context.}
\label{fig:component_effect}
\end{figure}

\textbf{분석 포인트:}
\begin{itemize}
\item DIA 제거 시 복잡한 패턴의 이상 탐지 능력 저하
\item WhiteningAdapter 제거 시 분포 정렬 실패로 인한 false positive 증가
\item Spatial Context 제거 시 경계 영역 탐지 정확도 저하
\end{itemize}

\subsubsection{Failure Case Analysis}

그림~\ref{fig:failure}은 모델이 실패하는 대표적인 사례들을 분석한다.

\begin{figure}[t]
\centering
% \includegraphics[width=0.48\textwidth]{figures/failure_cases.pdf}
\caption{Failure case analysis. (a) 저대비 미세 결함 미탐지, (b) 정상 변이를 이상으로 오탐지, (c) 회전 변형에 민감한 탐지.}
\label{fig:failure}
\end{figure}

\begin{table}[t]
\centering
\caption{Failure Case 분류 및 원인 분석}
\label{tab:failure}
\begin{tabular}{lll}
\toprule
\textbf{Failure Type} & \textbf{Cause} & \textbf{Potential Solution} \\
\midrule
저대비 미세 결함 & 특징 추출 한계 & 고해상도 입력, 다중 스케일 분석 \\
정상 변이 오탐지 & 정상 분포의 다양성 부족 & 데이터 증강, 더 넓은 정상 범위 학습 \\
회전 민감성 & Positional Encoding의 고정성 & 회전 불변 특징, 증강 \\
클래스 간 유사성 & 프로토타입 중첩 & 더 강한 클래스 분리 학습 \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\subsection{Computational Efficiency}
\label{sec:efficiency}

표~\ref{tab:efficiency}는 각 방법의 계산 효율성을 비교한다.

\begin{table}[t]
\centering
\caption{Computational Efficiency 비교}
\label{tab:efficiency}
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{Params/Task} & \textbf{Train Time} & \textbf{Inference} & \textbf{Memory} \\
\midrule
Joint Training & 23.5M & 8.5h & 12ms & 4.2GB \\
Task-Separated & 23.5M $\times$ 15 & 2.1h $\times$ 15 & 12ms & 62.5GB \\
DNE & $\sim$1M & 1.5h/task & 15ms & 1.8GB \\
UCAD & $\sim$2M & 2.2h/task & 18ms & 2.4GB \\
\textbf{MoLE-Flow} & $\sim$2M & 1.8h/task & 14ms & 2.1GB \\
\bottomrule
\end{tabular}
\end{table}

\textbf{분석 포인트:}
\begin{itemize}
\item MoLE-Flow는 작업당 약 0.5M의 추가 파라미터로 가장 효율적
\item 추론 시 Router overhead가 전체 추론 시간의 1\% 미만
\item 메모리 사용량이 Task 수에 선형적으로 증가하나, 증가폭이 작음
\end{itemize}

\section{Conclusion}
\label{sec:conclusion}

본 논문에서는 산업 환경에서의 지속적 이상 탐지(Continual Anomaly Detection)를 위한 MoLE-Flow 프레임워크를 제안하였다.
핵심 기여는 다음과 같다:

\begin{enumerate}
\item \textbf{Parameter Isolation 기반 지속 학습}: Base Normalizing Flow 가중치를 공유/고정하고 작업별 경량 어댑터(LoRA, WhiteningAdapter, DIA)만 학습하는 전략을 제안하여, 파멸적 망각을 효과적으로 방지하면서도 파라미터 효율성을 확보하였다.

\item \textbf{Deep Invertible Adapter (DIA)}: 선형 LoRA의 한계를 극복하는 비선형 가역 적응 모듈을 제안하였다. DIA는 작업별 복잡한 매니폴드 차이를 보정하며, Ablation study에서 가장 중요한 구성 요소로 확인되었다 (제거 시 Image AUROC 3\%+ 하락).

\item \textbf{One-stage Task-agnostic 추론}: Mahalanobis 거리 기반 프로토타입 라우터를 통해 Task ID 없이 단일 추론으로 라우팅과 이상 탐지를 동시에 수행한다. 이는 기존 방법들의 two-stage 추론 대비 효율적이며, 100\% 라우팅 정확도로 신뢰성을 검증하였다.

\item \textbf{Tail-Aware Loss}: 분포의 경계에 위치한 어려운 패치에 집중하는 손실 함수를 제안하여, 특히 픽셀 수준의 정밀한 이상 위치 추정(Pixel AP) 성능을 향상시켰다.
\end{enumerate}

제안하는 실험 설계는 (1) 기존 Continual AD 방법(DNE, UCAD) 및 CL baseline(EWC, LwF)과의 포괄적 비교, (2) 각 모듈의 유효성을 검증하는 체계적인 Ablation Study, (3) Forgetting 분석, Router 성능 분석, Class Order Sensitivity 등 지속 학습 특성의 심층 분석, (4) 히트맵 시각화 및 실패 사례 분석을 포함한 정성적 평가로 구성된다.

\paragraph{Limitations and Future Work:}
본 연구의 한계점과 향후 연구 방향은 다음과 같다:
\begin{itemize}
\item \textbf{Cross-domain 일반화}: 현재 실험은 주로 MVTec AD에 집중되어 있으며, VisA, MPDD 등 다른 도메인에서의 성능 검증이 필요하다.
\item \textbf{더 긴 작업 시퀀스}: 15개 이상의 작업으로 확장 시 성능 변화에 대한 추가 검증이 필요하다.
\item \textbf{Few-shot 적응}: 작업당 학습 데이터가 제한된 상황에서의 성능 분석이 향후 과제이다.
\item \textbf{실시간 적용}: 산업 현장에서의 실시간 추론 성능 최적화가 필요하다.
\end{itemize}

\bibliographystyle{elsarticle-harv}
\bibliography{Reference}

\section{Appendix}

\end{document}
% \endinput
%%
%% End of file `elsarticle-template-num.tex'.
