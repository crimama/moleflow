\documentclass[aspectratio=169]{beamer}

% 테마 설정
\usetheme{Madrid}
\usecolortheme{whale}

% 패키지
\usepackage{kotex}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage{pifont}
\usepackage{multirow}
\usetikzlibrary{shapes,arrows,positioning,calc}

% 이미지 경로 설정
\graphicspath{{figures/}{figure/}}

% 수식 명령어
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

% 색상 정의
\definecolor{mainblue}{RGB}{0,82,147}
\definecolor{accentorange}{RGB}{230,126,34}
\definecolor{accentgreen}{RGB}{39,174,96}
\definecolor{lightgray}{RGB}{240,240,240}

% 프레임 번호 표시
\setbeamertemplate{footline}[frame number]

% 제목 정보
\title[MoLE-Flow]{MoLE-Flow: Mixture of LoRA Experts with \\ Normalizing Flow for Continual Anomaly Detection}
\subtitle{지속적 이상 탐지를 위한 LoRA 전문가 혼합 정규화 흐름}
\author{Hun Im, Pilsung Kang*}
\institute{Seoul National University}
\date{\today}

\begin{document}

%===============================================================================
% 제목 슬라이드
%===============================================================================

%-------------------------------------------------------------------------------
% Frame: Title Page
%-------------------------------------------------------------------------------
\begin{frame}
\titlepage
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Contents
%-------------------------------------------------------------------------------
\begin{frame}{Contents}
\tableofcontents
\end{frame}

%===============================================================================
\section{Introduction}
%===============================================================================

%-------------------------------------------------------------------------------
% Frame: Problem - Continual Anomaly Detection
%-------------------------------------------------------------------------------
\begin{frame}{Problem: Continual Anomaly Detection}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{산업 환경의 현실}
\begin{itemize}
    \item 새로운 제품이 지속적으로 추가됨
    \item 모든 데이터를 저장/재학습하기 어려움
    \item 이전 제품에 대한 성능 유지 필요
\end{itemize}

\vspace{1em}
\textbf{핵심 문제: Catastrophic Forgetting}
\begin{itemize}
    \item 새 작업 학습 시 이전 작업 성능 급감
    \item 기존 방법: 전체 모델 복제 $\rightarrow$ 메모리 비효율
\end{itemize}
\end{column}

\begin{column}{0.5\textwidth}
\centering
\begin{tikzpicture}[scale=0.8]
    % Task boxes
    \node[draw, fill=mainblue!20, minimum width=2cm, minimum height=1cm] (t0) at (0,2) {Task 0};
    \node[draw, fill=mainblue!30, minimum width=2cm, minimum height=1cm] (t1) at (0,0) {Task 1};
    \node[draw, fill=mainblue!40, minimum width=2cm, minimum height=1cm] (t2) at (0,-2) {Task 2};

    % Arrows
    \draw[->, thick] (t0) -- (t1);
    \draw[->, thick] (t1) -- (t2);

    % Performance indicator
    \node[draw, fill=red!30, minimum width=1.5cm] at (3.5,2) {100\%};
    \node[draw, fill=orange!30, minimum width=1.5cm] at (3.5,0) {70\%};
    \node[draw, fill=red!50, minimum width=1.5cm] at (3.5,-2) {40\%};

    \node at (3.5,3) {\small Task 0 성능};
\end{tikzpicture}   
\end{column}
\end{columns}
\end{frame}

%===============================================================================
\section{Previous Method}
%===============================================================================
% References:
% [ReplayCAD] Hu, Lei, et al. "ReplayCAD: Generative Diffusion Replay for Continual Anomaly Detection." arXiv preprint arXiv:2505.06603 (2025).
% [IUF] Tang, Jiaqi, et al. "An incremental unified framework for small defect inspection." ECCV 2024.
% [UCAD] Liu, Jiaqi, et al. "Unsupervised continual anomaly detection with contrastively-learned prompt." AAAI 2024.

%-------------------------------------------------------------------------------
% Frame: 기존 연구 방법
%-------------------------------------------------------------------------------
\begin{frame}{기존 연구 방법}
\begin{columns}
\begin{column}{0.33\textwidth}
\centering
\textbf{Replay 방식 (ReplayCAD)}
\vspace{0.3em}
\includegraphics[width=\textwidth]{replaycad.png}
\vspace{0.3em}
\small
이전 작업 데이터를 재사용하여 학습
\end{column}

\begin{column}{0.33\textwidth}
\centering
\textbf{Prompt 방식 (IUF)}
\vspace{0.3em}
\includegraphics[width=\textwidth]{iuf.png}
\vspace{0.3em}
\small
Class-specific 정보를 학습하기 위한 별도의 Discriminator를 사용
\end{column}

\begin{column}{0.33\textwidth}
\centering
\textbf{Adapter 방식 (UCAD)}
\vspace{0.3em}
\includegraphics[width=\textwidth]{ucad.png}
\vspace{0.3em}
\small
Class-specific 정보를 학습하기 위한 별도의 Prompt를 학습
\end{column}
\end{columns}

\vspace{1em}
\begin{alertblock}{기존 연구의 한계점}
\begin{itemize}
    \item \textbf{Replay 방식}: 오랜 학습 시간이 소요되며, replay로 인한 memory cost 존재
    \item \textbf{Adapter 방식}: Discriminator 또한 Catastrophic Forgetting 유발 가능성 있으며, 높은 학습 cost 존재
    \item \textbf{Prompt 방식}: 추론 단계에서 Task ID 인식을 위한 별도의 프로세스 필요
\end{itemize}
\end{alertblock}

\vfill
\tiny
\textcolor{gray}{[1] Hu et al., ReplayCAD, arXiv 2025 \quad [2] Tang et al., IUF, ECCV 2024 \quad [3] Liu et al., UCAD, AAAI 2024}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Our Solution - MoLE-Flow
%-------------------------------------------------------------------------------
\begin{frame}{Our Solution: MoLE-Flow}
    \begin{block}{핵심 아이디어: Parameter Isolation}
    Base 파라미터는 공유/고정하고, 경량 어댑터를 통해 만 task-specific 파라미터를 학습
    \end{block}

    \vspace{1em}
    \textbf{5가지 핵심 기여:}
    \begin{enumerate}
        \item \textcolor{mainblue}{\textbf{MoLE (Mixture of LoRA Experts)}}: NF coupling 블록에 LoRA 적용
        \item \textcolor{mainblue}{\textbf{WhiteningAdapter}}: 작업 간 분포 차이 정렬
        \item \textcolor{mainblue}{\textbf{Deep Invertible Adapter (DIA)}}: 비선형 매니폴드 적응
        \item \textcolor{mainblue}{\textbf{Prototype-based Router}}: Task ID 없이 자동 라우팅
        \item \textcolor{mainblue}{\textbf{Tail-Aware Loss}}: 분포 경계 학습 강화
    \end{enumerate}
    \end{frame}

%===============================================================================
\section{Overall Architecture}
%===============================================================================

%-------------------------------------------------------------------------------
% Frame: Overall Architecture
%-------------------------------------------------------------------------------
\begin{frame}{Overall Architecture}
\begin{center}
\includegraphics[width=0.95\textwidth]{figures/main2.png}
\end{center}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Overall Architecture - 학습 전략
%-------------------------------------------------------------------------------
\begin{frame}{Overall Architecture - 학습 전략}
\textbf{Parameter Isolation 전략:}
\begin{itemize}
    \item \textcolor{gray}{\textbf{회색 (Shared/Frozen)}}: Backbone, Base NF weights - 모든 작업이 공유
    \item \textcolor{red}{\textbf{빨간색 (Task-specific)}}: LoRA, DIA, Whitening Adapter - 작업별 독립
\end{itemize}

\vspace{1em}
\textbf{학습 전략:}
\begin{itemize}
    \item \textbf{Task 0}: Base NF + 모든 어댑터 학습 $\rightarrow$ Base 동결
    \item \textbf{Task $t > 0$}: 새로운 어댑터(LoRA, Whitening, DIA)만 학습
\end{itemize}

\vspace{1em}
\begin{alertblock}{핵심 장점}
작업당 \textbf{약 10.8\%}의 추가 파라미터만으로 완전한 작업 분리 달성
\end{alertblock}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Pipeline 수식
%-------------------------------------------------------------------------------
\begin{frame}{Pipeline 수식}
\begin{equation*}
\mathbf{x} \xrightarrow{\text{Backbone}} \mathbf{F} \xrightarrow{\text{PE}} \mathbf{F}' \xrightarrow{\text{Whitening}} \hat{\mathbf{F}} \xrightarrow{\text{SCM}} \tilde{\mathbf{F}} \xrightarrow{\text{NF+LoRA}} \mathbf{z}' \xrightarrow{\text{DIA}} (\mathbf{z}, \log|\det \mathbf{J}|)
\end{equation*}

\vspace{1em}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{공유/고정 파라미터}
\begin{itemize}
    \item Backbone (ViT-Base)
    \item Base NF weights ($\mathbf{W}_{\text{base}}$)
    \item Spatial Context Mixer
\end{itemize}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Task-specific 파라미터}
\begin{itemize}
    \item LoRA: $\mathbf{A}_t, \mathbf{B}_t$
    \item Whitening: $\gamma_t, \beta_t$
    \item DIA: 별도 flow 블록
\end{itemize}
\end{column}
\end{columns}

\vspace{1em}
\begin{alertblock}{핵심 장점}
작업당 \textbf{약 10.8\%}의 추가 파라미터만으로 완전한 작업 분리 달성
\end{alertblock}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Parameter Analysis (Backbone 제외)
%-------------------------------------------------------------------------------
\begin{frame}{Parameter Analysis (Backbone 제외)}
\textbf{Default Configuration:}
\scriptsize
\texttt{embed\_dim=512, coupling\_layers=8, lora\_rank=32, dia\_n\_blocks=4}

\vspace{0.5em}
\normalsize
\begin{columns}
\begin{column}{0.48\textwidth}
\textbf{Shared Parameters (Task 0 후 Freeze)}
\begin{table}
\scriptsize
\begin{tabular}{lr}
\toprule
\textbf{Module} & \textbf{Params} \\
\midrule
Base NF (8 subnets) & 5,255,168 \\
\quad s\_layer1 (512→512) & 2,101,248 \\
\quad s\_layer2 (512→256) & 1,050,624 \\
\quad t\_layer1 (256→512) & 1,052,672 \\
\quad t\_layer2 (512→256) & 1,050,624 \\
Context Conv (×8) & 40,968 \\
SpatialContextMixer & 5,121 \\
\midrule
\textbf{Total Shared} & \textbf{5,301,257} \\
\bottomrule
\end{tabular}
\end{table}
\end{column}

\begin{column}{0.48\textwidth}
\textbf{Per-Task Parameters (매 Task 생성)}
\begin{table}
\scriptsize
\begin{tabular}{lr}
\toprule
\textbf{Module} & \textbf{Params} \\
\midrule
LoRA Adapters (A+B) & 851,968 \\
\quad s\_layer1 LoRA & 262,144 \\
\quad s\_layer2 LoRA & 196,608 \\
\quad t\_layer1 LoRA & 196,608 \\
\quad t\_layer2 LoRA & 196,608 \\
Task Bias & 12,288 \\
WhiteningAdapter & 1,024 \\
DIA (4 blocks) & 1,579,008 \\
\midrule
\textbf{Total Per-Task} & \textbf{2,444,288} \\
\bottomrule
\end{tabular}
\end{table}
\end{column}
\end{columns}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Parameter Breakdown Visualization
%-------------------------------------------------------------------------------
\begin{frame}{Parameter Breakdown Visualization}
\begin{columns}
\begin{column}{0.55\textwidth}
\textbf{모듈별 파라미터 비중}

\vspace{0.5em}
\begin{tikzpicture}[scale=0.85]
    % Bar chart
    \draw[fill=mainblue!70] (0,0) rectangle (6.78,0.5);
    \node[right] at (6.9,0.25) {\scriptsize Base NF 67.8\%};

    \draw[fill=accentorange!70] (0,0.7) rectangle (2.04,1.2);
    \node[right] at (2.14,0.95) {\scriptsize DIA 20.4\%};

    \draw[fill=accentgreen!70] (0,1.4) rectangle (1.1,1.9);
    \node[right] at (1.2,1.65) {\scriptsize LoRA 11.0\%};

    \draw[fill=gray!50] (0,2.1) rectangle (0.05,2.6);
    \node[right] at (0.15,2.35) {\scriptsize Context/Bias $<$1\%};

    % Legend
    \draw[fill=mainblue!70] (0,3.2) rectangle (0.3,3.5);
    \node[right] at (0.4,3.35) {\scriptsize Shared (Frozen)};

    \draw[fill=accentorange!70] (3,3.2) rectangle (3.3,3.5);
    \node[right] at (3.4,3.35) {\scriptsize Per-Task};
\end{tikzpicture}
\end{column}

\begin{column}{0.42\textwidth}
\textbf{Task 수에 따른 누적 파라미터}

\begin{table}
\scriptsize
\begin{tabular}{rrc}
\toprule
\textbf{Tasks} & \textbf{Total Params} & \textbf{증가량} \\
\midrule
Task 0 & 7.75M & - \\
Task 1 & 10.19M & +2.44M \\
Task 2 & 12.63M & +2.44M \\
Task 3 & 15.08M & +2.44M \\
\midrule
\textbf{15 Tasks} & \textbf{41.97M} & - \\
\bottomrule
\end{tabular}
\end{table}

\vspace{0.5em}
\begin{alertblock}{\scriptsize Per-Task 비율}
\scriptsize
$\frac{2.44\text{M}}{7.75\text{M}} \approx \textbf{31.6\%}$ (Task 0 대비) \\
Backbone (86M) 제외 시 매우 효율적
\end{alertblock}
\end{column}
\end{columns}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Parameter Distribution (Pie Chart)
%-------------------------------------------------------------------------------
\begin{frame}{Parameter Distribution (Per-Task 기준)}
\begin{columns}
\begin{column}{0.5\textwidth}
\centering
\textbf{Per-Task 파라미터 구성}

\vspace{0.5em}
\begin{tikzpicture}[scale=1.0]
    % Pie chart for Per-Task parameters
    % DIA: 64.6%, LoRA: 34.8%, Bias: 0.5%, Whitening: 0.04%

    % DIA slice (64.6% = 232.6 degrees)
    \fill[accentorange!80] (0,0) -- (0:2) arc (0:232.6:2) -- cycle;
    \node at (116.3:1.3) {\footnotesize \textbf{DIA}};
    \node at (116.3:0.8) {\scriptsize 64.6\%};

    % LoRA slice (34.8% = 125.3 degrees)
    \fill[accentgreen!80] (0,0) -- (232.6:2) arc (232.6:357.9:2) -- cycle;
    \node at (295.3:1.3) {\footnotesize \textbf{LoRA}};
    \node at (295.3:0.8) {\scriptsize 34.8\%};

    % Task Bias + Whitening (0.6%)
    \fill[gray!60] (0,0) -- (357.9:2) arc (357.9:360:2) -- cycle;

\end{tikzpicture}

\vspace{0.3em}
\scriptsize
\textcolor{gray}{Task Bias + Whitening $<$ 1\%}
\end{column}

\begin{column}{0.5\textwidth}
\centering
\textbf{전체 모델 파라미터 구성 (Task 0)}

\vspace{0.5em}
\begin{tikzpicture}[scale=1.0]
    % Total: 7.75M
    % Base NF: 67.8% = 244.1 degrees
    % DIA: 20.4% = 73.4 degrees
    % LoRA: 11.0% = 39.6 degrees
    % Others: 0.8% = 2.9 degrees

    % Base NF (Shared)
    \fill[mainblue!80] (0,0) -- (0:2) arc (0:244.1:2) -- cycle;
    \node at (122:1.4) {\footnotesize \textbf{Base NF}};
    \node at (122:0.9) {\scriptsize 67.8\%};

    % DIA
    \fill[accentorange!80] (0,0) -- (244.1:2) arc (244.1:317.5:2) -- cycle;
    \node at (280.8:1.4) {\footnotesize \textbf{DIA}};
    \node at (280.8:0.9) {\scriptsize 20.4\%};

    % LoRA
    \fill[accentgreen!80] (0,0) -- (317.5:2) arc (317.5:357.1:2) -- cycle;
    \node at (337.3:1.5) {\footnotesize \textbf{LoRA}};

    % Others
    \fill[gray!60] (0,0) -- (357.1:2) arc (357.1:360:2) -- cycle;

\end{tikzpicture}

\vspace{0.3em}
\scriptsize
\textcolor{mainblue!80}{■} Shared (Frozen) \quad
\textcolor{accentorange!80}{■} \textcolor{accentgreen!80}{■} Per-Task
\end{column}
\end{columns}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Cumulative Parameters Graph
%-------------------------------------------------------------------------------
\begin{frame}{Task 수에 따른 누적 파라미터 증가}
\begin{center}
\begin{tikzpicture}[scale=0.75]
    % Axes
    \draw[->] (0,0) -- (12,0) node[right] {\small Tasks};
    \draw[->] (0,0) -- (0,7) node[above] {\small Parameters (M)};

    % Y-axis labels
    \foreach \y/\label in {0/0, 1.5/10, 3/20, 4.5/30, 6/40} {
        \draw (-0.1,\y) -- (0.1,\y);
        \node[left] at (-0.2,\y) {\scriptsize \label};
    }

    % X-axis labels
    \foreach \x/\label in {0.7/0, 1.4/1, 2.1/2, 2.8/3, 3.5/4, 4.2/5, 4.9/6, 5.6/7, 6.3/8, 7/9, 7.7/10, 8.4/11, 9.1/12, 9.8/13, 10.5/14} {
        \node[below] at (\x,-0.1) {\tiny \label};
    }

    % Shared base (horizontal line at 5.3M = 0.795)
    \draw[dashed, mainblue!50, thick] (0,0.795) -- (11,0.795);
    \node[left] at (-0.3,0.795) {\tiny 5.3M};

    % Per-task stacked bars
    % Task 0: 7.75M total (5.3M shared + 2.44M per-task)
    \fill[mainblue!70] (0.5,0) rectangle (0.9,0.795);
    \fill[accentorange!70] (0.5,0.795) rectangle (0.9,1.163);

    % Task 1-14: cumulative
    \foreach \t/\h in {1/1.529, 2/1.895, 3/2.261, 4/2.627, 5/2.993, 6/3.359, 7/3.725, 8/4.091, 9/4.457, 10/4.823, 11/5.189, 12/5.555, 13/5.921, 14/6.287} {
        \pgfmathsetmacro{\x}{0.5 + \t*0.7}
        \fill[mainblue!70] (\x,0) rectangle (\x+0.4,0.795);
        \fill[accentorange!70] (\x,0.795) rectangle (\x+0.4,\h);
    }

    % Labels
    \node[above] at (0.7,1.163) {\tiny 7.75M};
    \node[above] at (10.7,6.287) {\tiny 41.97M};

    % Legend
    \fill[mainblue!70] (8,6.5) rectangle (8.4,6.8);
    \node[right] at (8.5,6.65) {\scriptsize Shared (5.3M)};
    \fill[accentorange!70] (8,6) rectangle (8.4,6.3);
    \node[right] at (8.5,6.15) {\scriptsize Per-Task (+2.44M/task)};

    % Comparison line for full model duplication
    \draw[red, dashed, thick] (0.7,1.163) -- (10.7,6.287*2.1);
    \node[red, right] at (9.5,5.5) {\scriptsize Full Copy};
    \node[red, right] at (9.5,5.1) {\scriptsize (×15 = 116M)};

\end{tikzpicture}
\end{center}

\begin{alertblock}{효율성 비교}
\textbf{MoLE-Flow}: 15 Tasks에서 \textbf{41.97M} 파라미터 \\
\textbf{Full Model Copy}: 15 Tasks에서 \textbf{116.25M} 파라미터 → \textbf{64\% 절약}
\end{alertblock}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: DIA Parameter Details
%-------------------------------------------------------------------------------
\begin{frame}{DIA (Deep Invertible Adapter) Parameter Details}
\textbf{DIA 구조: 4개의 AffineCouplingBlock}

\vspace{0.5em}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{AffineCouplingBlock 구성}
\begin{itemize}
    \item \texttt{split\_dim = 512 / 2 = 256}
    \item \texttt{hidden\_dim = 512 × 0.5 = 256}
\end{itemize}

\vspace{0.5em}
\textbf{SimpleSubnet (s\_net, t\_net)}
\begin{itemize}
    \item Linear(256 → 256): 65,792
    \item Linear(256 → 256): 65,792
    \item Linear(256 → 256): 65,792
    \item \textbf{Subnet Total}: 197,376
\end{itemize}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{파라미터 계산}
\begin{table}
\scriptsize
\begin{tabular}{lr}
\toprule
\textbf{Component} & \textbf{Params} \\
\midrule
s\_net (per block) & 197,376 \\
t\_net (per block) & 197,376 \\
\midrule
\textbf{Block Total} & 394,752 \\
\midrule
\textbf{4 Blocks Total} & \textbf{1,579,008} \\
\bottomrule
\end{tabular}
\end{table}

\vspace{0.5em}
\begin{block}{\scriptsize DIA의 역할}
\scriptsize
비선형 매니폴드 적응으로 \\
LoRA가 표현 못하는 복잡한 분포 변환 학습
\end{block}
\end{column}
\end{columns}
\end{frame}

%===============================================================================
\section{Feature Extraction}
%===============================================================================

%-------------------------------------------------------------------------------
% Frame: Feature Extraction & Preprocessing
%-------------------------------------------------------------------------------
\begin{frame}{Feature Extraction \& Preprocessing}
\begin{columns}
\begin{column}{0.6\textwidth}
\textbf{1. Backbone (ViT-Base)}
\begin{itemize}
    \item 사전 학습된 ViT 사용 (Frozen)
    \item 다중 스케일 특징: 블록 $\{1, 3, 5, 11\}$
\end{itemize}

\vspace{0.5em}
\textbf{2. Patch Maker}
\begin{itemize}
    \item Feature Map을 패치 단위로 분할
    \item 출력: $\mathbf{F} \in \mathbb{R}^{B \times H \times W \times D}$
    \item PatchCore의 방식과 동일하게 패치 단위로 분할하여 패치 임베딩을 생성
\end{itemize}

\vspace{0.5em}
\textbf{3. Positional Encoding}
\begin{itemize}
    \item NF의 순열 불변성 극복
    \item 2D Sinusoidal PE 추가
\end{itemize}
\begin{equation*}
\mathbf{F}' = \mathbf{F} + \mathbf{P}
\end{equation*}
\end{column}

\begin{column}{0.4\textwidth}
\centering
\begin{tikzpicture}[scale=0.7]
    % Image grid
    \draw[step=0.5cm, gray, thin] (0,0) grid (3,3);
    \node at (1.5,-0.5) {\small Input Image};

    % Arrow
    \draw[->, thick] (3.3,1.5) -- (4,1.5);

    % Patch embeddings
    \foreach \y in {0,0.5,1,1.5,2,2.5} {
        \draw[fill=mainblue!30] (4.2,\y) rectangle (5.5,\y+0.4);
    }
    \node at (4.85,-0.5) {\small Patches};

    % Arrow
    \draw[->, thick] (5.7,1.5) -- (6.4,1.5);

    % PE added
    \foreach \y in {0,0.5,1,1.5,2,2.5} {
        \draw[fill=accentgreen!30] (6.6,\y) rectangle (7.9,\y+0.4);
    }
    \node at (7.25,-0.5) {\small +PE};
\end{tikzpicture}
\end{column}
\end{columns}
\end{frame}

%===============================================================================
\section{Task Adapters}
%===============================================================================

%-------------------------------------------------------------------------------
% Frame: Task Adapters - Whitening
%-------------------------------------------------------------------------------
\begin{frame}{Task Adapters: WhiteningAdapter}
\textbf{\textcolor{red}{문제}: 클래스별 이미지 분포 차이}
\begin{itemize}
    \item 클래스별로 다른 이미지 통계량 $\rightarrow$ NF 학습 불안정
    \item Task 전환 시 급격한 입력 분포 변화
\end{itemize}

\vspace{0.3em}
\textbf{\textcolor{accentgreen}{해결}: 2단계 Whitening 전략}

\vspace{0.3em}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{Step 1: Task-Agnostic Whitening}
\begin{equation*}
\mathbf{x}_{\text{white}} = \frac{\mathbf{F}' - \mathbb{E}[\mathbf{F}']}{\sqrt{\text{Var}[\mathbf{F}'] + \epsilon}}
\end{equation*}
\begin{itemize}
    \item 모든 Task를 \textbf{동일한 시작점}으로
    \item LayerNorm 기반 (학습 파라미터 없음)
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{Step 2: Task-Specific De-whitening}
\begin{equation*}
\hat{\mathbf{F}}_t = \gamma_t \odot \mathbf{x}_{\text{white}} + \beta_t
\end{equation*}
\begin{itemize}
    \item $\gamma_t \in [0.5, 2.0]$ (sigmoid)
    \item $\beta_t \in [-2.0, 2.0]$ (tanh)
    \item \textbf{범위 제한}으로 안정성 확보
\end{itemize}
\end{column}
\end{columns}

\vspace{0.3em}
\begin{alertblock}{\textcolor{mainblue}{효과}: wo\_Adapter 시 두 번째로 큰 성능 하락}
Image AUC \textcolor{red}{\textbf{-1.89\%}} (0.9793 $\rightarrow$ 0.9604), Pixel AP \textcolor{red}{-2.74\%}
\end{alertblock}
\end{frame}

%===============================================================================
\section{MoLE-Flow}
%===============================================================================

%-------------------------------------------------------------------------------
% Frame: Development Journey - Overview
%-------------------------------------------------------------------------------
\begin{frame}{Development Journey: 78개 실험에서 최적화까지}
\begin{block}{실험 규모}
\textbf{78개 이상의 실험}을 수행하여 최적의 하이퍼파라미터 조합 탐색
\end{block}

\vspace{0.5em}
\textbf{Baseline에서 최적 설정까지의 개선 과정:}

\begin{center}
\begin{tikzpicture}[scale=0.75]
    % Baseline
    \node[draw, fill=red!20, minimum width=2.2cm, minimum height=0.7cm, font=\scriptsize] (b) at (0,0) {Baseline};
    \node[below=0.05cm of b, font=\tiny] {Pixel AP: 0.4640};

    % +LogdetReg
    \node[draw, fill=orange!20, minimum width=2.2cm, minimum height=0.7cm, font=\scriptsize] (l) at (3.2,0) {+LogdetReg};
    \node[below=0.05cm of l, font=\tiny] {\textcolor{accentgreen}{+4.15\%}};

    % +TopK5+TailW
    \node[draw, fill=yellow!30, minimum width=2.2cm, minimum height=0.7cm, font=\scriptsize] (t) at (6.4,0) {+TopK+TailW};
    \node[below=0.05cm of t, font=\tiny] {\textcolor{accentgreen}{+5.81\%}};

    % +ScaleCtxK5
    \node[draw, fill=accentgreen!20, minimum width=2.2cm, minimum height=0.7cm, font=\scriptsize] (s) at (9.6,0) {+ScaleCtxK5};
    \node[below=0.05cm of s, font=\tiny] {\textcolor{accentgreen}{+6.77\%}};

    % Final
    \node[draw, fill=accentgreen!50, minimum width=2.2cm, minimum height=0.7cm, font=\scriptsize] (f) at (12.8,0) {\textbf{Final}};
    \node[below=0.05cm of f, font=\tiny] {\textbf{0.5350 (+7.10\%)}};

    % Arrows
    \draw[->, thick] (b) -- (l);
    \draw[->, thick] (l) -- (t);
    \draw[->, thick] (t) -- (s);
    \draw[->, thick] (s) -- (f);
\end{tikzpicture}
\end{center}

\vspace{0.5em}
\begin{alertblock}{핵심 발견}
각 모듈이 특정 문제를 해결하기 위해 도입됨 $\rightarrow$ 문제-해결-효과 구조로 설명
\end{alertblock}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: MoLE-Flow - Spatial Context Mixer
%-------------------------------------------------------------------------------
\begin{frame}{MoLE-Flow: Spatial Context Mixer}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\centering
\includegraphics[width=\textwidth]{spatial_context_mixer.png}
\end{column}

\begin{column}{0.42\textwidth}
\textbf{\textcolor{red}{문제}: 패치 독립 처리의 한계}
\begin{itemize}
    \item 기존 NF: 각 패치 독립 처리
    \item 주변 맥락 정보 부족
    \item 결함 경계 인식 어려움
\end{itemize}

\vspace{0.3em}
\textbf{\textcolor{accentgreen}{해결}: Spatial Context Mixer}
\begin{equation*}
\mathbf{x}_{\text{mixed}} = (1-g) \cdot \mathbf{x} + g \cdot \mathbf{x}_{\text{ctx}}
\end{equation*}

\vspace{0.2em}
\small
\begin{itemize}
    \item $\mathbf{x}_{\text{ctx}}$: DepthwiseConv$_{3\times3}$
    \item $g = \sigma(\theta)$: 학습 가능 게이트
\end{itemize}

\vspace{0.3em}
\textbf{\textcolor{mainblue}{효과}}: wo\_SpatialCtx 시 Pixel AP \textcolor{red}{-0.76\%}
\end{column}
\end{columns}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: MoLE-Flow - LoRA-based Coupling Layer
%-------------------------------------------------------------------------------
\begin{frame}{MoLE-Flow: LoRA-based Coupling Layer}
\textbf{\textcolor{red}{문제}: 전체 모델 Fine-tuning의 한계}
\begin{itemize}
    \item 전체 파라미터 학습 $\rightarrow$ \textbf{Catastrophic Forgetting} 발생
    \item Task별 별도 모델 저장 $\rightarrow$ 메모리 비효율
\end{itemize}

\vspace{0.5em}
\begin{center}
\includegraphics[width=0.75\textwidth]{Molesubnet.png}
\end{center}

\vspace{0.3em}
\textbf{\textcolor{accentgreen}{해결}: LoRA (Low-Rank Adaptation)}
\begin{equation*}
\mathbf{h}(\mathbf{x}) = \underbrace{\mathbf{W}_{\text{base}}\mathbf{x}}_{\text{Base (Frozen)}} + \underbrace{\frac{\alpha}{r}(\mathbf{B}\mathbf{A})\mathbf{x}}_{\text{LoRA (Task-specific)}} + (\mathbf{b}_{\text{base}} + \mathbf{b}_t)
\end{equation*}

\textbf{\textcolor{mainblue}{효과}}: Task당 \textbf{약 2.1M} 파라미터 ($\sim$11\% of total)
\end{frame}

%-------------------------------------------------------------------------------
% Frame: MoLE-Flow - LoRA-based Coupling Layer (상세)
%-------------------------------------------------------------------------------
\begin{frame}{MoLE-Flow: LoRA-based Coupling Layer (상세)}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Base Linear (Frozen Anchor)}
\begin{itemize}
    \item Task 0에서 학습 후 \textbf{영구 고정}
    \item 범용적인 특징 변환 역할
    \item 모든 작업이 공유
\end{itemize}

\vspace{0.5em}
\textbf{LoRA Rank 민감도 분석:}
\begin{table}
\scriptsize
\begin{tabular}{ccc}
\toprule
Rank & Image AUC & Pixel AP \\
\midrule
32 & 0.9794 & 0.4737 \\
64 & 0.9793 & 0.4735 \\
128 & 0.9794 & 0.4736 \\
\bottomrule
\end{tabular}
\end{table}
\small $\rightarrow$ Rank 64로 충분
\end{column}

\begin{column}{0.5\textwidth}
\textbf{LoRA Linear (Task-Specialist)}
\begin{itemize}
    \item 작업 고유 분포 특성 보정
    \item 저랭크 행렬 ($r=64$)
    \item 작업마다 새로운 $\mathbf{A}, \mathbf{B}$ 생성
\end{itemize}

\vspace{0.5em}
\textbf{초기화 전략:}
\begin{itemize}
    \item $\mathbf{A}$: Xavier uniform
    \item $\mathbf{B}$: Zero $\rightarrow$ $\Delta\mathbf{W}=0$ at start
\end{itemize}
\end{column}
\end{columns}

\vspace{0.5em}
\begin{alertblock}{파라미터 효율성}
전체 대비 \textbf{약 11\%}의 파라미터만으로 효과적인 작업 적응, Forgetting $\approx$ 0
\end{alertblock}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: MoLE-Flow - Context-Aware s/t Networks
%-------------------------------------------------------------------------------
\begin{frame}{MoLE-Flow: Scale Context (s-network only)}
\textbf{\textcolor{red}{문제}: s-network가 anomaly 판단에 주변 정보 필요}
\begin{itemize}
    \item 이상치의 ``크기''는 주변 패치와의 비교에 의존
    \item t-network는 위치 이동만 담당 $\rightarrow$ context 불필요
\end{itemize}

\vspace{0.5em}
\textbf{\textcolor{accentgreen}{해결}: s-network에만 Context 입력}

\vspace{0.5em}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Scale Network (Context-Aware)}
\begin{equation*}
\mathbf{s} = f_s([\mathbf{x}; \mathbf{ctx}_{K \times K}])
\end{equation*}
\begin{itemize}
    \item 원본 + $K \times K$ 문맥 정보 결합
    \item \textbf{K=5가 최적} (실험 결과)
\end{itemize}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Translation Network (Context-Free)}
\begin{equation*}
\mathbf{t} = f_t(\mathbf{x})
\end{equation*}
\begin{itemize}
    \item 원본 특징만 사용
    \item 분포 중심은 패치 고유 특성에 종속
\end{itemize}
\end{column}
\end{columns}

\vspace{0.5em}
\begin{alertblock}{\textcolor{mainblue}{효과}: Scale Context K=5}
wo\_ScaleCtx 시 Pixel AP \textcolor{red}{-0.41\%}, Image AUC \textcolor{red}{-0.18\%}
\end{alertblock}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: MoLE-Flow - Deep Invertible Adapter (DIA)
%-------------------------------------------------------------------------------
\begin{frame}{MoLE-Flow: Deep Invertible Adapter (DIA)}
\textbf{\textcolor{red}{문제}: 선형 LoRA의 표현력 한계}
\begin{itemize}
    \item LoRA: $\mathbf{W} + \mathbf{BA}$ $\rightarrow$ 선형 변환
    \item WhiteningAdapter: $\gamma \cdot \mathbf{x} + \beta$ $\rightarrow$ 선형 변환
    \item 복잡한 \textbf{비선형 분포 차이} 보상 어려움
\end{itemize}

\vspace{0.5em}
\textbf{\textcolor{accentgreen}{해결}: DIA (Deep Invertible Adapter)}
\begin{equation*}
\mathbf{z}_{\text{final}} = f_{\text{DIA}}^{(t)}(\mathbf{z}_{\text{base}}), \quad \text{with } \log|\det \mathbf{J}_{\text{DIA}}|
\end{equation*}

\vspace{0.3em}
\begin{columns}
\begin{column}{0.55\textwidth}
\textbf{DIA 구조:}
\begin{itemize}
    \item 4개의 AffineCouplingBlock
    \item Task별 독립 파라미터 (1.58M/task)
    \item Near-identity 초기화
\end{itemize}
\end{column}
\begin{column}{0.42\textwidth}
\textbf{Trade-off 발견:}
\begin{table}
\scriptsize
\begin{tabular}{ccc}
\toprule
DIA & ImgAUC & PixAP \\
\midrule
4 & 0.979 & \textbf{0.474} \\
6 & 0.982 & 0.461 \\
8 & \textbf{0.983} & 0.455 \\
\bottomrule
\end{tabular}
\end{table}
\end{column}
\end{columns}

\vspace{0.3em}
\begin{alertblock}{\textcolor{mainblue}{효과}: wo\_DIA 시 \textbf{가장 큰 성능 하락}}
Image AUC \textcolor{red}{\textbf{-3.14\%}} (0.9793 $\rightarrow$ 0.9479), Pixel AP \textcolor{red}{-1.49\%}
\end{alertblock}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Key Insights from Optimization
%-------------------------------------------------------------------------------
\begin{frame}{Key Insights from Optimization (78개 실험 분석)}
\textbf{각 하이퍼파라미터의 개별 효과 (vs Baseline 0.4640):}

\begin{table}
\centering
\scriptsize
\begin{tabular}{lccc}
\toprule
\textbf{Component} & \textbf{Pixel AP} & \textbf{Delta} & \textbf{Impact} \\
\midrule
\textcolor{red}{\textbf{LogdetReg 1e-4}} & 0.5055 & \textcolor{red}{\textbf{+4.15\%}} & \ding{72}\ding{72}\ding{72}\ding{72}\ding{72} \\
ScaleCtxK5 & 0.4870 & +2.30\% & \ding{72}\ding{72}\ding{72}\ding{72} \\
TopK5-TailW0.5 & 0.4866 & +2.26\% & \ding{72}\ding{72}\ding{72}\ding{72} \\
lr 3e-4 & 0.4718 & +0.78\% & \ding{72}\ding{72} \\
DIA6 & 0.4606 & -0.34\% & \ding{72} \\
\bottomrule
\end{tabular}
\end{table}

\vspace{0.5em}
\begin{columns}
\begin{column}{0.48\textwidth}
\textbf{핵심 발견:}
\begin{enumerate}
    \item \textbf{LogdetReg 1e-4}: 단일 최대 개선 효과
    \item \textbf{TailW 0.75-0.8}: Pixel AP 최적
    \item \textbf{Coupling 16}: 불안정 $\rightarrow$ 8-12 권장
\end{enumerate}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{Warning:}
\begin{itemize}
    \item Coupling16: Image AUC 0.73으로 급락
    \item DIA $>$ 6: Image AUC $\uparrow$, Pixel AP $\downarrow$
\end{itemize}
\end{column}
\end{columns}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Trade-offs Discovered
%-------------------------------------------------------------------------------
\begin{frame}{Trade-offs Discovered}
\textbf{실험을 통해 발견된 핵심 Trade-off:}

\vspace{0.5em}
\begin{columns}
\begin{column}{0.48\textwidth}
\textbf{1. DIA Blocks}
\begin{table}
\scriptsize
\begin{tabular}{ccc}
\toprule
Blocks & Image AUC & Pixel AP \\
\midrule
4 & 0.9793 & \textbf{0.4735} \\
6 & 0.9820 & 0.4606 \\
8 & \textbf{0.9825} & 0.4546 \\
\bottomrule
\end{tabular}
\end{table}
$\uparrow$ DIA $\rightarrow$ $\uparrow$ Image AUC, $\downarrow$ Pixel AP
\end{column}

\begin{column}{0.48\textwidth}
\textbf{2. TailWeight}
\begin{table}
\scriptsize
\begin{tabular}{ccc}
\toprule
TailW & Image AUC & Pixel AP \\
\midrule
0.50 & \textbf{0.983} & 0.5221 \\
0.65 & 0.983 & 0.5324 \\
0.80 & 0.981 & \textbf{0.5447} \\
\bottomrule
\end{tabular}
\end{table}
$\uparrow$ TailW $\rightarrow$ $\uparrow$ Pixel AP, $\downarrow$ Image AUC
\end{column}
\end{columns}

\vspace{0.5em}
\begin{alertblock}{최적 균형점}
\textbf{권장 설정}: DIA=4, TailW=0.55, TopK=5, LogdetReg=1e-4, ScaleCtxK=5 \\
$\rightarrow$ Image AUC \textbf{0.9824}, Pixel AP \textbf{0.5350}
\end{alertblock}
\end{frame}

%===============================================================================
\section{Training \& Inference}
%===============================================================================

%-------------------------------------------------------------------------------
% Frame: Training Objective - Likelihood Calculation
%-------------------------------------------------------------------------------
\begin{frame}{Training Objective: Likelihood Calculation}
\textbf{Normalizing Flow의 핵심: 변수 변환}
\begin{equation*}
\log p(\mathbf{x}) = \log p(\mathbf{z}_{\text{final}}) + \log|\det \mathbf{J}_{\text{total}}|
\end{equation*}

\vspace{1em}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{잠재 확률}
\begin{equation*}
\log p(\mathbf{z}) = -\frac{1}{2}\|\mathbf{z}\|_2^2 - \frac{D}{2}\log(2\pi)
\end{equation*}
\begin{itemize}
    \item 표준 정규분포 가정
    \item 원점에 가까울수록 높은 확률
\end{itemize}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Jacobian 누적}
\begin{equation*}
\log|\det \mathbf{J}_{\text{total}}| = \log|\det \mathbf{J}_{\text{flow}}| + \log|\det \mathbf{J}_{\text{DIA}}|
\end{equation*}
\begin{itemize}
    \item 각 변환의 부피 변화율
    \item 밀도 보정 역할
\end{itemize}
\end{column}
\end{columns}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Training Objective - Tail-Aware Loss
%-------------------------------------------------------------------------------
\begin{frame}{Training Objective: Tail-Aware Loss}
\textbf{\textcolor{red}{문제}: 일반 NLL의 한계}
\begin{itemize}
    \item 모든 패치의 평균 NLL 최소화
    \item ``쉬운'' 정상 패치에만 집중 $\rightarrow$ \textbf{경계 학습 부족}
    \item 정상/이상 경계의 ``어려운'' 패치 무시
\end{itemize}

\vspace{0.5em}
\textbf{\textcolor{accentgreen}{해결}: Tail-Aware Loss}
\begin{equation*}
\mathcal{L}_{\text{train}} = (1 - \lambda) \cdot \mathbb{E}[\mathcal{L}_{\text{all}}] + \lambda \cdot \mathbb{E}[\mathcal{L}_{\text{top-k}}]
\end{equation*}

\begin{columns}
\begin{column}{0.5\textwidth}
\begin{itemize}
    \item $\mathcal{L}_{\text{top-k}}$: 상위 5\% 고손실 패치
    \item ``어려운'' 패치에 추가 집중
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{TailW 최적화 실험:}
\begin{table}
\scriptsize
\begin{tabular}{ccc}
\toprule
TailW & ImgAUC & PixAP \\
\midrule
0.50 & 0.983 & 0.5221 \\
0.55 & 0.983 & 0.5256 \\
\textbf{0.75} & 0.981 & \textbf{0.5449} \\
\bottomrule
\end{tabular}
\end{table}
\end{column}
\end{columns}

\vspace{0.3em}
\begin{alertblock}{\textcolor{mainblue}{효과}: Pixel AP +3$\sim$5\% 개선}
TailW 증가 $\rightarrow$ Pixel AP 향상, Image AUC 약간 하락 (Trade-off 존재)
\end{alertblock}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Training Objective - LogDet Regularization
%-------------------------------------------------------------------------------
\begin{frame}{Training Objective: LogDet Regularization}
\textbf{\textcolor{red}{문제}: Jacobian 불안정성}
\begin{itemize}
    \item NF의 log-determinant가 불안정하면 density estimation 품질 저하
    \item 특히 deep NF에서 Jacobian explosion/vanishing 문제 발생
\end{itemize}

\vspace{0.5em}
\textbf{\textcolor{accentgreen}{해결}: LogDet Regularization}
\begin{equation*}
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{NLL}} + \lambda_{\text{logdet}} \cdot |\log|\det \mathbf{J}||
\end{equation*}

\vspace{0.5em}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{LogdetReg 효과 분석:}
\begin{table}
\scriptsize
\begin{tabular}{cc}
\toprule
$\lambda_{\text{logdet}}$ & Pixel AP \\
\midrule
0 (baseline) & 0.4640 \\
1e-6 & 0.4700 \\
\textbf{1e-4} & \textbf{0.5055} \\
\bottomrule
\end{tabular}
\end{table}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{역할:}
\begin{itemize}
    \item Jacobian을 안정적 범위로 유지
    \item Volume-preserving 변환 유도
    \item 학습 안정성 향상
\end{itemize}
\end{column}
\end{columns}

\vspace{0.3em}
\begin{alertblock}{\textcolor{mainblue}{효과}: 단일 최대 개선 효과 \textbf{+4.15\%}}
LogdetReg 1e-4가 모든 하이퍼파라미터 중 가장 큰 Pixel AP 개선 효과
\end{alertblock}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Inference - Task Routing
%-------------------------------------------------------------------------------
\begin{frame}{Inference: Task Routing}
\textbf{핵심 문제: 추론 시 Task ID가 주어지지 않음}

\vspace{1em}
\textbf{해결: Prototype-based Mahalanobis Router}
\begin{equation*}
t^* = \argmin_t D_M(\mathbf{f}, t), \quad D_M(\mathbf{f}, t) = \sqrt{(\mathbf{f} - \boldsymbol{\mu}_t)^\top \boldsymbol{\Sigma}_t^{-1} (\mathbf{f} - \boldsymbol{\mu}_t)}
\end{equation*}

\vspace{0.5em}
\textbf{장점:}
\begin{itemize}
    \item \textbf{One-stage}: 별도의 라우팅 추론 불필요
    \item \textbf{공분산 고려}: 분포 형태를 반영한 거리 측정
    \item \textbf{스케일 불변}: 특징 차원 간 스케일 차이 자동 보정
\end{itemize}

\begin{alertblock}{기존 방법 대비 장점}
기존: Two-stage (라우팅 $\rightarrow$ 탐지) \\
Ours: \textbf{One-stage} (라우팅 + 탐지 동시)
\end{alertblock}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Inference - Anomaly Scoring
%-------------------------------------------------------------------------------
\begin{frame}{Inference: Anomaly Scoring}
\textbf{Step 1: Patch-wise Scoring}
\begin{equation*}
\text{Score}_{(h,w)} = \underbrace{\frac{1}{2}\|\mathbf{z}_{(h,w)}\|^2}_{\text{Distance Score}} \underbrace{- \log|\det \mathbf{J}|_{(h,w)}}_{\text{Distortion Score}}
\end{equation*}

\vspace{0.5em}
\textbf{Step 2: Top-K Mean Aggregation}
\begin{equation*}
\text{Final Score} = \frac{1}{K} \sum_{i=1}^{K} S_{\text{top}}^{(i)}
\end{equation*}

\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{vs Max}
\begin{itemize}
    \item 단일 노이즈에 의한 오탐 방지
\end{itemize}
\end{column}
\begin{column}{0.5\textwidth}
\textbf{vs Mean}
\begin{itemize}
    \item 이상 신호 희석 방지
    \item 결함은 보통 군집 형성
\end{itemize}
\end{column}
\end{columns}
\end{frame}

%===============================================================================
\section{Experiments Part 1: Hyperparameter Optimization}
%===============================================================================

%-------------------------------------------------------------------------------
% Frame: Hyperparameter Optimization Overview
%-------------------------------------------------------------------------------
\begin{frame}{Hyperparameter Optimization Overview}
\begin{block}{실험 규모}
\textbf{78개 이상의 실험}을 수행하여 최적의 하이퍼파라미터 조합 탐색
\end{block}

\vspace{1em}
\textbf{Baseline 성능 (MVTec AD, WRN50-80ep):}
\begin{table}
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{Baseline} & \textbf{Target} \\
\midrule
Image AUC & 0.9796 & $\geq$ 0.98 \\
Pixel AP & 0.4640 & 0.54 - 0.60 \\
Routing Acc. & 100\% & 100\% \\
\bottomrule
\end{tabular}
\end{table}

\vspace{0.5em}
\textbf{최종 달성:}
\begin{itemize}
    \item \textcolor{accentgreen}{\textbf{Pixel AP: 0.5350}} (+15.3\% 개선)
    \item \textcolor{accentgreen}{\textbf{Image AUC: 0.9824}} (유지/향상)
\end{itemize}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Individual Component Effects
%-------------------------------------------------------------------------------
\begin{frame}{Individual Component Effects}
\textbf{각 하이퍼파라미터의 개별 효과 (vs Baseline 0.4640):}

\begin{table}
\centering
\scriptsize
\begin{tabular}{lccc}
\toprule
\textbf{Component} & \textbf{Pixel AP} & \textbf{Delta} & \textbf{Impact} \\
\midrule
\textcolor{red}{\textbf{LogdetReg 1e-4}} & 0.5055 & \textcolor{red}{\textbf{+4.15\%}} & \ding{72}\ding{72}\ding{72}\ding{72}\ding{72} \\
ScaleCtxK5 & 0.4870 & +2.30\% & \ding{72}\ding{72}\ding{72}\ding{72} \\
TopK5-TailW0.5 & 0.4866 & +2.26\% & \ding{72}\ding{72}\ding{72}\ding{72} \\
lr 3e-4 & 0.4718 & +0.78\% & \ding{72}\ding{72} \\
DIA6 & 0.4606 & -0.34\% & \ding{72} \\
\bottomrule
\end{tabular}
\end{table}

\vspace{1em}
\begin{alertblock}{핵심 발견}
\textbf{Log-determinant Regularization (1e-4)}이 \textbf{단일 최대 개선 효과} (+4.15\%)
\end{alertblock}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Tail Weight Effect Analysis
%-------------------------------------------------------------------------------
\begin{frame}{Tail Weight Effect Analysis}
\textbf{TailWeight: 어려운 패치에 집중하는 정도}

\begin{table}
\centering
\begin{tabular}{cccc}
\toprule
\textbf{TailW} & \textbf{Pixel AP} & \textbf{Image AUC} & \textbf{최적 TailTopK} \\
\midrule
0.50 & 0.5221 & 0.983 & 5\% \\
0.55 & 0.5256 & 0.983 & 5\% \\
0.60 & 0.5290 & 0.983 & 3\% \\
0.65 & 0.5324 & 0.983 & 1\% \\
\textcolor{accentgreen}{\textbf{0.75}} & \textcolor{accentgreen}{\textbf{0.5449}} & 0.981 & 2\% \\
0.80 & 0.5447 & 0.981 & 3\% \\
\bottomrule
\end{tabular}
\end{table}

\vspace{0.5em}
\textbf{Trade-off 발견:}
\begin{itemize}
    \item TailW 증가 $\rightarrow$ Pixel AP 향상
    \item TailW $>$ 0.75 $\rightarrow$ Image AUC 약간 하락 (0.983 $\rightarrow$ 0.981)
\end{itemize}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Optimization Journey
%-------------------------------------------------------------------------------
\begin{frame}{Optimization Journey}
\textbf{Baseline에서 최적 설정까지의 개선 과정:}

\begin{center}
\begin{tikzpicture}[scale=0.9]
    % Baseline
    \node[draw, fill=red!20, minimum width=2.5cm, minimum height=0.8cm] (b) at (0,0) {Baseline};
    \node[below=0.1cm of b] {\scriptsize 0.4640};

    % +LogdetReg
    \node[draw, fill=orange!20, minimum width=2.5cm, minimum height=0.8cm] (l) at (3.5,0) {+LogdetReg};
    \node[below=0.1cm of l] {\scriptsize 0.5055 (+4.15\%)};

    % +TopK5+TailW
    \node[draw, fill=yellow!30, minimum width=2.5cm, minimum height=0.8cm] (t) at (7,0) {+TopK5+TailW};
    \node[below=0.1cm of t] {\scriptsize 0.5221 (+5.81\%)};

    % +ScaleCtxK5
    \node[draw, fill=accentgreen!20, minimum width=2.5cm, minimum height=0.8cm] (s) at (10.5,0) {+ScaleCtxK5};
    \node[below=0.1cm of s] {\scriptsize 0.5317 (+6.77\%)};

    % Final
    \node[draw, fill=accentgreen!50, minimum width=2.5cm, minimum height=0.8cm] (f) at (14,0) {\textbf{Final}};
    \node[below=0.1cm of f] {\scriptsize \textbf{0.5350 (+7.10\%)}};

    % Arrows
    \draw[->, thick] (b) -- (l);
    \draw[->, thick] (l) -- (t);
    \draw[->, thick] (t) -- (s);
    \draw[->, thick] (s) -- (f);
\end{tikzpicture}
\end{center}

\vspace{1em}
\textbf{최적 설정:}
\begin{itemize}
    \item \texttt{TailW=0.55, TopK=5, LogdetReg=1e-4, ScaleCtxK=5, lr=3e-4}
\end{itemize}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Top 10 Experiments by Pixel AP
%-------------------------------------------------------------------------------
\begin{frame}{Top 10 Experiments by Pixel AP}
\begin{table}
\centering
\scriptsize
\begin{tabular}{clccc}
\toprule
\textbf{Rank} & \textbf{Configuration} & \textbf{Image AUC} & \textbf{Pixel AP} & \textbf{Routing} \\
\midrule
1 & TailW0.55-TopK5-LogdetReg1e-4-ScaleCtxK5-lr3e-4 & 0.9824 & \textbf{0.5350} & 100\% \\
2 & TailW0.65-TailTopK3-TopK5-LogdetReg1e-4 & 0.9827 & 0.5324 & 100\% \\
3 & TopK3-TailW0.5-LogdetReg1e-4-ScaleCtxK5 & 0.9802 & 0.5317 & 100\% \\
4 & TopK5-TailW0.5-LogdetReg1e-4-ScaleCtxK5 & 0.9809 & 0.5317 & 100\% \\
5 & TailW0.6-TailTopK3-TopK5-LogdetReg1e-4-ScaleCtxK5-80ep & 0.9826 & 0.5310 & 100\% \\
6 & TailW0.6-TopK5-LogdetReg1e-4 & 0.9827 & 0.5290 & 100\% \\
7 & TailW0.55-TopK5-LogdetReg1e-4 & 0.9827 & 0.5256 & 100\% \\
8 & TailW0.5-TailTopK3-TopK5-LogdetReg1e-4 & 0.9830 & 0.5242 & 100\% \\
9 & FullBest-80ep-lr3e-4-LoRA128-C10-DIA5-TailW0.55 & \textbf{0.9836} & 0.5242 & 100\% \\
10 & TopK5-TailW0.5-LogdetReg1e-4 & 0.9826 & 0.5221 & 100\% \\
\bottomrule
\end{tabular}
\end{table}

\vspace{0.5em}
\textbf{Observation:} 모든 상위 설정에서 \textbf{Routing Accuracy 100\%} 유지
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Per-Class Performance Improvement
%-------------------------------------------------------------------------------
\begin{frame}{Per-Class Performance Improvement}
\begin{table}
\centering
\scriptsize
\begin{tabular}{lccc}
\toprule
\textbf{Class} & \textbf{Baseline} & \textbf{Top Config} & \textbf{Improvement} \\
\midrule
carpet & 0.3601 & 0.6167 & \textcolor{accentgreen}{\textbf{+0.2566}} \\
bottle & 0.4551 & 0.6774 & \textcolor{accentgreen}{\textbf{+0.2223}} \\
leather & 0.2292 & 0.3970 & \textcolor{accentgreen}{\textbf{+0.1678}} \\
toothbrush & 0.4028 & 0.5619 & +0.1591 \\
wood & 0.3546 & 0.4453 & +0.0907 \\
hazelnut & 0.5110 & 0.5798 & +0.0688 \\
\midrule
metal\_nut & 0.8491 & 0.7776 & \textcolor{red}{-0.0715} \\
cable & 0.6575 & 0.6339 & \textcolor{red}{-0.0236} \\
\midrule
\textbf{Mean} & \textbf{0.4640} & \textbf{0.5350} & \textbf{+0.0710} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Observations:}
\begin{itemize}
    \item \textcolor{accentgreen}{\textbf{Textured classes}} (carpet, leather): 가장 큰 개선
    \item \textcolor{red}{\textbf{Fine-grained objects}} (metal\_nut, cable): 약간의 성능 저하
\end{itemize}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Hyperparameter Sensitivity Summary
%-------------------------------------------------------------------------------
\begin{frame}{Hyperparameter Sensitivity Summary}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{DIA Blocks}
\begin{table}
\scriptsize
\begin{tabular}{ccc}
\toprule
Blocks & Image AUC & Pixel AP \\
\midrule
4 & 0.9793 & 0.4735 \\
6 & 0.9820 & 0.4606 \\
8 & \textbf{0.9825} & 0.4546 \\
\bottomrule
\end{tabular}
\end{table}
\begin{itemize}
    \item[$\uparrow$] Blocks $\rightarrow$ $\uparrow$ Image AUC
    \item[$\downarrow$] Pixel AP (trade-off)
\end{itemize}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{LoRA Rank (Minimal Effect)}
\begin{table}
\scriptsize
\begin{tabular}{ccc}
\toprule
Rank & Image AUC & Pixel AP \\
\midrule
32 & 0.9794 & 0.4737 \\
64 & 0.9793 & 0.4735 \\
128 & 0.9794 & 0.4736 \\
256 & 0.9796 & 0.4741 \\
\bottomrule
\end{tabular}
\end{table}
\begin{itemize}
    \item Rank 64로 충분
    \item 파라미터 효율성 확인
\end{itemize}
\end{column}
\end{columns}

\vspace{1em}
\begin{alertblock}{Warning: Coupling Layers}
\textbf{Coupling16}: 학습 불안정 발생 (Image AUC 0.73으로 급락). 8-12 권장.
\end{alertblock}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Optimal Configuration Recommendations
%-------------------------------------------------------------------------------
\begin{frame}{Optimal Configuration Recommendations}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Balanced Setting (권장)}
\begin{itemize}
    \item \texttt{tail\_weight = 0.55}
    \item \texttt{topk = 5}
    \item \texttt{logdet\_reg = 1e-4}
    \item \texttt{scale\_context\_k = 5}
    \item \texttt{lr = 3e-4}
    \item \texttt{epochs = 60}
\end{itemize}
\vspace{0.5em}
$\rightarrow$ Image AUC $\approx$ \textbf{0.982}, Pixel AP $\approx$ \textbf{0.535}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Max Image AUC Setting}
\begin{itemize}
    \item \texttt{tail\_weight = 0.55}
    \item \texttt{lora\_rank = 128}
    \item \texttt{dia\_n\_blocks = 5}
    \item \texttt{coupling = 10}
    \item \texttt{lr = 3e-4}
    \item \texttt{epochs = 80}
\end{itemize}
\vspace{0.5em}
$\rightarrow$ Image AUC $\approx$ \textbf{0.984}, Pixel AP $\approx$ \textbf{0.524}
\end{column}
\end{columns}
\end{frame}

%===============================================================================
\section{Experiments Part 2: Paper Experiment Design}
%===============================================================================

%-------------------------------------------------------------------------------
% Frame: Experimental Setup
%-------------------------------------------------------------------------------
\begin{frame}{Experimental Setup}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Datasets}
\begin{itemize}
    \item \textbf{MVTec AD}: 15 classes, 5,354 images
    \item \textbf{VisA}: 12 classes, 10,821 images
    \item \textbf{MPDD}: 6 classes (metal parts)
\end{itemize}

\vspace{0.5em}
\textbf{Evaluation Metrics}
\begin{itemize}
    \item Image AUROC / AP (primary)
    \item Pixel AUROC / AP / PRO
    \item Forgetting (F), BWT
    \item Routing Accuracy
\end{itemize}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Implementation}
\begin{itemize}
    \item Backbone: ViT-Base-16 (frozen)
    \item NF: 8 Coupling Layers
    \item LoRA rank: 64
    \item DIA: 4 blocks
    \item Epochs: 60 per task
    \item LR: $2 \times 10^{-4}$
    \item Input: 224 $\times$ 224
\end{itemize}

\vspace{0.5em}
\textbf{Hardware}: NVIDIA RTX 4090
\end{column}
\end{columns}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Continual Learning Scenarios
%-------------------------------------------------------------------------------
\begin{frame}{Continual Learning Scenarios}
\textbf{4가지 시나리오로 지속 학습 능력 검증:}

\vspace{0.5em}
\begin{enumerate}
    \item \textbf{Scenario A: Standard 5-Task Protocol}
    \begin{itemize}
        \item MVTec 15 classes $\rightarrow$ 5 tasks (각 3 classes)
        \item Task 0: leather, grid, transistor (텍스처 + 객체 혼합)
    \end{itemize}

    \vspace{0.3em}
    \item \textbf{Scenario B: Long Sequence (15-Task)}
    \begin{itemize}
        \item 15개 클래스를 각각 독립 작업으로 구성
        \item 장기 망각(Long-term Forgetting) 분석
    \end{itemize}

    \vspace{0.3em}
    \item \textbf{Scenario C: Class Order Sensitivity}
    \begin{itemize}
        \item 5개 무작위 순서로 학습
        \item Parameter Isolation의 순서 견고성 검증
    \end{itemize}

    \vspace{0.3em}
    \item \textbf{Scenario D: Task 0 Dependency Analysis}
    \begin{itemize}
        \item Texture-first vs Object-first vs Mixed-first
        \item Base weights 학습이 후속 작업에 미치는 영향
    \end{itemize}
\end{enumerate}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Comparison with SOTA Methods
%-------------------------------------------------------------------------------
\begin{frame}{Comparison with SOTA Methods}
\textbf{비교 대상:}

\vspace{0.5em}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Continual AD Methods}
\begin{itemize}
    \item \textbf{DNE}: 분포 저장 기반
    \item \textbf{UCAD}: Prompt tuning 기반 SOTA
\end{itemize}

\vspace{0.5em}
\textbf{CL + AD Adaptation}
\begin{itemize}
    \item EWC: 중요 파라미터 정규화
    \item LwF: Knowledge Distillation
    \item Replay (5\%): 데이터 저장
\end{itemize}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Bounds}
\begin{itemize}
    \item \textbf{Joint Training}: Upper bound
    \item \textbf{Task-Separated}: 망각 없음, 비효율
    \item \textbf{Fine-tuning}: Lower bound
\end{itemize}

\vspace{0.5em}
\textbf{검증 목표:}
\begin{itemize}
    \item 이상 탐지 성능 우수성
    \item Forgetting $\approx$ 0 (Parameter Isolation)
    \item Routing Accuracy 100\%
\end{itemize}
\end{column}
\end{columns}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Ablation Study Design (7 Components)
%-------------------------------------------------------------------------------
\begin{frame}{Ablation Study: 컴포넌트별 중요도 분석}
\begin{table}
\centering
\scriptsize
\begin{tabular}{lcccl}
\toprule
\textbf{Removed Component} & \textbf{Image AUC} & \textbf{Pixel AP} & \textbf{$\Delta$ ImgAUC} & \textbf{Importance} \\
\midrule
\textbf{Full Model} & \textbf{0.9793} & \textbf{0.4735} & - & Baseline \\
\midrule
\multicolumn{5}{l}{\textit{Core Adapters}} \\
\quad w/o DIA & 0.9479 & 0.4586 & \textcolor{red}{\textbf{-3.14\%}} & \ding{72}\ding{72}\ding{72}\ding{72}\ding{72} \\
\quad w/o Whitening & 0.9604 & 0.4461 & \textcolor{red}{-1.89\%} & \ding{72}\ding{72}\ding{72}\ding{72} \\
\quad w/o LoRA & 0.9797 & 0.4753 & +0.04\% & \ding{72} \\
\midrule
\multicolumn{5}{l}{\textit{Context Modules}} \\
\quad w/o Spatial Context & 0.9772 & 0.4659 & -0.21\% & \ding{72}\ding{72} \\
\quad w/o Scale Context & 0.9775 & 0.4776 & -0.18\% & \ding{72}\ding{72} \\
\quad w/o PosEmbed & 0.9767 & 0.4564 & -0.26\% & \ding{72}\ding{72} \\
\midrule
\multicolumn{5}{l}{\textit{Loss Components}} \\
\quad w/o LogdetReg & - & 0.4640 & PixAP \textcolor{red}{-4.15\%} & \ding{72}\ding{72}\ding{72}\ding{72}\ding{72} \\
\bottomrule
\end{tabular}
\end{table}

\begin{alertblock}{Key Insight}
\textbf{DIA}: Image AUC에 가장 중요 (-3.14\%) \quad \textbf{LogdetReg}: Pixel AP에 가장 중요 (+4.15\%)
\end{alertblock}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Cross-Dataset Generalization
%-------------------------------------------------------------------------------
\begin{frame}{Cross-Dataset Generalization}
\textbf{MVTec $\rightarrow$ VisA $\rightarrow$ MPDD 일반화 평가:}

\begin{table}
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Dataset} & \textbf{Classes} & \textbf{Image AUC} & \textbf{Pixel AP} & \textbf{Routing Acc.} \\
\midrule
MVTec AD & 15 & \textbf{0.9824} & \textbf{0.5350} & 100\% \\
VisA & 12 & 0.8566 & 0.2878 & 100\% \\
MPDD & 6 & 0.9019 & 0.2890 & 98.12\% \\
\bottomrule
\end{tabular}
\end{table}

\vspace{0.5em}
\textbf{VisA Analysis:}
\begin{itemize}
    \item 복잡한 텍스처와 미세 결함 $\rightarrow$ 더 도전적
    \item 병목 클래스: macaroni1/2 (Pixel AP $<$ 0.1)
    \item ViT backbone: Image AUC 0.88 (WRN50 대비 +4.2\%)
\end{itemize}

\textbf{MPDD:}
\begin{itemize}
    \item 금속 표면의 유사성 $\rightarrow$ Routing 오류 (98.12\%)
\end{itemize}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Continual Learning Analysis
%-------------------------------------------------------------------------------
\begin{frame}{Continual Learning Analysis}
\textbf{Forgetting 분석:}
\begin{itemize}
    \item Parameter Isolation (LoRA + DIA) $\rightarrow$ \textbf{Forgetting $\approx$ 0}
    \item vs Fine-tuning: 급격한 성능 하락
    \item vs EWC/LwF: 완만한 하락
\end{itemize}

\vspace{1em}
\textbf{Router Performance:}
\begin{itemize}
    \item 5-Task: 100\% Routing Accuracy
    \item 15-Task: Oracle과의 Gap 분석
    \item Task 수 증가에 따른 Scalability 검증
\end{itemize}

\vspace{1em}
\textbf{Storage Efficiency:}
\begin{itemize}
    \item MoLE-Flow: 약 2MB/Task (LoRA + DIA)
    \item vs Replay (5\%): 50MB/Task $\rightarrow$ \textbf{25x 절약}
\end{itemize}
\end{frame}

%===============================================================================
\section{Conclusion \& Future Work}
%===============================================================================

%-------------------------------------------------------------------------------
% Frame: Summary
%-------------------------------------------------------------------------------
\begin{frame}{Summary}
\textbf{MoLE-Flow: 지속적 이상 탐지를 위한 프레임워크}

\vspace{1em}
\begin{enumerate}
    \item \textbf{Parameter Isolation}: Base 공유 + Task-specific 어댑터
    \item \textbf{MoLE}: LoRA 기반 경량 작업 적응
    \item \textbf{WhiteningAdapter}: 분포 정렬을 통한 안정적 학습
    \item \textbf{DIA}: 비선형 매니폴드 적응
    \item \textbf{Prototype Router}: One-stage 추론
    \item \textbf{Tail-Aware Loss}: 경계 학습 강화
\end{enumerate}

\vspace{1em}
\begin{block}{핵심 장점}
\begin{itemize}
    \item 파멸적 망각 방지 (Forgetting $\approx$ 0)
    \item 파라미터 효율성 (작업당 $\sim$10.8\%)
    \item Task ID 없이 추론 가능 (Routing 100\%)
\end{itemize}
\end{block}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Key Results
%-------------------------------------------------------------------------------
\begin{frame}{Key Results}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{MVTec AD (Best Performance)}
\begin{itemize}
    \item Image AUC: \textbf{0.9836}
    \item Pixel AP: \textbf{0.5350}
    \item Routing Acc.: \textbf{100\%}
\end{itemize}

\vspace{1em}
\textbf{개선 효과}
\begin{itemize}
    \item Pixel AP: +15.3\% (Baseline 대비)
    \item 78개 실험을 통한 최적화
\end{itemize}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Cross-Dataset}
\begin{itemize}
    \item VisA: Image AUC 0.8566
    \item MPDD: Image AUC 0.9019
\end{itemize}

\vspace{1em}
\textbf{핵심 하이퍼파라미터}
\begin{itemize}
    \item LogdetReg 1e-4 (최대 효과)
    \item TailW 0.55-0.75
    \item ScaleCtxK 5
\end{itemize}
\end{column}
\end{columns}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Future Work
%-------------------------------------------------------------------------------
\begin{frame}{Future Work}
\textbf{1. 성능 향상 방향}
\begin{itemize}
    \item Pixel AP 0.6+ 달성을 위한 추가 최적화
    \item 고해상도 입력 (448 $\times$ 448) 적용
    \item DINOv2 ViT-L/H 등 강력한 backbone 탐색
\end{itemize}

\vspace{1em}
\textbf{2. 일반화 강화}
\begin{itemize}
    \item VisA 병목 클래스 (macaroni) 특화 전략
    \item Multi-scale 평가 앙상블
    \item Class-specific hyperparameter tuning
\end{itemize}

\vspace{1em}
\textbf{3. 실용화 연구}
\begin{itemize}
    \item 실시간 추론 최적화
    \item 경량화 (Quantization, Pruning)
    \item 온라인 학습 시나리오 확장
\end{itemize}
\end{frame}

%-------------------------------------------------------------------------------
% Frame: Thank You
%-------------------------------------------------------------------------------
\begin{frame}
\centering
\Huge Thank You!

\vspace{2em}
\Large Questions?

\vspace{3em}
\normalsize
\textbf{GitHub}: \texttt{github.com/your-repo/moleflow}

\textbf{Contact}: author@example.com
\end{frame}

\end{document}
